{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a739384",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16020846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.metrics.pairwise import manhattan_distances,pairwise_distances\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from metric_learn import NCA\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8832d8",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed626f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train_unique.csv')\n",
    "X_val = pd.read_csv('X_val_unique.csv')\n",
    "X_test = pd.read_csv('X_test_unique.csv')\n",
    "\n",
    "y_train = pd.read_csv('y_train_unique.csv')\n",
    "y_val = pd.read_csv('y_val_unique.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e27b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.set_index('unique_id',inplace=True)\n",
    "X_val.set_index('unique_id',inplace=True)\n",
    "X_test.set_index('unique_id',inplace=True)\n",
    "y_train.set_index('unique_id',inplace=True)\n",
    "y_val.set_index('unique_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c3556d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2380, 1539)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8337015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e353eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2324814, 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7a74e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_df = raw_test_df[['unique_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "943fc698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2380, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c168bb",
   "metadata": {},
   "source": [
    "### Submission 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e759a5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cidem\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(max_depth=2,learning_rate=0.01,n_estimators=100,min_child_samples=100,colsample_bytree=0.5)\n",
    "lgbm.fit(X_train,y_train)\n",
    "\n",
    "pred_train = pd.DataFrame(lgbm.predict_proba(X_train)[:,1],columns=['pred'],index=X_train.index)\n",
    "pred_val = pd.DataFrame(lgbm.predict_proba(X_val)[:,1],columns=['pred'],index=X_val.index)\n",
    "pred_test = pd.DataFrame(lgbm.predict_proba(X_test)[:,1],columns=['pred'],index=X_test.index)\n",
    "\n",
    "pred_train = pd.merge(pred_train,y_train,how='left',left_index=True, right_index=True)\n",
    "pred_val = pd.merge(pred_val,y_val,how='left',left_index=True, right_index=True)\n",
    "\n",
    "roc_train = roc_auc_score(pred_train['female_label'],pred_train['pred'])\n",
    "roc_val = roc_auc_score(pred_val['female_label'],pred_val['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3406483b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC:  0.857003441098348\n",
      "Val ROC:  0.8480658721894403\n"
     ]
    }
   ],
   "source": [
    "print('Train ROC: ',roc_train)\n",
    "print('Val ROC: ',roc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "828e45b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_rate_df = pd.DataFrame()\n",
    "\n",
    "for th in np.arange(0,1,0.1):\n",
    "\n",
    "    pred_train['pred_binary'] = np.where(pred_train['pred']>=th,1,0)\n",
    "    pred_val['pred_binary'] = np.where(pred_val['pred']>=th,1,0)\n",
    "\n",
    "    err_rate1_train = 1-(pred_train[pred_train['female_label']==1]['pred_binary'].sum()/pred_train[pred_train['female_label']==1]['pred_binary'].count())\n",
    "    err_rate0_train = pred_train[pred_train['female_label']==0]['pred_binary'].sum()/pred_train[pred_train['female_label']==0]['pred_binary'].count()\n",
    "    err_rate_train = err_rate1_train+err_rate0_train\n",
    "\n",
    "    err_rate1_val = 1-(pred_val[pred_val['female_label']==1]['pred_binary'].sum()/pred_val[pred_val['female_label']==1]['pred_binary'].count())\n",
    "    err_rate0_val = pred_val[pred_val['female_label']==0]['pred_binary'].sum()/pred_val[pred_val['female_label']==0]['pred_binary'].count()\n",
    "    err_rate_val = err_rate1_val+err_rate0_val\n",
    "\n",
    "    err_rate_df_tmp = pd.DataFrame({'threshold':[th],\n",
    "                                    'err_rate1_train':[err_rate1_train],\n",
    "                                    'err_rate0_train':[err_rate0_train],\n",
    "                                    'err_rate_train':[err_rate_train],\n",
    "                                    'err_rate1_val':[err_rate1_val],\n",
    "                                    'err_rate0_val':[err_rate0_val],\n",
    "                                    'err_rate_val':[err_rate_val]\n",
    "                                   })\n",
    "    err_rate_df = pd.concat([err_rate_df,err_rate_df_tmp])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e7a10a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>err_rate1_train</th>\n",
       "      <th>err_rate0_train</th>\n",
       "      <th>err_rate_train</th>\n",
       "      <th>err_rate1_val</th>\n",
       "      <th>err_rate0_val</th>\n",
       "      <th>err_rate_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.970361</td>\n",
       "      <td>0.973080</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.979458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.078858</td>\n",
       "      <td>0.552191</td>\n",
       "      <td>0.631049</td>\n",
       "      <td>0.082768</td>\n",
       "      <td>0.576227</td>\n",
       "      <td>0.658995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>0.389820</td>\n",
       "      <td>0.523742</td>\n",
       "      <td>0.143826</td>\n",
       "      <td>0.413437</td>\n",
       "      <td>0.557263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.414684</td>\n",
       "      <td>0.063789</td>\n",
       "      <td>0.478473</td>\n",
       "      <td>0.443691</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.490202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.619307</td>\n",
       "      <td>0.016108</td>\n",
       "      <td>0.635415</td>\n",
       "      <td>0.658073</td>\n",
       "      <td>0.025840</td>\n",
       "      <td>0.683913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  err_rate1_train  err_rate0_train  err_rate_train  err_rate1_val  \\\n",
       "0        0.0         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.1         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.2         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.3         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.4         0.002719         0.970361        0.973080       0.002714   \n",
       "0        0.5         0.078858         0.552191        0.631049       0.082768   \n",
       "0        0.6         0.133923         0.389820        0.523742       0.143826   \n",
       "0        0.7         0.414684         0.063789        0.478473       0.443691   \n",
       "0        0.8         0.619307         0.016108        0.635415       0.658073   \n",
       "0        0.9         1.000000         0.000000        1.000000       1.000000   \n",
       "\n",
       "   err_rate0_val  err_rate_val  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       0.976744      0.979458  \n",
       "0       0.576227      0.658995  \n",
       "0       0.413437      0.557263  \n",
       "0       0.046512      0.490202  \n",
       "0       0.025840      0.683913  \n",
       "0       0.000000      1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_rate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e78aa4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.722639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>0.798873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>0.760979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>0.828495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.726179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6191</th>\n",
       "      <td>0.633658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6121</th>\n",
       "      <td>0.632104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0.596183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6640</th>\n",
       "      <td>0.627353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7509</th>\n",
       "      <td>0.633658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2380 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred\n",
       "unique_id          \n",
       "108        0.722639\n",
       "2724       0.798873\n",
       "717        0.760979\n",
       "578        0.828495\n",
       "147        0.726179\n",
       "...             ...\n",
       "6191       0.633658\n",
       "6121       0.632104\n",
       "3245       0.596183\n",
       "6640       0.627353\n",
       "7509       0.633658\n",
       "\n",
       "[2380 rows x 1 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c870afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a27e0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>0.722639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id      pred\n",
       "0        108  0.722639"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test[pred_test['unique_id']==108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "369d8ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.722639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2724</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>717</td>\n",
       "      <td>2</td>\n",
       "      <td>0.760979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>578</td>\n",
       "      <td>3</td>\n",
       "      <td>0.828495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147</td>\n",
       "      <td>4</td>\n",
       "      <td>0.726179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>6191</td>\n",
       "      <td>2375</td>\n",
       "      <td>0.633658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>6121</td>\n",
       "      <td>2376</td>\n",
       "      <td>0.632104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>3245</td>\n",
       "      <td>2377</td>\n",
       "      <td>0.596183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>6640</td>\n",
       "      <td>2378</td>\n",
       "      <td>0.627353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>7509</td>\n",
       "      <td>2379</td>\n",
       "      <td>0.633658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2380 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id  index      pred\n",
       "0           108      0  0.722639\n",
       "1          2724      1  0.798873\n",
       "2           717      2  0.760979\n",
       "3           578      3  0.828495\n",
       "4           147      4  0.726179\n",
       "...         ...    ...       ...\n",
       "2375       6191   2375  0.633658\n",
       "2376       6121   2376  0.632104\n",
       "2377       3245   2377  0.596183\n",
       "2378       6640   2378  0.627353\n",
       "2379       7509   2379  0.633658\n",
       "\n",
       "[2380 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1 = pd.merge(raw_test_df,pred_test.reset_index(),how='left',on='unique_id')\n",
    "sub1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "32209a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1['pred'] = sub1['pred'].apply(lambda x: round(x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f226660d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.723,0.799,0.761,0.828,0.726,0.841,0.841,0.748,0.713,0.839,0.439,0.632,0.521,0.632,0.645,0.654,0.752,0.768,0.787,0.839,0.654,0.838,0.841,0.759,0.838,0.447,0.426,0.704,0.726,0.624,0.743,0.749,0.668,0.841,0.759,0.84,0.839,0.66,0.733,0.737,0.841,0.537,0.515,0.839,0.841,0.718,0.748,0.765,0.471,0.626,0.766,0.838,0.513,0.841,0.452,0.832,0.761,0.525,0.841,0.841,0.41,0.578,0.407,0.825,0.515,0.752,0.499,0.685,0.834,0.634,0.737,0.65,0.684,0.439,0.704,0.841,0.604,0.839,0.807,0.838,0.634,0.812,0.624,0.627,0.645,0.45,0.618,0.634,0.41,0.841,0.825,0.599,0.758,0.754,0.816,0.757,0.677,0.536,0.665,0.822,0.839,0.718,0.71,0.841,0.513,0.675,0.807,0.673,0.841,0.632,0.834,0.841,0.712,0.663,0.726,0.839,0.834,0.632,0.754,0.596,0.64,0.565,0.455,0.562,0.731,0.841,0.762,0.834,0.634,0.709,0.811,0.736,0.819,0.759,0.677,0.839,0.833,0.627,0.84,0.838,0.679,0.645,0.841,0.634,0.739,0.732,0.841,0.74,0.746,0.689,0.841,0.617,0.694,0.743,0.488,0.795,0.636,0.841,0.444,0.632,0.841,0.832,0.749,0.696,0.837,0.841,0.44,0.759,0.426,0.692,0.768,0.718,0.65,0.684,0.761,0.829,0.648,0.456,0.617,0.841,0.626,0.531,0.761,0.841,0.42,0.757,0.729,0.84,0.715,0.839,0.418,0.829,0.736,0.545,0.84,0.839,0.735,0.841,0.838,0.759,0.522,0.743,0.611,0.75,0.48,0.834,0.757,0.675,0.702,0.823,0.724,0.841,0.776,0.464,0.451,0.813,0.828,0.759,0.759,0.683,0.696,0.472,0.619,0.728,0.821,0.407,0.632,0.832,0.768,0.634,0.761,0.704,0.835,0.472,0.536,0.672,0.626,0.671,0.647,0.757,0.841,0.598,0.822,0.478,0.759,0.841,0.841,0.734,0.841,0.624,0.822,0.834,0.701,0.759,0.535,0.481,0.761,0.624,0.596,0.739,0.822,0.747,0.702,0.701,0.841,0.78,0.641,0.669,0.841,0.708,0.719,0.407,0.838,0.766,0.712,0.539,0.544,0.399,0.634,0.803,0.839,0.634,0.768,0.709,0.838,0.839,0.832,0.595,0.738,0.624,0.841,0.839,0.627,0.834,0.757,0.841,0.841,0.839,0.837,0.759,0.841,0.841,0.701,0.757,0.736,0.734,0.725,0.716,0.757,0.732,0.75,0.657,0.652,0.624,0.82,0.839,0.826,0.832,0.762,0.417,0.823,0.835,0.489,0.715,0.521,0.836,0.84,0.841,0.823,0.841,0.837,0.627,0.714,0.634,0.841,0.489,0.439,0.602,0.737,0.725,0.4,0.738,0.685,0.819,0.634,0.781,0.634,0.821,0.55,0.716,0.841,0.825,0.835,0.794,0.832,0.701,0.739,0.839,0.592,0.841,0.839,0.735,0.626,0.759,0.568,0.763,0.841,0.632,0.696,0.49,0.813,0.632,0.838,0.832,0.839,0.841,0.813,0.832,0.838,0.65,0.626,0.813,0.755,0.624,0.838,0.731,0.759,0.64,0.822,0.628,0.645,0.598,0.833,0.753,0.791,0.487,0.73,0.736,0.617,0.704,0.404,0.834,0.74,0.841,0.632,0.836,0.841,0.738,0.813,0.747,0.638,0.824,0.774,0.718,0.743,0.743,0.801,0.731,0.816,0.674,0.657,0.44,0.618,0.46,0.793,0.831,0.746,0.834,0.824,0.462,0.832,0.708,0.464,0.594,0.634,0.739,0.839,0.731,0.407,0.414,0.754,0.738,0.632,0.751,0.529,0.815,0.83,0.822,0.708,0.831,0.468,0.84,0.759,0.434,0.835,0.841,0.834,0.822,0.624,0.822,0.841,0.714,0.437,0.6,0.44,0.739,0.453,0.829,0.839,0.717,0.841,0.841,0.766,0.781,0.553,0.74,0.49,0.834,0.822,0.577,0.707,0.814,0.453,0.723,0.83,0.636,0.76,0.756,0.839,0.421,0.839,0.436,0.737,0.587,0.434,0.558,0.799,0.833,0.628,0.831,0.463,0.409,0.656,0.761,0.627,0.634,0.447,0.731,0.544,0.502,0.606,0.833,0.631,0.841,0.83,0.643,0.634,0.831,0.635,0.841,0.708,0.44,0.818,0.832,0.683,0.752,0.583,0.831,0.464,0.775,0.675,0.806,0.624,0.514,0.733,0.839,0.447,0.715,0.759,0.647,0.822,0.448,0.412,0.8,0.639,0.485,0.465,0.774,0.841,0.709,0.839,0.497,0.841,0.626,0.429,0.634,0.621,0.645,0.823,0.407,0.748,0.416,0.453,0.841,0.427,0.412,0.768,0.399,0.764,0.762,0.841,0.457,0.424,0.4,0.44,0.723,0.409,0.819,0.841,0.497,0.744,0.746,0.839,0.82,0.766,0.841,0.841,0.71,0.841,0.416,0.634,0.634,0.822,0.699,0.841,0.841,0.46,0.738,0.759,0.841,0.648,0.708,0.744,0.631,0.743,0.522,0.841,0.626,0.841,0.624,0.713,0.439,0.738,0.806,0.841,0.838,0.831,0.768,0.617,0.834,0.406,0.636,0.448,0.84,0.757,0.839,0.426,0.825,0.475,0.523,0.399,0.713,0.711,0.655,0.612,0.496,0.736,0.516,0.714,0.841,0.841,0.47,0.771,0.489,0.632,0.841,0.839,0.829,0.681,0.653,0.439,0.409,0.636,0.634,0.474,0.626,0.432,0.828,0.84,0.838,0.422,0.539,0.646,0.644,0.839,0.822,0.841,0.841,0.709,0.832,0.841,0.833,0.685,0.697,0.72,0.409,0.838,0.838,0.65,0.44,0.841,0.822,0.426,0.841,0.634,0.523,0.757,0.624,0.583,0.691,0.624,0.839,0.71,0.708,0.793,0.701,0.752,0.406,0.833,0.621,0.419,0.458,0.464,0.696,0.768,0.593,0.626,0.631,0.625,0.768,0.612,0.798,0.841,0.818,0.407,0.833,0.84,0.615,0.548,0.829,0.715,0.636,0.636,0.611,0.634,0.634,0.634,0.636,0.574,0.636,0.625,0.634,0.634,0.636,0.634,0.634,0.634,0.618,0.773,0.841,0.45,0.659,0.464,0.505,0.816,0.746,0.632,0.539,0.801,0.399,0.41,0.823,0.632,0.841,0.591,0.436,0.472,0.675,0.841,0.841,0.82,0.792,0.399,0.839,0.491,0.757,0.755,0.735,0.579,0.715,0.841,0.41,0.744,0.723,0.735,0.404,0.834,0.76,0.511,0.634,0.482,0.834,0.779,0.675,0.441,0.681,0.775,0.528,0.743,0.822,0.645,0.525,0.798,0.818,0.841,0.841,0.823,0.591,0.841,0.679,0.552,0.834,0.834,0.816,0.771,0.699,0.629,0.785,0.624,0.536,0.841,0.841,0.835,0.782,0.761,0.826,0.841,0.636,0.841,0.818,0.432,0.841,0.841,0.591,0.827,0.841,0.839,0.823,0.746,0.7,0.826,0.84,0.841,0.484,0.801,0.634,0.837,0.441,0.627,0.634,0.426,0.839,0.793,0.4,0.459,0.823,0.423,0.418,0.399,0.829,0.624,0.834,0.807,0.641,0.516,0.839,0.428,0.759,0.706,0.438,0.832,0.677,0.654,0.399,0.84,0.626,0.555,0.839,0.624,0.795,0.628,0.839,0.578,0.399,0.64,0.771,0.84,0.835,0.661,0.445,0.81,0.648,0.841,0.412,0.832,0.694,0.834,0.65,0.407,0.41,0.785,0.761,0.477,0.65,0.822,0.839,0.841,0.523,0.632,0.531,0.712,0.49,0.46,0.52,0.795,0.489,0.625,0.63,0.841,0.841,0.841,0.426,0.634,0.438,0.766,0.425,0.783,0.631,0.775,0.828,0.835,0.737,0.739,0.752,0.626,0.636,0.687,0.768,0.779,0.841,0.556,0.822,0.58,0.632,0.414,0.544,0.84,0.834,0.506,0.483,0.841,0.405,0.624,0.423,0.604,0.453,0.841,0.634,0.625,0.826,0.514,0.634,0.634,0.841,0.738,0.687,0.483,0.45,0.474,0.44,0.624,0.716,0.634,0.841,0.841,0.464,0.399,0.751,0.573,0.683,0.534,0.648,0.841,0.676,0.515,0.841,0.636,0.841,0.624,0.799,0.648,0.734,0.84,0.791,0.409,0.59,0.409,0.424,0.533,0.815,0.41,0.746,0.647,0.693,0.429,0.474,0.524,0.509,0.632,0.841,0.841,0.84,0.624,0.429,0.743,0.745,0.512,0.839,0.521,0.429,0.841,0.634,0.505,0.841,0.841,0.47,0.553,0.738,0.835,0.634,0.832,0.628,0.841,0.64,0.841,0.495,0.837,0.428,0.77,0.412,0.631,0.657,0.631,0.402,0.841,0.624,0.41,0.55,0.759,0.527,0.841,0.588,0.405,0.634,0.824,0.427,0.737,0.409,0.713,0.841,0.818,0.841,0.832,0.631,0.759,0.834,0.829,0.624,0.414,0.533,0.425,0.624,0.632,0.624,0.66,0.838,0.433,0.461,0.407,0.632,0.409,0.476,0.634,0.733,0.535,0.469,0.632,0.409,0.839,0.641,0.841,0.634,0.632,0.839,0.459,0.632,0.631,0.472,0.624,0.704,0.759,0.399,0.841,0.822,0.743,0.624,0.743,0.841,0.794,0.631,0.715,0.736,0.408,0.827,0.624,0.648,0.544,0.446,0.531,0.399,0.429,0.634,0.524,0.825,0.438,0.508,0.741,0.823,0.759,0.533,0.518,0.576,0.632,0.645,0.787,0.648,0.487,0.406,0.418,0.6,0.455,0.762,0.629,0.841,0.841,0.636,0.508,0.807,0.636,0.414,0.836,0.523,0.801,0.779,0.776,0.624,0.626,0.789,0.75,0.816,0.819,0.834,0.748,0.478,0.837,0.833,0.788,0.661,0.503,0.41,0.407,0.721,0.592,0.45,0.746,0.692,0.485,0.841,0.424,0.632,0.634,0.641,0.81,0.43,0.634,0.832,0.713,0.829,0.409,0.476,0.68,0.497,0.698,0.697,0.841,0.787,0.84,0.579,0.692,0.841,0.674,0.596,0.825,0.733,0.407,0.841,0.841,0.634,0.801,0.834,0.401,0.637,0.643,0.45,0.831,0.547,0.838,0.799,0.646,0.632,0.507,0.718,0.521,0.648,0.632,0.737,0.835,0.841,0.834,0.631,0.838,0.627,0.51,0.464,0.774,0.723,0.414,0.841,0.841,0.841,0.636,0.841,0.721,0.634,0.479,0.717,0.841,0.632,0.84,0.729,0.555,0.502,0.624,0.841,0.737,0.624,0.823,0.41,0.626,0.632,0.781,0.632,0.698,0.634,0.626,0.636,0.734,0.801,0.737,0.632,0.718,0.822,0.814,0.632,0.698,0.841,0.634,0.757,0.624,0.746,0.677,0.634,0.643,0.647,0.766,0.464,0.421,0.624,0.645,0.839,0.734,0.448,0.634,0.539,0.827,0.632,0.631,0.839,0.589,0.634,0.624,0.765,0.841,0.407,0.841,0.729,0.626,0.624,0.839,0.811,0.479,0.726,0.628,0.645,0.693,0.816,0.447,0.634,0.487,0.485,0.84,0.667,0.715,0.724,0.461,0.399,0.736,0.838,0.743,0.424,0.841,0.834,0.424,0.73,0.832,0.749,0.839,0.552,0.827,0.409,0.841,0.841,0.554,0.834,0.474,0.632,0.645,0.432,0.816,0.839,0.823,0.632,0.418,0.841,0.841,0.499,0.841,0.839,0.736,0.411,0.618,0.648,0.547,0.674,0.418,0.835,0.541,0.838,0.399,0.837,0.839,0.837,0.671,0.684,0.834,0.701,0.65,0.84,0.726,0.84,0.831,0.648,0.399,0.634,0.736,0.631,0.634,0.534,0.768,0.489,0.434,0.822,0.631,0.624,0.836,0.631,0.841,0.839,0.458,0.834,0.648,0.841,0.446,0.737,0.724,0.634,0.631,0.714,0.535,0.519,0.624,0.724,0.441,0.808,0.399,0.651,0.639,0.631,0.558,0.841,0.636,0.648,0.648,0.409,0.796,0.515,0.841,0.84,0.841,0.826,0.634,0.399,0.658,0.648,0.8,0.406,0.632,0.648,0.626,0.412,0.648,0.634,0.83,0.831,0.841,0.841,0.46,0.839,0.41,0.624,0.49,0.635,0.628,0.841,0.639,0.399,0.42,0.84,0.495,0.634,0.518,0.739,0.841,0.46,0.423,0.636,0.62,0.632,0.817,0.537,0.838,0.694,0.631,0.839,0.657,0.745,0.617,0.602,0.839,0.399,0.417,0.73,0.837,0.444,0.647,0.692,0.51,0.664,0.626,0.504,0.573,0.418,0.647,0.42,0.429,0.659,0.404,0.466,0.797,0.658,0.834,0.407,0.684,0.836,0.48,0.839,0.837,0.483,0.49,0.733,0.737,0.418,0.473,0.407,0.629,0.456,0.422,0.79,0.458,0.547,0.511,0.567,0.631,0.647,0.634,0.618,0.745,0.84,0.816,0.482,0.449,0.579,0.624,0.749,0.629,0.827,0.841,0.625,0.478,0.648,0.634,0.444,0.615,0.806,0.632,0.418,0.841,0.739,0.634,0.841,0.838,0.596,0.716,0.47,0.462,0.838,0.481,0.496,0.759,0.84,0.829,0.516,0.657,0.465,0.724,0.464,0.636,0.73,0.628,0.632,0.592,0.42,0.841,0.645,0.816,0.724,0.399,0.587,0.563,0.407,0.625,0.746,0.436,0.837,0.807,0.634,0.634,0.626,0.626,0.407,0.494,0.628,0.399,0.411,0.645,0.476,0.624,0.661,0.807,0.567,0.746,0.405,0.791,0.636,0.634,0.445,0.632,0.437,0.634,0.578,0.808,0.718,0.593,0.459,0.636,0.83,0.731,0.564,0.741,0.641,0.634,0.821,0.641,0.55,0.432,0.467,0.416,0.421,0.644,0.723,0.639,0.626,0.785,0.437,0.826,0.744,0.619,0.425,0.631,0.489,0.834,0.841,0.841,0.455,0.841,0.822,0.634,0.624,0.683,0.626,0.648,0.584,0.632,0.632,0.84,0.814,0.645,0.838,0.624,0.454,0.634,0.841,0.628,0.696,0.614,0.458,0.82,0.666,0.412,0.624,0.409,0.738,0.747,0.681,0.634,0.834,0.832,0.741,0.65,0.824,0.556,0.628,0.841,0.833,0.834,0.49,0.762,0.406,0.634,0.648,0.399,0.839,0.55,0.673,0.839,0.399,0.407,0.624,0.834,0.572,0.841,0.832,0.552,0.773,0.731,0.632,0.49,0.401,0.833,0.837,0.71,0.634,0.632,0.604,0.835,0.841,0.399,0.819,0.521,0.404,0.509,0.626,0.643,0.712,0.624,0.829,0.686,0.551,0.632,0.427,0.628,0.634,0.634,0.535,0.487,0.743,0.838,0.662,0.547,0.819,0.623,0.475,0.714,0.418,0.414,0.518,0.818,0.634,0.624,0.468,0.823,0.634,0.815,0.632,0.641,0.41,0.634,0.747,0.721,0.662,0.634,0.671,0.735,0.826,0.785,0.418,0.486,0.838,0.506,0.45,0.4,0.491,0.533,0.644,0.758,0.634,0.409,0.624,0.733,0.826,0.461,0.552,0.634,0.788,0.634,0.433,0.683,0.442,0.634,0.744,0.841,0.838,0.463,0.459,0.629,0.624,0.634,0.624,0.634,0.411,0.825,0.677,0.732,0.811,0.624,0.629,0.748,0.647,0.841,0.5,0.41,0.5,0.645,0.839,0.542,0.841,0.742,0.482,0.835,0.414,0.57,0.839,0.458,0.678,0.477,0.821,0.626,0.416,0.465,0.624,0.696,0.425,0.496,0.841,0.42,0.451,0.705,0.634,0.833,0.62,0.841,0.459,0.634,0.448,0.739,0.84,0.713,0.818,0.416,0.632,0.473,0.65,0.46,0.629,0.759,0.479,0.538,0.552,0.486,0.632,0.45,0.634,0.75,0.45,0.532,0.817,0.837,0.646,0.818,0.416,0.655,0.44,0.632,0.813,0.839,0.61,0.423,0.409,0.409,0.804,0.781,0.778,0.648,0.611,0.634,0.841,0.762,0.829,0.816,0.841,0.497,0.788,0.648,0.759,0.617,0.793,0.634,0.606,0.818,0.545,0.813,0.634,0.42,0.632,0.684,0.774,0.826,0.624,0.632,0.545,0.62,0.535,0.691,0.719,0.838,0.519,0.626,0.841,0.631,0.634,0.821,0.841,0.424,0.462,0.632,0.723,0.553,0.746,0.6,0.827,0.558,0.723,0.716,0.411,0.688,0.631,0.624,0.807,0.595,0.8,0.636,0.841,0.399,0.602,0.624,0.429,0.785,0.837,0.624,0.665,0.841,0.475,0.834,0.596,0.515,0.399,0.629,0.634,0.484,0.432,0.634,0.634,0.463,0.493,0.64,0.717,0.722,0.634,0.624,0.839,0.528,0.422,0.638,0.634,0.626,0.634,0.821,0.53,0.465,0.626,0.634,0.478,0.479,0.626,0.632,0.632,0.628,0.438,0.624,0.606,0.841,0.408,0.632,0.631,0.415,0.841,0.816,0.488,0.494,0.839,0.643,0.624,0.633,0.624,0.4,0.648,0.648,0.48,0.562,0.404,0.841,0.772,0.467,0.671,0.643,0.6,0.539,0.739,0.841,0.759,0.634,0.634,0.404,0.445,0.44,0.819,0.63,0.743,0.834,0.424,0.689,0.634,0.486,0.838,0.666,0.839,0.478,0.466,0.641,0.694,0.523,0.841,0.811,0.541,0.817,0.648,0.532,0.841,0.841,0.438,0.484,0.634,0.841,0.474,0.63,0.624,0.831,0.832,0.536,0.634,0.523,0.841,0.417,0.632,0.648,0.471,0.729,0.634,0.634,0.456,0.725,0.624,0.603,0.465,0.437,0.604,0.816,0.624,0.407,0.617,0.634,0.634,0.624,0.576,0.703,0.399,0.399,0.634,0.759,0.741,0.631,0.576,0.838,0.576,0.531,0.697,0.624,0.809,0.632,0.665,0.841,0.76,0.47,0.451,0.744,0.679,0.634,0.43,0.408,0.729,0.448,0.766,0.474,0.644,0.624,0.82,0.84,0.634,0.555,0.634,0.399,0.589,0.634,0.648,0.648,0.654,0.634,0.632,0.536,0.496,0.404,0.645,0.624,0.746,0.414,0.634,0.594,0.479,0.513,0.624,0.457,0.632,0.592,0.628,0.592,0.626,0.648,0.648,0.442,0.661,0.429,0.521,0.634,0.648,0.713,0.831,0.611,0.634,0.837,0.783,0.494,0.625,0.521,0.521,0.521,0.636,0.504,0.822,0.723,0.839,0.643,0.648,0.511,0.701,0.45,0.624,0.624,0.631,0.479,0.827,0.624,0.76,0.634,0.841,0.638,0.634,0.634,0.634,0.835,0.461,0.841,0.523,0.455,0.634,0.494,0.625,0.58,0.744,0.586,0.748,0.632,0.827,0.837,0.634,0.746,0.634,0.41,0.471,0.841,0.675,0.399,0.464,0.725,0.45,0.675,0.512,0.499,0.733,0.694,0.626,0.634,0.839,0.444,0.648,0.624,0.632,0.685,0.841,0.45,0.732,0.632,0.445,0.634,0.746,0.692,0.784,0.537,0.478,0.739,0.442,0.631,0.624,0.41,0.624,0.519,0.634,0.516,0.806,0.648,0.82,0.634,0.648,0.471,0.625,0.477,0.67,0.578,0.407,0.735,0.634,0.783,0.632,0.841,0.722,0.715,0.626,0.645,0.427,0.624,0.744,0.513,0.794,0.648,0.733,0.831,0.45,0.779,0.519,0.759,0.644,0.812,0.841,0.839,0.841,0.624,0.631,0.675,0.462,0.694,0.629,0.632,0.442,0.632,0.634,0.839,0.762,0.608,0.75,0.481,0.636,0.408,0.634,0.789,0.552,0.738,0.413,0.627,0.626,0.634,0.634,0.634,0.737,0.593,0.634,0.634,0.746,0.629,0.636,0.646,0.634,0.739,0.553,0.535,0.632,0.634,0.648,0.632,0.57,0.64,0.596,0.759,0.453,0.634,0.634,0.634,0.643,0.634,0.617,0.699,0.448,0.828,0.685,0.448,0.634,0.634,0.634,0.634,0.632,0.528,0.634,0.631,0.517,0.741,0.634,0.632,0.714,0.836,0.632,0.779,0.62,0.423,0.489,0.782,0.486,0.587,0.694,0.424,0.686,0.634,0.629,0.768,0.664,0.634,0.626,0.632,0.679,0.626,0.624,0.617,0.645,0.839,0.626,0.621,0.634,0.791,0.634,0.632,0.596,0.627,0.634'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1_txt = ''\n",
    "for prob in list(sub1['pred'].values):\n",
    "    sub1_txt = sub1_txt+','+str(prob)\n",
    "sub1_txt = sub1_txt[1:]\n",
    "\n",
    "sub1_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "53bad80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>9</td>\n",
       "      <td>612</td>\n",
       "      <td>0.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>18</td>\n",
       "      <td>203</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>21</td>\n",
       "      <td>186</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>25</td>\n",
       "      <td>92</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>31</td>\n",
       "      <td>39</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>7982</td>\n",
       "      <td>1266</td>\n",
       "      <td>0.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>7990</td>\n",
       "      <td>1222</td>\n",
       "      <td>0.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>7993</td>\n",
       "      <td>1610</td>\n",
       "      <td>0.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>7994</td>\n",
       "      <td>1559</td>\n",
       "      <td>0.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>7998</td>\n",
       "      <td>1575</td>\n",
       "      <td>0.634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2380 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id  index   pred\n",
       "612           9    612  0.738\n",
       "203          18    203  0.750\n",
       "186          21    186  0.729\n",
       "92           25     92  0.758\n",
       "39           31     39  0.737\n",
       "...         ...    ...    ...\n",
       "1266       7982   1266  0.634\n",
       "1222       7990   1222  0.510\n",
       "1610       7993   1610  0.634\n",
       "1559       7994   1559  0.632\n",
       "1575       7998   1575  0.634\n",
       "\n",
       "[2380 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1.sort_values(by='unique_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a30e67c",
   "metadata": {},
   "source": [
    "* Right order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e0447a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.738,0.75,0.729,0.758,0.737,0.841,0.675,0.409,0.698,0.701,0.593,0.535,0.807,0.841,0.708,0.746,0.617,0.426,0.71,0.832,0.822,0.762,0.761,0.738,0.78,0.759,0.817,0.813,0.723,0.692,0.791,0.733,0.712,0.817,0.84,0.76,0.644,0.698,0.841,0.731,0.726,0.819,0.834,0.8,0.813,0.785,0.838,0.674,0.743,0.832,0.41,0.841,0.779,0.416,0.433,0.405,0.839,0.806,0.841,0.744,0.787,0.807,0.562,0.759,0.841,0.748,0.837,0.759,0.759,0.841,0.761,0.736,0.787,0.707,0.75,0.832,0.733,0.834,0.743,0.749,0.457,0.714,0.84,0.433,0.754,0.761,0.819,0.814,0.738,0.719,0.841,0.718,0.726,0.807,0.696,0.839,0.839,0.823,0.58,0.759,0.757,0.757,0.79,0.841,0.713,0.513,0.632,0.499,0.715,0.595,0.734,0.841,0.768,0.829,0.652,0.839,0.735,0.834,0.819,0.841,0.839,0.841,0.481,0.714,0.749,0.839,0.836,0.738,0.41,0.409,0.818,0.692,0.399,0.776,0.712,0.768,0.714,0.841,0.65,0.747,0.491,0.752,0.709,0.677,0.774,0.837,0.675,0.715,0.555,0.838,0.838,0.821,0.841,0.837,0.63,0.841,0.748,0.737,0.766,0.675,0.822,0.732,0.839,0.736,0.768,0.822,0.739,0.814,0.701,0.43,0.841,0.738,0.795,0.752,0.838,0.729,0.839,0.828,0.628,0.833,0.539,0.536,0.714,0.624,0.579,0.746,0.812,0.841,0.841,0.832,0.839,0.617,0.684,0.818,0.841,0.439,0.759,0.502,0.757,0.718,0.807,0.768,0.841,0.83,0.64,0.712,0.515,0.448,0.679,0.476,0.747,0.724,0.576,0.841,0.761,0.685,0.841,0.798,0.71,0.774,0.733,0.724,0.624,0.833,0.835,0.612,0.407,0.838,0.59,0.424,0.417,0.737,0.693,0.839,0.657,0.841,0.839,0.718,0.841,0.832,0.617,0.841,0.759,0.716,0.768,0.614,0.717,0.399,0.834,0.71,0.667,0.406,0.833,0.833,0.464,0.65,0.841,0.766,0.533,0.409,0.822,0.657,0.426,0.841,0.839,0.841,0.661,0.839,0.744,0.407,0.828,0.839,0.768,0.567,0.748,0.726,0.834,0.822,0.831,0.833,0.816,0.841,0.515,0.831,0.708,0.401,0.822,0.726,0.645,0.841,0.41,0.404,0.599,0.825,0.44,0.539,0.768,0.409,0.572,0.713,0.841,0.839,0.757,0.761,0.841,0.768,0.73,0.774,0.841,0.822,0.841,0.823,0.399,0.732,0.821,0.423,0.839,0.624,0.715,0.638,0.736,0.747,0.44,0.544,0.841,0.739,0.624,0.675,0.732,0.632,0.565,0.76,0.409,0.834,0.755,0.632,0.831,0.841,0.481,0.828,0.685,0.839,0.706,0.799,0.779,0.84,0.713,0.429,0.834,0.826,0.488,0.463,0.841,0.721,0.539,0.838,0.739,0.827,0.841,0.841,0.84,0.765,0.448,0.737,0.7,0.825,0.418,0.841,0.768,0.535,0.738,0.841,0.751,0.841,0.639,0.762,0.715,0.754,0.734,0.674,0.822,0.752,0.536,0.648,0.822,0.737,0.522,0.807,0.841,0.841,0.464,0.835,0.66,0.839,0.728,0.839,0.841,0.834,0.759,0.708,0.648,0.841,0.841,0.743,0.841,0.753,0.426,0.464,0.737,0.483,0.701,0.48,0.788,0.65,0.759,0.399,0.737,0.407,0.591,0.632,0.834,0.704,0.757,0.841,0.658,0.453,0.624,0.417,0.841,0.796,0.815,0.418,0.409,0.841,0.684,0.829,0.759,0.693,0.483,0.757,0.523,0.826,0.832,0.657,0.764,0.811,0.521,0.841,0.577,0.511,0.839,0.841,0.453,0.822,0.687,0.834,0.841,0.841,0.821,0.823,0.841,0.672,0.841,0.819,0.681,0.839,0.418,0.681,0.654,0.749,0.716,0.617,0.537,0.838,0.65,0.834,0.813,0.826,0.624,0.683,0.414,0.841,0.841,0.478,0.399,0.49,0.798,0.834,0.838,0.448,0.407,0.685,0.624,0.839,0.776,0.841,0.836,0.57,0.587,0.423,0.814,0.823,0.834,0.634,0.399,0.822,0.521,0.841,0.766,0.632,0.773,0.841,0.738,0.618,0.515,0.399,0.406,0.634,0.646,0.405,0.64,0.432,0.407,0.439,0.749,0.841,0.826,0.832,0.841,0.738,0.399,0.759,0.683,0.44,0.839,0.829,0.717,0.411,0.822,0.661,0.416,0.831,0.624,0.611,0.834,0.624,0.409,0.84,0.6,0.624,0.841,0.759,0.754,0.822,0.725,0.791,0.399,0.804,0.489,0.648,0.835,0.425,0.781,0.832,0.45,0.841,0.833,0.678,0.46,0.829,0.829,0.596,0.41,0.49,0.825,0.824,0.675,0.736,0.824,0.759,0.832,0.399,0.838,0.84,0.677,0.841,0.838,0.489,0.829,0.838,0.74,0.801,0.806,0.407,0.729,0.661,0.841,0.414,0.478,0.823,0.819,0.822,0.711,0.841,0.424,0.793,0.626,0.832,0.765,0.838,0.838,0.759,0.401,0.659,0.657,0.84,0.645,0.536,0.444,0.416,0.787,0.839,0.803,0.833,0.839,0.66,0.4,0.841,0.832,0.839,0.834,0.837,0.624,0.399,0.838,0.632,0.483,0.399,0.775,0.793,0.836,0.835,0.797,0.638,0.823,0.399,0.624,0.835,0.841,0.724,0.813,0.624,0.55,0.675,0.709,0.838,0.694,0.536,0.841,0.841,0.624,0.816,0.555,0.632,0.418,0.444,0.84,0.836,0.841,0.819,0.418,0.838,0.759,0.624,0.655,0.623,0.841,0.84,0.464,0.453,0.64,0.578,0.756,0.833,0.757,0.822,0.41,0.564,0.731,0.497,0.427,0.598,0.624,0.834,0.755,0.737,0.827,0.841,0.427,0.816,0.841,0.835,0.596,0.841,0.648,0.766,0.827,0.579,0.841,0.489,0.84,0.484,0.759,0.445,0.84,0.839,0.761,0.823,0.827,0.425,0.8,0.645,0.822,0.399,0.839,0.684,0.463,0.841,0.671,0.421,0.84,0.722,0.815,0.839,0.816,0.812,0.841,0.84,0.841,0.841,0.704,0.841,0.736,0.841,0.841,0.624,0.624,0.821,0.691,0.841,0.839,0.627,0.736,0.799,0.624,0.715,0.841,0.464,0.624,0.841,0.841,0.839,0.406,0.662,0.841,0.712,0.837,0.677,0.84,0.762,0.494,0.737,0.841,0.461,0.789,0.465,0.455,0.51,0.837,0.677,0.841,0.624,0.824,0.831,0.834,0.634,0.558,0.823,0.832,0.409,0.418,0.841,0.563,0.608,0.701,0.489,0.825,0.418,0.841,0.8,0.544,0.411,0.841,0.407,0.759,0.841,0.741,0.732,0.84,0.826,0.826,0.624,0.739,0.592,0.618,0.708,0.841,0.768,0.839,0.841,0.819,0.839,0.716,0.838,0.841,0.666,0.781,0.71,0.632,0.841,0.841,0.829,0.825,0.552,0.474,0.759,0.53,0.535,0.746,0.632,0.841,0.668,0.837,0.821,0.791,0.766,0.816,0.736,0.704,0.793,0.64,0.835,0.696,0.513,0.624,0.841,0.813,0.437,0.841,0.823,0.799,0.841,0.634,0.841,0.47,0.544,0.618,0.83,0.794,0.426,0.838,0.685,0.841,0.589,0.699,0.841,0.808,0.839,0.409,0.509,0.739,0.518,0.801,0.637,0.698,0.531,0.841,0.631,0.598,0.471,0.841,0.437,0.46,0.494,0.841,0.841,0.831,0.553,0.534,0.641,0.42,0.761,0.52,0.458,0.511,0.841,0.414,0.426,0.671,0.661,0.471,0.673,0.841,0.841,0.634,0.83,0.839,0.832,0.516,0.841,0.746,0.478,0.841,0.665,0.816,0.439,0.838,0.632,0.73,0.414,0.834,0.841,0.841,0.801,0.532,0.839,0.793,0.409,0.824,0.579,0.825,0.455,0.74,0.84,0.759,0.841,0.751,0.841,0.841,0.409,0.841,0.677,0.399,0.841,0.658,0.841,0.763,0.822,0.839,0.458,0.841,0.739,0.545,0.743,0.81,0.815,0.839,0.41,0.839,0.619,0.704,0.477,0.416,0.841,0.801,0.762,0.748,0.834,0.829,0.451,0.841,0.573,0.813,0.442,0.737,0.44,0.838,0.624,0.759,0.839,0.84,0.834,0.735,0.841,0.453,0.794,0.801,0.752,0.705,0.762,0.834,0.634,0.618,0.835,0.841,0.713,0.594,0.441,0.834,0.768,0.514,0.834,0.808,0.841,0.826,0.432,0.531,0.84,0.596,0.841,0.591,0.834,0.631,0.818,0.404,0.632,0.626,0.519,0.624,0.834,0.841,0.834,0.811,0.634,0.801,0.632,0.625,0.399,0.673,0.68,0.41,0.474,0.46,0.503,0.553,0.471,0.839,0.841,0.641,0.841,0.826,0.486,0.743,0.759,0.745,0.841,0.818,0.686,0.641,0.72,0.592,0.626,0.841,0.841,0.743,0.841,0.778,0.799,0.839,0.589,0.746,0.506,0.792,0.84,0.552,0.841,0.643,0.841,0.65,0.837,0.49,0.632,0.624,0.596,0.634,0.745,0.626,0.795,0.425,0.602,0.596,0.465,0.684,0.404,0.624,0.654,0.757,0.837,0.708,0.841,0.738,0.418,0.448,0.644,0.806,0.412,0.6,0.625,0.474,0.439,0.476,0.734,0.823,0.743,0.635,0.625,0.41,0.834,0.703,0.725,0.411,0.841,0.528,0.592,0.648,0.771,0.456,0.639,0.818,0.477,0.424,0.761,0.399,0.834,0.624,0.648,0.794,0.632,0.841,0.405,0.624,0.82,0.632,0.632,0.837,0.464,0.624,0.399,0.733,0.737,0.645,0.426,0.733,0.788,0.834,0.631,0.821,0.839,0.45,0.434,0.445,0.648,0.841,0.82,0.813,0.785,0.634,0.837,0.831,0.699,0.628,0.841,0.41,0.818,0.531,0.84,0.624,0.743,0.399,0.841,0.743,0.604,0.519,0.399,0.762,0.558,0.839,0.41,0.818,0.407,0.406,0.841,0.409,0.407,0.702,0.459,0.759,0.621,0.713,0.624,0.629,0.739,0.699,0.473,0.823,0.448,0.648,0.752,0.634,0.838,0.834,0.626,0.838,0.748,0.827,0.647,0.825,0.655,0.715,0.636,0.745,0.839,0.716,0.446,0.429,0.429,0.615,0.533,0.685,0.634,0.533,0.418,0.816,0.625,0.841,0.839,0.624,0.841,0.632,0.624,0.399,0.451,0.822,0.683,0.417,0.656,0.816,0.816,0.841,0.781,0.648,0.841,0.839,0.436,0.839,0.709,0.834,0.624,0.643,0.624,0.841,0.654,0.836,0.583,0.463,0.441,0.617,0.841,0.841,0.486,0.839,0.399,0.459,0.833,0.82,0.689,0.44,0.766,0.634,0.841,0.841,0.462,0.775,0.829,0.454,0.739,0.724,0.453,0.746,0.648,0.624,0.624,0.522,0.45,0.412,0.633,0.535,0.726,0.822,0.832,0.841,0.496,0.399,0.774,0.512,0.839,0.472,0.832,0.41,0.684,0.535,0.82,0.464,0.427,0.741,0.624,0.758,0.841,0.471,0.416,0.61,0.837,0.841,0.578,0.838,0.475,0.458,0.624,0.632,0.826,0.442,0.838,0.772,0.624,0.532,0.839,0.487,0.49,0.628,0.459,0.409,0.841,0.593,0.634,0.444,0.632,0.733,0.841,0.831,0.436,0.832,0.631,0.486,0.632,0.62,0.461,0.602,0.806,0.593,0.713,0.841,0.624,0.479,0.624,0.785,0.657,0.399,0.834,0.399,0.573,0.731,0.709,0.634,0.743,0.744,0.624,0.632,0.464,0.632,0.632,0.455,0.596,0.497,0.669,0.624,0.841,0.479,0.632,0.4,0.632,0.665,0.837,0.489,0.626,0.634,0.488,0.632,0.594,0.644,0.434,0.634,0.626,0.494,0.841,0.535,0.591,0.513,0.626,0.626,0.832,0.48,0.634,0.578,0.626,0.626,0.468,0.625,0.429,0.626,0.775,0.4,0.624,0.516,0.76,0.743,0.624,0.741,0.696,0.624,0.438,0.515,0.624,0.468,0.718,0.839,0.634,0.627,0.62,0.475,0.476,0.779,0.694,0.618,0.456,0.624,0.839,0.47,0.4,0.421,0.626,0.718,0.462,0.588,0.648,0.691,0.422,0.531,0.701,0.441,0.837,0.743,0.626,0.46,0.84,0.429,0.651,0.429,0.841,0.779,0.679,0.626,0.67,0.631,0.683,0.831,0.621,0.628,0.838,0.407,0.442,0.759,0.835,0.839,0.832,0.62,0.816,0.838,0.689,0.829,0.542,0.648,0.409,0.817,0.831,0.536,0.516,0.687,0.841,0.567,0.724,0.6,0.736,0.841,0.841,0.631,0.841,0.62,0.795,0.696,0.759,0.552,0.568,0.423,0.835,0.437,0.664,0.404,0.789,0.539,0.696,0.761,0.558,0.841,0.757,0.634,0.841,0.84,0.55,0.518,0.818,0.447,0.715,0.841,0.404,0.835,0.414,0.4,0.818,0.438,0.773,0.841,0.646,0.702,0.827,0.407,0.421,0.407,0.681,0.424,0.408,0.414,0.811,0.41,0.49,0.841,0.412,0.788,0.771,0.841,0.831,0.45,0.432,0.835,0.399,0.643,0.757,0.841,0.759,0.449,0.505,0.75,0.837,0.784,0.662,0.839,0.407,0.74,0.407,0.509,0.839,0.552,0.84,0.422,0.515,0.839,0.399,0.783,0.438,0.791,0.828,0.84,0.771,0.407,0.841,0.412,0.838,0.671,0.583,0.735,0.833,0.841,0.659,0.648,0.747,0.418,0.424,0.465,0.402,0.697,0.46,0.446,0.841,0.822,0.43,0.811,0.833,0.464,0.479,0.746,0.427,0.781,0.587,0.734,0.478,0.839,0.414,0.611,0.467,0.547,0.63,0.442,0.41,0.459,0.42,0.83,0.785,0.816,0.823,0.841,0.448,0.645,0.832,0.447,0.429,0.42,0.84,0.785,0.807,0.735,0.839,0.837,0.744,0.841,0.731,0.423,0.783,0.816,0.648,0.841,0.404,0.407,0.832,0.701,0.485,0.841,0.578,0.841,0.838,0.841,0.828,0.744,0.839,0.81,0.841,0.641,0.723,0.697,0.547,0.717,0.528,0.718,0.406,0.831,0.84,0.44,0.423,0.744,0.45,0.839,0.723,0.746,0.676,0.75,0.497,0.408,0.827,0.836,0.49,0.834,0.412,0.438,0.721,0.482,0.624,0.835,0.746,0.485,0.809,0.82,0.746,0.628,0.839,0.414,0.694,0.782,0.729,0.84,0.743,0.641,0.645,0.839,0.748,0.645,0.592,0.518,0.436,0.45,0.409,0.412,0.606,0.839,0.735,0.411,0.82,0.757,0.404,0.701,0.697,0.632,0.457,0.408,0.416,0.555,0.782,0.841,0.413,0.834,0.553,0.576,0.513,0.547,0.409,0.461,0.759,0.552,0.486,0.731,0.827,0.407,0.494,0.474,0.741,0.458,0.481,0.692,0.766,0.653,0.42,0.434,0.42,0.424,0.838,0.77,0.445,0.487,0.739,0.744,0.75,0.462,0.634,0.617,0.744,0.719,0.822,0.733,0.692,0.648,0.694,0.739,0.686,0.634,0.723,0.807,0.65,0.746,0.445,0.399,0.415,0.42,0.838,0.507,0.424,0.639,0.519,0.779,0.456,0.465,0.645,0.422,0.428,0.738,0.521,0.674,0.521,0.576,0.634,0.45,0.48,0.634,0.634,0.634,0.469,0.634,0.634,0.58,0.722,0.634,0.634,0.634,0.432,0.562,0.634,0.619,0.41,0.624,0.523,0.742,0.632,0.643,0.429,0.648,0.632,0.73,0.632,0.632,0.634,0.632,0.631,0.399,0.629,0.628,0.648,0.472,0.632,0.499,0.544,0.624,0.634,0.634,0.641,0.592,0.523,0.495,0.504,0.459,0.679,0.647,0.634,0.634,0.634,0.632,0.632,0.45,0.525,0.466,0.648,0.537,0.425,0.636,0.648,0.647,0.714,0.83,0.636,0.632,0.724,0.634,0.648,0.632,0.665,0.733,0.648,0.645,0.636,0.636,0.675,0.529,0.644,0.634,0.584,0.524,0.517,0.634,0.624,0.624,0.664,0.646,0.595,0.47,0.723,0.739,0.829,0.759,0.645,0.762,0.694,0.485,0.634,0.617,0.55,0.643,0.631,0.604,0.634,0.666,0.645,0.44,0.636,0.466,0.648,0.641,0.624,0.499,0.736,0.462,0.634,0.478,0.634,0.647,0.478,0.448,0.432,0.648,0.447,0.647,0.464,0.44,0.634,0.451,0.76,0.475,0.489,0.645,0.538,0.437,0.612,0.645,0.502,0.636,0.734,0.641,0.729,0.746,0.746,0.783,0.632,0.439,0.635,0.646,0.632,0.45,0.45,0.45,0.491,0.647,0.407,0.514,0.479,0.455,0.648,0.648,0.5,0.554,0.482,0.708,0.626,0.541,0.484,0.629,0.632,0.547,0.627,0.737,0.645,0.556,0.634,0.634,0.632,0.631,0.694,0.634,0.624,0.632,0.65,0.556,0.694,0.627,0.629,0.634,0.628,0.624,0.419,0.634,0.626,0.624,0.632,0.65,0.735,0.636,0.634,0.648,0.648,0.636,0.648,0.632,0.631,0.631,0.496,0.521,0.648,0.663,0.634,0.624,0.484,0.626,0.624,0.683,0.73,0.626,0.624,0.496,0.6,0.628,0.624,0.64,0.65,0.645,0.634,0.636,0.512,0.447,0.634,0.634,0.624,0.631,0.626,0.624,0.629,0.624,0.627,0.626,0.626,0.626,0.631,0.505,0.504,0.624,0.648,0.632,0.648,0.645,0.46,0.596,0.644,0.648,0.634,0.487,0.624,0.632,0.624,0.63,0.473,0.634,0.626,0.452,0.634,0.634,0.634,0.487,0.627,0.516,0.632,0.731,0.624,0.631,0.671,0.626,0.624,0.692,0.634,0.721,0.493,0.45,0.624,0.511,0.679,0.636,0.496,0.47,0.718,0.64,0.632,0.634,0.638,0.508,0.621,0.629,0.626,0.548,0.643,0.472,0.634,0.428,0.408,0.461,0.55,0.634,0.731,0.438,0.645,0.489,0.739,0.479,0.746,0.648,0.467,0.636,0.49,0.576,0.611,0.632,0.634,0.534,0.634,0.634,0.634,0.634,0.636,0.634,0.634,0.523,0.587,0.634,0.551,0.497,0.715,0.586,0.634,0.632,0.639,0.647,0.714,0.525,0.617,0.424,0.521,0.741,0.634,0.5,0.636,0.479,0.746,0.628,0.632,0.629,0.602,0.632,0.628,0.632,0.632,0.634,0.631,0.632,0.533,0.643,0.648,0.634,0.636,0.716,0.604,0.628,0.631,0.626,0.628,0.603,0.704,0.628,0.632,0.713,0.626,0.629,0.629,0.634,0.482,0.634,0.631,0.632,0.632,0.634,0.634,0.636,0.606,0.444,0.528,0.634,0.636,0.634,0.626,0.627,0.725,0.477,0.634,0.553,0.723,0.57,0.634,0.634,0.632,0.654,0.696,0.636,0.723,0.521,0.523,0.521,0.634,0.634,0.634,0.626,0.634,0.634,0.615,0.472,0.617,0.634,0.634,0.508,0.527,0.634,0.634,0.495,0.629,0.625,0.632,0.632,0.634,0.648,0.634,0.44,0.634,0.631,0.634,0.631,0.632,0.634,0.636,0.634,0.632,0.634,0.632,0.624,0.631,0.634,0.634,0.632,0.648,0.541,0.606,0.545,0.647,0.634,0.634,0.634,0.552,0.625,0.634,0.632,0.634,0.636,0.634,0.725,0.624,0.634,0.626,0.634,0.634,0.634,0.634,0.627,0.626,0.631,0.465,0.458,0.675,0.523,0.474,0.634,0.634,0.634,0.634,0.636,0.474,0.634,0.634,0.634,0.626,0.634,0.634,0.626,0.631,0.723,0.523,0.545,0.723,0.625,0.634,0.631,0.521,0.634,0.636,0.634,0.634,0.643,0.627,0.631,0.629,0.632,0.631,0.539,0.519,0.506,0.625,0.634,0.611,0.537,0.636,0.634,0.634,0.634,0.634,0.631,0.634,0.634,0.634,0.634,0.634,0.524,0.634,0.634,0.634,0.632,0.634,0.634,0.634,0.631,0.688,0.634,0.636,0.634,0.634,0.634,0.604,0.632,0.636,0.574,0.634,0.51,0.634,0.632,0.634'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1_txt = ''\n",
    "for prob in list(sub1.sort_values(by='unique_id')['pred'].values):\n",
    "    sub1_txt = sub1_txt+','+str(prob)\n",
    "sub1_txt = sub1_txt[1:]\n",
    "\n",
    "sub1_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdaece9",
   "metadata": {},
   "source": [
    "### Preprocessings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d35ea2",
   "metadata": {},
   "source": [
    "* Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1cf4efd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputer.fit(X_train)\n",
    "\n",
    "X_train_imp = pd.DataFrame(imputer.transform(X_train),columns=X_train.columns,index=X_train.index)\n",
    "X_val_imp = pd.DataFrame(imputer.transform(X_val),columns=X_val.columns,index=X_val.index)\n",
    "X_test_imp = pd.DataFrame(imputer.transform(X_test),columns=X_test.columns,index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7235b77",
   "metadata": {},
   "source": [
    "* Min-max scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aa1fa01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmscaler = MinMaxScaler()\n",
    "mmscaler.fit(X_train_imp)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(mmscaler.transform(X_train_imp),columns=X_train_imp.columns,index=X_train_imp.index)\n",
    "X_val_scaled = pd.DataFrame(mmscaler.transform(X_val_imp),columns=X_val_imp.columns,index=X_val_imp.index)\n",
    "X_test_scaled = pd.DataFrame(mmscaler.transform(X_test_imp),columns=X_test_imp.columns,index=X_test_imp.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a336f70",
   "metadata": {},
   "source": [
    "### Submission 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9d28864b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cidem\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=20,weights='uniform')\n",
    "knn.fit(X_train_scaled,y_train)\n",
    "\n",
    "pred_train = pd.DataFrame(knn.predict(X_train_scaled),columns=['pred'],index=X_train.index)\n",
    "pred_val = pd.DataFrame(knn.predict(X_val_scaled),columns=['pred'],index=X_val.index)\n",
    "pred_test = pd.DataFrame(knn.predict(X_test_scaled),columns=['pred'],index=X_test.index)\n",
    "\n",
    "pred_train = pd.merge(pred_train,y_train,how='left',left_index=True, right_index=True)\n",
    "pred_val = pd.merge(pred_val,y_val,how='left',left_index=True, right_index=True)\n",
    "\n",
    "roc_train = roc_auc_score(pred_train['female_label'],pred_train['pred'])\n",
    "roc_val = roc_auc_score(pred_val['female_label'],pred_val['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9bb396e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC:  0.6366143639574733\n",
      "Val ROC:  0.5936508437376191\n"
     ]
    }
   ],
   "source": [
    "print('Train ROC: ',roc_train)\n",
    "print('Val ROC: ',roc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "305b9c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred            int64\n",
       "female_label    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4547046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_rate_df = pd.DataFrame()\n",
    "\n",
    "for th in [1]:\n",
    "\n",
    "    err_rate1_train = 1-(pred_train[pred_train['female_label']==1]['pred'].sum()/pred_train[pred_train['female_label']==1]['pred'].count())\n",
    "    err_rate0_train = pred_train[pred_train['female_label']==0]['pred'].sum()/pred_train[pred_train['female_label']==0]['pred'].count()\n",
    "    err_rate_train = err_rate1_train+err_rate0_train\n",
    "\n",
    "    err_rate1_val = 1-(pred_val[pred_val['female_label']==1]['pred'].sum()/pred_val[pred_val['female_label']==1]['pred'].count())\n",
    "    err_rate0_val = pred_val[pred_val['female_label']==0]['pred'].sum()/pred_val[pred_val['female_label']==0]['pred'].count()\n",
    "    err_rate_val = err_rate1_val+err_rate0_val\n",
    "\n",
    "    err_rate_df_tmp = pd.DataFrame({'threshold':[th],\n",
    "                                    'err_rate1_train':[err_rate1_train],\n",
    "                                    'err_rate0_train':[err_rate0_train],\n",
    "                                    'err_rate_train':[err_rate_train],\n",
    "                                    'err_rate1_val':[err_rate1_val],\n",
    "                                    'err_rate0_val':[err_rate0_val],\n",
    "                                    'err_rate_val':[err_rate_val]\n",
    "                                   })\n",
    "    err_rate_df = pd.concat([err_rate_df,err_rate_df_tmp])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "de4e9adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>err_rate1_train</th>\n",
       "      <th>err_rate0_train</th>\n",
       "      <th>err_rate_train</th>\n",
       "      <th>err_rate1_val</th>\n",
       "      <th>err_rate0_val</th>\n",
       "      <th>err_rate_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.147519</td>\n",
       "      <td>0.579253</td>\n",
       "      <td>0.726771</td>\n",
       "      <td>0.189959</td>\n",
       "      <td>0.622739</td>\n",
       "      <td>0.812698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  err_rate1_train  err_rate0_train  err_rate_train  err_rate1_val  \\\n",
       "0          1         0.147519         0.579253        0.726771       0.189959   \n",
       "\n",
       "   err_rate0_val  err_rate_val  \n",
       "0       0.622739      0.812698  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_rate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "65b1a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "031ef4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id  pred\n",
       "0        108     1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test[pred_test['unique_id']==108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4922aade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2724</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>717</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>578</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>6191</td>\n",
       "      <td>2375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>6121</td>\n",
       "      <td>2376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>3245</td>\n",
       "      <td>2377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>6640</td>\n",
       "      <td>2378</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>7509</td>\n",
       "      <td>2379</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2380 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id  index  pred\n",
       "0           108      0     1\n",
       "1          2724      1     1\n",
       "2           717      2     1\n",
       "3           578      3     1\n",
       "4           147      4     1\n",
       "...         ...    ...   ...\n",
       "2375       6191   2375     1\n",
       "2376       6121   2376     1\n",
       "2377       3245   2377     1\n",
       "2378       6640   2378     1\n",
       "2379       7509   2379     1\n",
       "\n",
       "[2380 rows x 3 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub2 = pd.merge(raw_test_df,pred_test.reset_index(),how='left',on='unique_id')\n",
    "sub2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0d4bf8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2['pred'] = sub2['pred'].apply(lambda x: round(x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d36a7d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,0,1,1,1,0,1,1,1,1,0,0,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,1,0,1,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1,0,0,1,0,1,1,1,1,1,1,0,0,1,1,1,1,1,1,0,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,0,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,0,1,0,1,1,1,1,0,1,1,1,1,1,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,1,1,0,1,1,1,1,1,0,1,1,0,1,1,1,1,1,1,1,1,0,0,1,0,1,1,1,1,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,0,0,1,0,1,0,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,1,0,0,1,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,0,0,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,1,0,1,1,1,0,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,0,1,0,1,1,1,1,1,0,0,0,1,1,1,1,1,1,1,0,1,1,0,1,1,0,1,0,1,0,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,0,0,1,1,1,0,1,0,1,0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,1,0,0,0,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,0,1,1,1,0,1,1,1,1,0,1,0,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,0,1,0,1,1,1,1,1,0,0,1,0,0,1,1,1,1,1,1,1,0,1,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,0,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,0,1,1,1,1,1,1,0,0,1,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,0,1,1,1,1,1,1,0,1,0,1,0,0,0,1,1,0,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,0,1,1,1,1,1,1,0,1,0,1,1,1,1,1,0,1,0,1,1,0,1,1,0,1,1,1,1,0,1,1,1,1,1,1,0,1,1,0,1,1,1,1,0,1,1,0,0,1,1,1,1,1,0,1,1,0,1,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,1,0,1,0,1,0,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,1,0,1,1,1,0,1,1,1,1,1,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,1,0,1,1,1,0,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,1,0,1,1,1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,1,0,0,0,0,1,1,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,0,1,1,1,0,1,0,1,1,1,1,1,1,1,1,0,1,1,1,0,1,0,0,1,0,1,1,1,1,0,0,1,1,1,0,1,1,1,1,0,1,1,1,1,0,1,1,1,0,0,0,1,1,0,1,0,1,1,1,1,1,1,1,0,1,0,0,1,0,1,1,0,1,1,0,1,1,1,1,1,0,1,1,0,1,0,1,0,0,1,1,0,1,0,1,0,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,0,1,0,1,1,0,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,0,0,1,1,1,1,0,1,1,0,1,1,1,0,1,1,0,0,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,0,1,1,0,1,0,1,1,1,1,0,0,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,0,1,1,1,1,1,1,0,0,0,1,1,0,1,1,1,0,1,1,1,0,0,1,0,1,1,1,0,0,0,0,0,0,0,1,1,1,1,1,0,0,1,1,1,0,1,1,1,1,0,1,1,0,1,1,1,1,1,1,1,1,1,0,1,0,1,1,0,1,1,1,1,0,1,0,1,1,1,1,0,1,1,1,0,1,0,1,0,1,0,0,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,0,1,0,1,1,1,1,0,1,0,1,1,1,0,1,1,1,0,0,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,0,0,0,0,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,1,0,0,1,0,1,1,0,1,1,0,1,0,1,0,0,1,1,1,1,0,0,1,1,1,0,0,1,1,1,1,0,1,1,0,0,1,1,1,0,1,0,1,0,0,1,1,0,0,1,1,1,1,0,1,1,0,1,0,0,1,0,1,1,0,1,1,1,1,1,1,0,0,1,1,1,1,1,1,0,0,0,1,0,1,1,1,1,1,1,0,1,0,1,0,0,0,1,1,1,1,0,1,1,1,1,0,1,1,0,1,1,1,1,0,1,0,1,0,1,0,1,0,1,1,1,0,1,0,0,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,0,1,0,0,0,1,1,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,1,1,0,0,1,1,1,0,1,1,1,1,1,0,0,0,1,1,0,1,1,0,1,0,1,0,0,1,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,1,0,1,0,1,1,1,0,1,1,0,1,1,1,0,1,1,0,1,1,1,1,0,0,0,1,0,0,1,1,0,1,0,1,1,0,0,1,1,1,1,1,0,1,1,1,0,1,1,1,0,1,1,0,0,0,1,1,1,1,1,1,1,0,1,1,1,0,1,0,1,1,0,1,1,1,1,1,1,1,0,0,1,0,1,0,1,1,1,0,0,1,1,1,1,1,1,1,0,0,1,1,1,1,0,1,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,1,1,1,1,1,0,1,1,1,1,0,1,0,0,1,1,1,1,0,1,0,1,1,1,1,1,1,1,0,1,1,0,0,1,0,0,1,1,0,1,1,0,0,1,1,1,1,1,1,0,1,1,1,0,1,0,1,1,0,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,0,1,1,1,0,0,0,0,1,1,1,1,1'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub2_txt = ''\n",
    "for prob in list(sub2['pred'].values):\n",
    "    sub2_txt = sub2_txt+','+str(prob)\n",
    "sub2_txt = sub2_txt[1:]\n",
    "\n",
    "sub2_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc993ed0",
   "metadata": {},
   "source": [
    "* Right order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3c29f484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,0,1,1,1,1,1,1,0,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,1,0,1,1,1,1,1,0,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,1,0,0,1,1,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,0,1,1,1,1,0,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,1,1,0,1,1,1,1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,0,1,0,1,1,1,1,0,1,1,0,1,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,0,1,1,1,1,1,0,0,1,0,1,1,1,0,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,1,0,1,1,0,1,0,1,0,1,1,1,1,0,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,0,1,1,0,1,1,0,1,0,0,1,1,1,1,0,0,0,1,0,1,0,1,1,1,0,1,1,1,0,1,1,1,1,1,0,1,1,1,0,0,1,1,0,0,1,0,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,0,1,0,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,1,0,0,0,1,0,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1,1,1,0,1,1,1,1,1,0,1,1,0,1,1,1,0,0,1,1,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,0,0,0,0,1,1,1,0,1,1,1,1,1,0,0,0,1,1,0,1,0,1,1,1,0,1,1,0,1,1,1,1,1,1,1,1,1,0,0,1,1,1,0,1,1,1,1,1,0,1,1,1,1,0,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,0,1,0,0,0,0,1,1,0,1,1,1,1,1,1,1,1,1,0,1,0,0,0,0,1,0,1,1,1,0,1,0,1,1,1,1,0,0,1,0,1,1,0,0,1,0,0,1,1,0,1,1,1,0,1,1,0,0,1,1,0,1,1,1,1,0,1,1,0,1,1,0,1,1,1,1,1,1,0,1,0,1,0,1,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,0,1,0,0,1,1,0,1,0,1,1,1,1,1,1,1,1,0,0,0,1,1,0,1,1,1,0,0,0,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,0,1,1,1,0,1,0,1,1,1,1,1,1,0,1,1,0,1,0,0,0,1,0,0,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,1,0,0,1,1,1,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,1,1,0,0,1,0,1,0,0,0,0,1,0,1,1,1,1,1,0,1,1,1,1,0,1,0,1,1,0,1,0,0,1,0,1,1,0,1,1,1,0,1,1,1,0,0,0,0,0,0,0,0,1,0,1,0,0,1,1,1,0,0,0,1,1,1,1,1,0,1,1,0,0,1,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,0,1,0,1,1,0,0,1,0,0,1,1,1,1,1,1,1,0,1,1,1,0,1,1,1,1,0,0,0,0,1,1,1,1,1,1,0,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,0,0,0,0,1,0,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,0,1,1,0,0,0,1,1,0,1,0,1,1,1,1,1,1,0,1,0,1,0,1,1,1,0,1,1,1,1,1,1,0,1,1,0,0,1,1,0,1,1,1,1,1,0,1,0,1,1,1,0,1,1,1,1,1,1,0,1,0,1,1,0,1,1,0,0,0,1,1,1,0,0,1,1,1,1,0,1,1,0,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,0,1,0,1,1,1,0,0,1,0,1,1,0,0,0,0,1,0,0,1,1,0,1,1,0,1,1,0,1,0,0,1,1,0,1,1,0,0,1,0,1,1,0,0,1,0,0,0,1,1,0,0,0,1,0,1,1,1,0,1,0,1,1,0,0,0,1,0,0,1,0,1,0,0,0,1,0,1,1,1,0,1,1,1,1,1,0,1,1,1,0,1,0,0,1,0,0,0,1,1,1,0,0,1,1,1,1,0,1,0,1,1,0,1,1,0,1,0,1,1,0,0,1,1,0,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,0,0,0,1,1,0,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,0,0,0,0,1,1,0,1,0,1,0,1,1,1,1,1,1,0,0,1,0,1,1,1,0,1,1,1,1,0,0,1,1,1,1,0,0,0,1,1,1,1,0,1,1,0,1,0,0,0,1,0,1,0,1,1,0,1,1,0,0,1,1,1,0,0,1,0,0,1,1,1,0,1,1,0,1,1,0,0,1,1,1,0,0,0,1,1,1,0,1,0,1,0,1,0,0,0,0,0,1,1,1,1,1,1,0,0,1,1,1,1,1,0,0,1,0,1,1,0,0,1,0,1,1,0,0,1,0,1,0,0,1,1,1,0,0,1,1,0,1,1,0,0,1,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,0,1,1,1,0,1,0,1,1,0,1,1,1,1,1,0,0,1,1,1,1,1,0,0,1,1,0,1,0,0,0,1,1,1,1,1,0,0,1,0,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,0,1,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,0,1,1,0,1,1'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub2_txt = ''\n",
    "for prob in list(sub2.sort_values(by='unique_id')['pred'].values):\n",
    "    sub2_txt = sub2_txt+','+str(prob)\n",
    "sub2_txt = sub2_txt[1:]\n",
    "\n",
    "sub2_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135ff51f",
   "metadata": {},
   "source": [
    "### Submission 5 - Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb022f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female_label    2942\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45b24b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female_label    4494\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "157b13ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female_label    0.654651\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum()/y_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59ff1f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1552"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_train.count()-y_train.sum()).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f3b5e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_0 = y_train[y_train['female_label']==0]\n",
    "y_train_1 = y_train[y_train['female_label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4670cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-ec372bfd3f46>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_train_1['rand'] = np.random.rand(y_train_1.shape[0])\n"
     ]
    }
   ],
   "source": [
    "y_train_1['rand'] = np.random.rand(y_train_1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5035d7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cidem\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "y_train_1.sort_values(by='rand',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7d08ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_1 = y_train_1.head((y_train.count()-y_train.sum()).values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec401679",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_under = pd.concat([y_train_1[['female_label']],y_train_0])\n",
    "y_train_under.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "486ef5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3104"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(y_train_under.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "419801f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_under = X_train[X_train.index.isin(list(y_train_under.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a80f33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cidem\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py:6393: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().sort_index(\n"
     ]
    }
   ],
   "source": [
    "X_train_under.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a395d3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cidem\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(max_depth=2,learning_rate=0.01,n_estimators=100,min_child_samples=100,colsample_bytree=0.5)\n",
    "lgbm.fit(X_train_under,y_train_under)\n",
    "\n",
    "pred_train = pd.DataFrame(lgbm.predict_proba(X_train)[:,1],columns=['pred'],index=X_train.index)\n",
    "pred_val = pd.DataFrame(lgbm.predict_proba(X_val)[:,1],columns=['pred'],index=X_val.index)\n",
    "pred_test = pd.DataFrame(lgbm.predict_proba(X_test)[:,1],columns=['pred'],index=X_test.index)\n",
    "\n",
    "pred_train = pd.merge(pred_train,y_train,how='left',left_index=True, right_index=True)\n",
    "pred_val = pd.merge(pred_val,y_val,how='left',left_index=True, right_index=True)\n",
    "\n",
    "roc_train = roc_auc_score(pred_train['female_label'],pred_train['pred'])\n",
    "roc_val = roc_auc_score(pred_val['female_label'],pred_val['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "805175de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC:  0.8555797611204944\n",
      "Val ROC:  0.8452995768164113\n"
     ]
    }
   ],
   "source": [
    "print('Train ROC: ',roc_train)\n",
    "print('Val ROC: ',roc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3adb7d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_rate_df = pd.DataFrame()\n",
    "\n",
    "for th in np.arange(0,1,0.1):\n",
    "\n",
    "    pred_train['pred_binary'] = np.where(pred_train['pred']>=th,1,0)\n",
    "    pred_val['pred_binary'] = np.where(pred_val['pred']>=th,1,0)\n",
    "\n",
    "    err_rate1_train = 1-(pred_train[pred_train['female_label']==1]['pred_binary'].sum()/pred_train[pred_train['female_label']==1]['pred_binary'].count())\n",
    "    err_rate0_train = pred_train[pred_train['female_label']==0]['pred_binary'].sum()/pred_train[pred_train['female_label']==0]['pred_binary'].count()\n",
    "    err_rate_train = err_rate1_train+err_rate0_train\n",
    "\n",
    "    err_rate1_val = 1-(pred_val[pred_val['female_label']==1]['pred_binary'].sum()/pred_val[pred_val['female_label']==1]['pred_binary'].count())\n",
    "    err_rate0_val = pred_val[pred_val['female_label']==0]['pred_binary'].sum()/pred_val[pred_val['female_label']==0]['pred_binary'].count()\n",
    "    err_rate_val = err_rate1_val+err_rate0_val\n",
    "\n",
    "    err_rate_df_tmp = pd.DataFrame({'threshold':[th],\n",
    "                                    'err_rate1_train':[err_rate1_train],\n",
    "                                    'err_rate0_train':[err_rate0_train],\n",
    "                                    'err_rate_train':[err_rate_train],\n",
    "                                    'err_rate1_val':[err_rate1_val],\n",
    "                                    'err_rate0_val':[err_rate0_val],\n",
    "                                    'err_rate_val':[err_rate_val]\n",
    "                                   })\n",
    "    err_rate_df = pd.concat([err_rate_df,err_rate_df_tmp])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "12dcbf3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>err_rate1_train</th>\n",
       "      <th>err_rate0_train</th>\n",
       "      <th>err_rate_train</th>\n",
       "      <th>err_rate1_val</th>\n",
       "      <th>err_rate0_val</th>\n",
       "      <th>err_rate_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.017335</td>\n",
       "      <td>0.858892</td>\n",
       "      <td>0.876227</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.898646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.116927</td>\n",
       "      <td>0.449742</td>\n",
       "      <td>0.566670</td>\n",
       "      <td>0.127544</td>\n",
       "      <td>0.478036</td>\n",
       "      <td>0.605580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.325629</td>\n",
       "      <td>0.110180</td>\n",
       "      <td>0.435809</td>\n",
       "      <td>0.331072</td>\n",
       "      <td>0.103359</td>\n",
       "      <td>0.434431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.471788</td>\n",
       "      <td>0.046392</td>\n",
       "      <td>0.518180</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.553974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.633923</td>\n",
       "      <td>0.012242</td>\n",
       "      <td>0.646165</td>\n",
       "      <td>0.662144</td>\n",
       "      <td>0.020672</td>\n",
       "      <td>0.682816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  err_rate1_train  err_rate0_train  err_rate_train  err_rate1_val  \\\n",
       "0        0.0         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.1         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.2         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.3         0.017335         0.858892        0.876227       0.014925   \n",
       "0        0.4         0.116927         0.449742        0.566670       0.127544   \n",
       "0        0.5         0.325629         0.110180        0.435809       0.331072   \n",
       "0        0.6         0.471788         0.046392        0.518180       0.507463   \n",
       "0        0.7         0.633923         0.012242        0.646165       0.662144   \n",
       "0        0.8         1.000000         0.000000        1.000000       1.000000   \n",
       "0        0.9         1.000000         0.000000        1.000000       1.000000   \n",
       "\n",
       "   err_rate0_val  err_rate_val  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       0.883721      0.898646  \n",
       "0       0.478036      0.605580  \n",
       "0       0.103359      0.434431  \n",
       "0       0.046512      0.553974  \n",
       "0       0.020672      0.682816  \n",
       "0       0.000000      1.000000  \n",
       "0       0.000000      1.000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_rate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1110e5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.579206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>0.688762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>0.628206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>0.736456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.550859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6191</th>\n",
       "      <td>0.479936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6121</th>\n",
       "      <td>0.478385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0.458107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6640</th>\n",
       "      <td>0.473278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7509</th>\n",
       "      <td>0.479936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2380 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred\n",
       "unique_id          \n",
       "108        0.579206\n",
       "2724       0.688762\n",
       "717        0.628206\n",
       "578        0.736456\n",
       "147        0.550859\n",
       "...             ...\n",
       "6191       0.479936\n",
       "6121       0.478385\n",
       "3245       0.458107\n",
       "6640       0.473278\n",
       "7509       0.479936\n",
       "\n",
       "[2380 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4db3dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c46a0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>0.579206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id      pred\n",
       "0        108  0.579206"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test[pred_test['unique_id']==108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1849de47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.579206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2724</td>\n",
       "      <td>1</td>\n",
       "      <td>0.688762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>717</td>\n",
       "      <td>2</td>\n",
       "      <td>0.628206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>578</td>\n",
       "      <td>3</td>\n",
       "      <td>0.736456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147</td>\n",
       "      <td>4</td>\n",
       "      <td>0.550859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>6191</td>\n",
       "      <td>2375</td>\n",
       "      <td>0.479936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>6121</td>\n",
       "      <td>2376</td>\n",
       "      <td>0.478385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>3245</td>\n",
       "      <td>2377</td>\n",
       "      <td>0.458107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>6640</td>\n",
       "      <td>2378</td>\n",
       "      <td>0.473278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>7509</td>\n",
       "      <td>2379</td>\n",
       "      <td>0.479936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2380 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id  index      pred\n",
       "0           108      0  0.579206\n",
       "1          2724      1  0.688762\n",
       "2           717      2  0.628206\n",
       "3           578      3  0.736456\n",
       "4           147      4  0.550859\n",
       "...         ...    ...       ...\n",
       "2375       6191   2375  0.479936\n",
       "2376       6121   2376  0.478385\n",
       "2377       3245   2377  0.458107\n",
       "2378       6640   2378  0.473278\n",
       "2379       7509   2379  0.479936\n",
       "\n",
       "[2380 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub5 = pd.merge(raw_test_df,pred_test.reset_index(),how='left',on='unique_id')\n",
    "sub5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5919de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub5['pred'] = sub5['pred'].apply(lambda x: round(x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c76b428a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>9</td>\n",
       "      <td>612</td>\n",
       "      <td>0.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>18</td>\n",
       "      <td>203</td>\n",
       "      <td>0.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>21</td>\n",
       "      <td>186</td>\n",
       "      <td>0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>25</td>\n",
       "      <td>92</td>\n",
       "      <td>0.606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>31</td>\n",
       "      <td>39</td>\n",
       "      <td>0.619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>7982</td>\n",
       "      <td>1266</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>7990</td>\n",
       "      <td>1222</td>\n",
       "      <td>0.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>7993</td>\n",
       "      <td>1610</td>\n",
       "      <td>0.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>7994</td>\n",
       "      <td>1559</td>\n",
       "      <td>0.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>7998</td>\n",
       "      <td>1575</td>\n",
       "      <td>0.480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2380 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id  index   pred\n",
       "612           9    612  0.621\n",
       "203          18    203  0.610\n",
       "186          21    186  0.549\n",
       "92           25     92  0.606\n",
       "39           31     39  0.619\n",
       "...         ...    ...    ...\n",
       "1266       7982   1266  0.485\n",
       "1222       7990   1222  0.335\n",
       "1610       7993   1610  0.480\n",
       "1559       7994   1559  0.480\n",
       "1575       7998   1575  0.480\n",
       "\n",
       "[2380 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub5.sort_values(by='unique_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e110f923",
   "metadata": {},
   "source": [
    "* Right order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da83b22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.621,0.61,0.549,0.606,0.619,0.768,0.543,0.316,0.514,0.549,0.452,0.43,0.72,0.768,0.543,0.63,0.488,0.342,0.545,0.75,0.744,0.667,0.646,0.621,0.658,0.644,0.712,0.694,0.579,0.597,0.68,0.614,0.553,0.683,0.752,0.626,0.501,0.565,0.761,0.609,0.551,0.724,0.75,0.703,0.737,0.7,0.75,0.52,0.625,0.748,0.289,0.768,0.688,0.309,0.3,0.301,0.762,0.699,0.768,0.626,0.689,0.684,0.451,0.644,0.768,0.662,0.751,0.629,0.626,0.768,0.651,0.56,0.672,0.56,0.61,0.746,0.608,0.743,0.584,0.624,0.321,0.561,0.768,0.31,0.616,0.63,0.738,0.702,0.592,0.61,0.768,0.573,0.615,0.71,0.535,0.764,0.757,0.729,0.442,0.644,0.647,0.64,0.717,0.766,0.555,0.357,0.477,0.347,0.564,0.449,0.559,0.768,0.656,0.76,0.511,0.754,0.619,0.756,0.711,0.763,0.764,0.768,0.335,0.536,0.644,0.757,0.758,0.621,0.305,0.293,0.723,0.554,0.289,0.682,0.578,0.638,0.569,0.766,0.506,0.636,0.388,0.606,0.563,0.543,0.611,0.764,0.545,0.572,0.426,0.76,0.763,0.7,0.766,0.76,0.521,0.763,0.594,0.566,0.636,0.543,0.71,0.585,0.762,0.635,0.656,0.712,0.586,0.73,0.558,0.304,0.768,0.617,0.669,0.611,0.76,0.549,0.76,0.736,0.481,0.728,0.451,0.403,0.564,0.47,0.435,0.594,0.722,0.768,0.768,0.734,0.762,0.501,0.545,0.733,0.766,0.317,0.626,0.331,0.644,0.584,0.692,0.669,0.768,0.747,0.515,0.553,0.355,0.303,0.552,0.385,0.633,0.617,0.416,0.768,0.628,0.555,0.766,0.676,0.621,0.636,0.65,0.631,0.47,0.755,0.758,0.452,0.312,0.758,0.42,0.291,0.31,0.619,0.561,0.764,0.501,0.768,0.764,0.607,0.768,0.755,0.453,0.768,0.649,0.56,0.656,0.519,0.555,0.289,0.727,0.596,0.507,0.302,0.73,0.746,0.365,0.506,0.768,0.646,0.366,0.303,0.72,0.545,0.291,0.768,0.764,0.766,0.508,0.764,0.653,0.306,0.736,0.746,0.656,0.46,0.626,0.615,0.753,0.71,0.761,0.741,0.707,0.768,0.395,0.761,0.543,0.293,0.713,0.569,0.496,0.757,0.289,0.295,0.446,0.738,0.304,0.43,0.656,0.302,0.427,0.57,0.768,0.764,0.624,0.628,0.768,0.656,0.556,0.681,0.768,0.728,0.768,0.748,0.297,0.556,0.71,0.311,0.764,0.47,0.591,0.485,0.62,0.635,0.304,0.44,0.766,0.593,0.47,0.543,0.633,0.477,0.4,0.6,0.302,0.74,0.608,0.477,0.748,0.766,0.368,0.732,0.555,0.762,0.543,0.695,0.661,0.768,0.58,0.314,0.746,0.753,0.385,0.327,0.763,0.565,0.426,0.748,0.561,0.747,0.768,0.768,0.768,0.638,0.31,0.566,0.536,0.717,0.307,0.768,0.664,0.43,0.616,0.76,0.608,0.768,0.459,0.665,0.566,0.616,0.632,0.573,0.712,0.632,0.4,0.501,0.709,0.568,0.37,0.71,0.768,0.766,0.36,0.743,0.467,0.762,0.576,0.764,0.766,0.756,0.65,0.543,0.501,0.768,0.768,0.631,0.768,0.658,0.311,0.368,0.588,0.339,0.528,0.329,0.691,0.501,0.64,0.289,0.579,0.303,0.44,0.552,0.756,0.559,0.644,0.766,0.499,0.327,0.47,0.3,0.768,0.69,0.705,0.302,0.302,0.768,0.574,0.751,0.621,0.572,0.365,0.624,0.387,0.762,0.748,0.538,0.696,0.687,0.381,0.768,0.44,0.345,0.762,0.768,0.304,0.744,0.573,0.754,0.768,0.768,0.741,0.746,0.768,0.523,0.768,0.717,0.553,0.764,0.297,0.553,0.501,0.612,0.603,0.496,0.43,0.76,0.48,0.737,0.722,0.736,0.472,0.553,0.298,0.761,0.768,0.374,0.289,0.337,0.714,0.762,0.748,0.366,0.302,0.556,0.47,0.757,0.648,0.768,0.76,0.463,0.426,0.31,0.733,0.747,0.756,0.48,0.289,0.712,0.375,0.768,0.636,0.477,0.664,0.755,0.626,0.453,0.394,0.289,0.306,0.48,0.501,0.297,0.492,0.32,0.299,0.316,0.583,0.768,0.741,0.755,0.768,0.616,0.297,0.647,0.552,0.35,0.764,0.736,0.554,0.302,0.724,0.553,0.295,0.749,0.47,0.452,0.754,0.47,0.305,0.761,0.463,0.47,0.768,0.644,0.621,0.713,0.565,0.71,0.301,0.647,0.347,0.501,0.757,0.337,0.628,0.754,0.327,0.766,0.758,0.565,0.314,0.743,0.747,0.45,0.302,0.37,0.705,0.737,0.543,0.613,0.704,0.65,0.755,0.289,0.748,0.768,0.543,0.768,0.76,0.343,0.742,0.75,0.596,0.715,0.715,0.298,0.614,0.55,0.768,0.302,0.343,0.711,0.726,0.712,0.553,0.761,0.295,0.696,0.47,0.741,0.633,0.754,0.76,0.647,0.293,0.509,0.477,0.757,0.52,0.41,0.306,0.291,0.693,0.748,0.711,0.764,0.764,0.531,0.289,0.768,0.722,0.762,0.728,0.741,0.47,0.289,0.748,0.477,0.32,0.289,0.676,0.68,0.758,0.754,0.672,0.501,0.749,0.289,0.47,0.742,0.757,0.618,0.689,0.47,0.4,0.545,0.566,0.758,0.58,0.395,0.753,0.757,0.475,0.713,0.42,0.48,0.293,0.296,0.768,0.76,0.768,0.715,0.3,0.758,0.646,0.47,0.509,0.488,0.768,0.766,0.361,0.309,0.489,0.425,0.609,0.746,0.64,0.741,0.305,0.378,0.594,0.348,0.336,0.467,0.47,0.756,0.625,0.598,0.704,0.768,0.302,0.681,0.766,0.754,0.429,0.768,0.501,0.651,0.742,0.432,0.768,0.392,0.768,0.325,0.644,0.299,0.766,0.764,0.646,0.713,0.744,0.316,0.678,0.501,0.712,0.289,0.762,0.568,0.32,0.768,0.525,0.306,0.766,0.591,0.702,0.764,0.706,0.7,0.757,0.768,0.768,0.768,0.6,0.763,0.62,0.755,0.766,0.47,0.478,0.715,0.534,0.761,0.764,0.498,0.571,0.689,0.47,0.612,0.768,0.363,0.47,0.766,0.768,0.751,0.302,0.511,0.768,0.553,0.737,0.579,0.768,0.651,0.348,0.638,0.768,0.306,0.636,0.32,0.317,0.358,0.76,0.543,0.766,0.47,0.716,0.719,0.756,0.492,0.411,0.717,0.756,0.302,0.295,0.757,0.445,0.481,0.552,0.363,0.727,0.311,0.763,0.694,0.404,0.302,0.755,0.298,0.612,0.768,0.572,0.559,0.757,0.753,0.753,0.47,0.576,0.479,0.496,0.543,0.768,0.656,0.764,0.763,0.74,0.762,0.578,0.766,0.762,0.558,0.684,0.542,0.477,0.768,0.751,0.762,0.739,0.433,0.318,0.64,0.379,0.43,0.589,0.477,0.768,0.522,0.763,0.749,0.701,0.651,0.703,0.617,0.603,0.662,0.501,0.743,0.585,0.343,0.472,0.768,0.697,0.312,0.763,0.721,0.689,0.768,0.48,0.768,0.312,0.421,0.455,0.744,0.683,0.315,0.765,0.599,0.766,0.473,0.549,0.768,0.724,0.764,0.302,0.355,0.55,0.345,0.705,0.468,0.556,0.413,0.768,0.473,0.385,0.331,0.768,0.302,0.314,0.345,0.768,0.768,0.75,0.432,0.419,0.489,0.289,0.646,0.376,0.31,0.345,0.761,0.293,0.309,0.517,0.544,0.332,0.536,0.768,0.768,0.485,0.734,0.764,0.742,0.348,0.766,0.592,0.363,0.755,0.564,0.702,0.317,0.765,0.477,0.547,0.291,0.754,0.768,0.768,0.712,0.41,0.764,0.686,0.299,0.714,0.453,0.737,0.301,0.623,0.757,0.644,0.761,0.606,0.768,0.766,0.302,0.768,0.549,0.289,0.768,0.498,0.763,0.638,0.746,0.741,0.329,0.768,0.622,0.377,0.627,0.697,0.731,0.718,0.289,0.754,0.473,0.55,0.322,0.308,0.768,0.712,0.665,0.631,0.754,0.732,0.327,0.768,0.463,0.697,0.304,0.61,0.304,0.748,0.47,0.64,0.759,0.768,0.748,0.602,0.768,0.327,0.718,0.698,0.638,0.61,0.665,0.762,0.48,0.489,0.742,0.758,0.553,0.439,0.311,0.758,0.655,0.385,0.738,0.669,0.768,0.727,0.299,0.405,0.768,0.458,0.768,0.461,0.754,0.477,0.725,0.295,0.477,0.47,0.356,0.47,0.746,0.768,0.742,0.704,0.48,0.692,0.477,0.478,0.289,0.502,0.548,0.305,0.314,0.304,0.398,0.4,0.32,0.764,0.757,0.496,0.768,0.753,0.355,0.629,0.631,0.621,0.766,0.74,0.519,0.494,0.582,0.47,0.473,0.766,0.761,0.656,0.768,0.643,0.714,0.744,0.479,0.578,0.377,0.681,0.768,0.44,0.761,0.524,0.768,0.5,0.737,0.318,0.477,0.47,0.445,0.48,0.625,0.473,0.657,0.311,0.466,0.458,0.331,0.522,0.298,0.47,0.543,0.65,0.764,0.537,0.766,0.626,0.302,0.31,0.501,0.688,0.302,0.463,0.421,0.323,0.313,0.318,0.561,0.749,0.627,0.474,0.476,0.305,0.752,0.553,0.574,0.306,0.768,0.369,0.461,0.501,0.678,0.31,0.484,0.716,0.333,0.303,0.666,0.289,0.756,0.47,0.501,0.675,0.477,0.768,0.295,0.47,0.689,0.477,0.477,0.768,0.316,0.47,0.289,0.608,0.609,0.501,0.31,0.593,0.701,0.754,0.499,0.741,0.764,0.312,0.317,0.307,0.501,0.768,0.704,0.704,0.692,0.478,0.766,0.723,0.553,0.475,0.763,0.301,0.718,0.354,0.752,0.47,0.627,0.289,0.766,0.631,0.44,0.373,0.289,0.667,0.451,0.743,0.289,0.74,0.306,0.302,0.766,0.308,0.296,0.601,0.31,0.635,0.473,0.619,0.475,0.484,0.62,0.541,0.339,0.728,0.322,0.504,0.611,0.48,0.765,0.758,0.47,0.765,0.65,0.722,0.501,0.716,0.501,0.555,0.496,0.653,0.762,0.583,0.314,0.304,0.31,0.483,0.385,0.518,0.48,0.39,0.289,0.705,0.473,0.766,0.741,0.47,0.768,0.477,0.47,0.293,0.304,0.745,0.553,0.304,0.488,0.701,0.703,0.766,0.642,0.501,0.766,0.735,0.3,0.752,0.551,0.739,0.47,0.501,0.47,0.766,0.525,0.76,0.431,0.334,0.304,0.456,0.768,0.768,0.322,0.737,0.289,0.328,0.752,0.745,0.579,0.316,0.65,0.48,0.768,0.768,0.327,0.685,0.746,0.309,0.627,0.599,0.322,0.617,0.501,0.47,0.47,0.36,0.315,0.302,0.482,0.43,0.61,0.737,0.754,0.757,0.347,0.289,0.64,0.346,0.762,0.324,0.756,0.289,0.568,0.383,0.707,0.316,0.307,0.613,0.47,0.642,0.768,0.323,0.291,0.469,0.735,0.768,0.453,0.757,0.319,0.327,0.47,0.477,0.753,0.31,0.748,0.667,0.47,0.378,0.743,0.343,0.347,0.47,0.327,0.303,0.768,0.408,0.482,0.306,0.482,0.602,0.766,0.727,0.291,0.746,0.473,0.347,0.482,0.474,0.314,0.398,0.712,0.445,0.622,0.768,0.47,0.317,0.47,0.696,0.488,0.29,0.752,0.293,0.467,0.596,0.586,0.48,0.627,0.615,0.47,0.477,0.316,0.477,0.477,0.314,0.45,0.336,0.543,0.47,0.755,0.318,0.477,0.289,0.477,0.532,0.764,0.343,0.473,0.48,0.337,0.477,0.391,0.496,0.305,0.482,0.472,0.356,0.766,0.418,0.406,0.343,0.473,0.47,0.756,0.329,0.482,0.465,0.472,0.473,0.363,0.467,0.304,0.473,0.641,0.289,0.47,0.361,0.646,0.615,0.47,0.612,0.583,0.47,0.305,0.414,0.47,0.365,0.581,0.754,0.478,0.473,0.475,0.33,0.33,0.649,0.58,0.489,0.327,0.47,0.737,0.318,0.293,0.302,0.473,0.577,0.312,0.394,0.501,0.521,0.31,0.418,0.541,0.323,0.761,0.634,0.473,0.322,0.768,0.304,0.496,0.313,0.766,0.647,0.535,0.473,0.541,0.472,0.508,0.754,0.447,0.472,0.765,0.295,0.31,0.635,0.723,0.762,0.723,0.468,0.721,0.76,0.553,0.719,0.387,0.501,0.302,0.724,0.756,0.377,0.351,0.56,0.768,0.434,0.545,0.438,0.612,0.768,0.766,0.475,0.766,0.489,0.69,0.58,0.635,0.44,0.377,0.303,0.758,0.312,0.501,0.293,0.68,0.383,0.585,0.663,0.383,0.766,0.64,0.48,0.766,0.766,0.427,0.354,0.733,0.305,0.557,0.757,0.295,0.759,0.291,0.299,0.711,0.311,0.686,0.768,0.496,0.603,0.735,0.298,0.291,0.298,0.555,0.304,0.297,0.298,0.732,0.313,0.385,0.768,0.29,0.659,0.646,0.755,0.761,0.317,0.309,0.703,0.289,0.501,0.635,0.768,0.631,0.319,0.365,0.646,0.754,0.673,0.511,0.76,0.295,0.615,0.299,0.343,0.762,0.421,0.766,0.304,0.43,0.739,0.297,0.694,0.324,0.694,0.739,0.75,0.644,0.295,0.768,0.298,0.758,0.536,0.442,0.639,0.73,0.768,0.51,0.501,0.645,0.295,0.305,0.321,0.289,0.547,0.314,0.313,0.763,0.723,0.312,0.698,0.757,0.314,0.335,0.647,0.292,0.687,0.399,0.629,0.316,0.75,0.302,0.406,0.319,0.407,0.503,0.312,0.289,0.318,0.297,0.721,0.687,0.711,0.696,0.768,0.31,0.504,0.755,0.316,0.314,0.289,0.768,0.692,0.699,0.602,0.749,0.741,0.625,0.766,0.597,0.289,0.687,0.679,0.501,0.761,0.29,0.295,0.755,0.534,0.322,0.768,0.456,0.768,0.744,0.768,0.729,0.621,0.744,0.715,0.768,0.501,0.587,0.523,0.407,0.577,0.363,0.609,0.299,0.737,0.745,0.306,0.313,0.615,0.313,0.744,0.587,0.615,0.565,0.629,0.349,0.296,0.735,0.743,0.319,0.741,0.302,0.311,0.612,0.323,0.47,0.75,0.615,0.326,0.701,0.732,0.615,0.475,0.739,0.295,0.58,0.692,0.595,0.757,0.622,0.501,0.523,0.747,0.615,0.501,0.479,0.4,0.291,0.306,0.302,0.29,0.466,0.752,0.602,0.295,0.727,0.637,0.295,0.627,0.554,0.456,0.307,0.296,0.297,0.388,0.692,0.768,0.292,0.733,0.451,0.395,0.407,0.398,0.302,0.306,0.66,0.393,0.397,0.599,0.732,0.296,0.343,0.324,0.627,0.323,0.342,0.556,0.666,0.488,0.296,0.307,0.302,0.306,0.746,0.66,0.299,0.343,0.612,0.615,0.667,0.335,0.482,0.41,0.615,0.584,0.723,0.602,0.585,0.501,0.58,0.608,0.543,0.48,0.587,0.701,0.506,0.615,0.302,0.29,0.3,0.296,0.759,0.401,0.293,0.494,0.354,0.659,0.304,0.318,0.496,0.291,0.305,0.62,0.35,0.575,0.35,0.395,0.48,0.31,0.337,0.485,0.48,0.48,0.323,0.48,0.48,0.394,0.586,0.48,0.48,0.48,0.299,0.411,0.48,0.483,0.289,0.47,0.368,0.651,0.48,0.501,0.304,0.501,0.477,0.611,0.477,0.478,0.48,0.477,0.475,0.289,0.477,0.475,0.501,0.32,0.477,0.322,0.422,0.47,0.48,0.48,0.496,0.422,0.353,0.344,0.357,0.312,0.533,0.496,0.48,0.48,0.48,0.478,0.477,0.311,0.354,0.316,0.501,0.361,0.308,0.501,0.501,0.501,0.574,0.745,0.485,0.477,0.617,0.48,0.501,0.478,0.505,0.593,0.501,0.501,0.501,0.483,0.516,0.373,0.501,0.485,0.463,0.35,0.374,0.48,0.47,0.47,0.55,0.496,0.424,0.314,0.587,0.627,0.742,0.627,0.501,0.665,0.58,0.343,0.48,0.456,0.391,0.504,0.477,0.465,0.48,0.506,0.501,0.307,0.485,0.306,0.501,0.501,0.47,0.341,0.591,0.313,0.48,0.323,0.48,0.501,0.337,0.31,0.297,0.501,0.305,0.501,0.317,0.304,0.48,0.309,0.653,0.322,0.359,0.501,0.381,0.31,0.472,0.501,0.352,0.485,0.602,0.501,0.628,0.615,0.617,0.692,0.482,0.304,0.483,0.506,0.477,0.313,0.311,0.309,0.352,0.501,0.301,0.358,0.323,0.311,0.501,0.501,0.326,0.388,0.336,0.586,0.47,0.376,0.318,0.47,0.477,0.433,0.473,0.602,0.496,0.381,0.48,0.48,0.477,0.48,0.58,0.482,0.46,0.478,0.506,0.442,0.58,0.473,0.477,0.48,0.475,0.47,0.298,0.48,0.472,0.47,0.477,0.501,0.602,0.485,0.48,0.501,0.501,0.485,0.501,0.477,0.48,0.48,0.345,0.351,0.501,0.55,0.48,0.47,0.33,0.47,0.47,0.562,0.607,0.473,0.47,0.345,0.458,0.47,0.47,0.501,0.501,0.501,0.48,0.483,0.348,0.333,0.48,0.482,0.47,0.48,0.472,0.47,0.472,0.475,0.472,0.472,0.472,0.472,0.48,0.345,0.339,0.47,0.501,0.48,0.501,0.501,0.314,0.455,0.501,0.501,0.478,0.339,0.47,0.477,0.47,0.475,0.324,0.478,0.473,0.318,0.478,0.478,0.48,0.326,0.473,0.351,0.477,0.561,0.47,0.478,0.525,0.473,0.47,0.534,0.48,0.584,0.352,0.302,0.47,0.352,0.534,0.485,0.318,0.316,0.574,0.501,0.477,0.48,0.501,0.332,0.473,0.473,0.473,0.367,0.501,0.327,0.48,0.305,0.297,0.326,0.381,0.48,0.599,0.313,0.496,0.326,0.612,0.352,0.615,0.504,0.317,0.485,0.337,0.395,0.401,0.484,0.48,0.363,0.48,0.48,0.48,0.48,0.485,0.48,0.48,0.359,0.44,0.48,0.388,0.325,0.534,0.399,0.48,0.484,0.496,0.501,0.583,0.373,0.456,0.297,0.354,0.609,0.48,0.346,0.496,0.323,0.615,0.475,0.477,0.477,0.388,0.477,0.47,0.48,0.478,0.48,0.477,0.477,0.404,0.501,0.501,0.48,0.485,0.574,0.401,0.47,0.473,0.47,0.475,0.391,0.535,0.47,0.48,0.562,0.473,0.477,0.477,0.48,0.326,0.48,0.477,0.477,0.477,0.48,0.48,0.485,0.399,0.302,0.351,0.48,0.485,0.48,0.473,0.473,0.596,0.326,0.48,0.401,0.587,0.379,0.485,0.485,0.485,0.504,0.534,0.485,0.587,0.35,0.391,0.35,0.48,0.48,0.48,0.47,0.48,0.48,0.457,0.326,0.41,0.485,0.48,0.353,0.361,0.48,0.48,0.352,0.477,0.463,0.477,0.477,0.48,0.501,0.485,0.306,0.48,0.472,0.48,0.478,0.477,0.478,0.485,0.485,0.477,0.48,0.477,0.472,0.477,0.48,0.48,0.48,0.501,0.376,0.407,0.391,0.506,0.48,0.48,0.48,0.391,0.463,0.48,0.478,0.48,0.485,0.478,0.587,0.47,0.48,0.472,0.48,0.478,0.48,0.48,0.473,0.473,0.473,0.309,0.324,0.518,0.391,0.335,0.48,0.48,0.48,0.48,0.485,0.322,0.48,0.48,0.48,0.472,0.48,0.48,0.473,0.473,0.587,0.346,0.437,0.587,0.476,0.48,0.48,0.354,0.485,0.485,0.48,0.48,0.501,0.473,0.477,0.473,0.48,0.477,0.361,0.361,0.334,0.476,0.48,0.401,0.361,0.485,0.48,0.48,0.48,0.48,0.477,0.48,0.48,0.48,0.48,0.48,0.363,0.48,0.48,0.48,0.477,0.48,0.48,0.48,0.48,0.52,0.48,0.478,0.478,0.48,0.48,0.389,0.48,0.485,0.372,0.485,0.335,0.48,0.48,0.48'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub5_txt = ''\n",
    "for prob in list(sub5.sort_values(by='unique_id')['pred'].values):\n",
    "    sub5_txt = sub5_txt+','+str(prob)\n",
    "sub5_txt = sub5_txt[1:]\n",
    "\n",
    "sub5_txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
