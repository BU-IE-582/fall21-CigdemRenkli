{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a739384",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16020846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.metrics.pairwise import manhattan_distances,pairwise_distances\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from metric_learn import NCA\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8832d8",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed626f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = pd.read_csv('X_train_raw.csv')\n",
    "X_val_raw = pd.read_csv('X_val_raw.csv')\n",
    "X_test_raw = pd.read_csv('X_test_raw.csv')\n",
    "\n",
    "y_train_raw = pd.read_csv('y_train_raw.csv')\n",
    "y_val_raw = pd.read_csv('y_val_raw.csv')\n",
    "\n",
    "X_train_raw_under = pd.read_csv('X_train_raw_under.csv')\n",
    "y_train_raw_under = pd.read_csv('y_train_raw_under.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21d3a031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sellingprice</th>\n",
       "      <th>weekend_flag</th>\n",
       "      <th>campaign_flag</th>\n",
       "      <th>hour</th>\n",
       "      <th>4_hour_interval</th>\n",
       "      <th>8_hour_interval</th>\n",
       "      <th>week_no</th>\n",
       "      <th>seconds_between_consecutives_all</th>\n",
       "      <th>seconds_between_consecutives_daily</th>\n",
       "      <th>...</th>\n",
       "      <th>Level3_Category_Name_other_3</th>\n",
       "      <th>Level3_Category_Name_Çizme</th>\n",
       "      <th>Level3_Category_Name_Çorap</th>\n",
       "      <th>day_name_Friday</th>\n",
       "      <th>day_name_Monday</th>\n",
       "      <th>day_name_Saturday</th>\n",
       "      <th>day_name_Sunday</th>\n",
       "      <th>day_name_Thursday</th>\n",
       "      <th>day_name_Tuesday</th>\n",
       "      <th>day_name_Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_791869</td>\n",
       "      <td>69.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_791512</td>\n",
       "      <td>442.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_793084</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_792916</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_792175</td>\n",
       "      <td>49.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  sellingprice  weekend_flag  campaign_flag  hour  \\\n",
       "0  TRAIN_791869         69.90             0              0    10   \n",
       "1  TRAIN_791512        442.00             0              0    22   \n",
       "2  TRAIN_793084          0.00             0              0    11   \n",
       "3  TRAIN_792916          0.00             0              0    11   \n",
       "4  TRAIN_792175         49.99             1              0    14   \n",
       "\n",
       "   4_hour_interval  8_hour_interval  week_no  \\\n",
       "0                3                2       42   \n",
       "1                6                3       42   \n",
       "2                3                2       42   \n",
       "3                3                2       42   \n",
       "4                4                2       42   \n",
       "\n",
       "   seconds_between_consecutives_all  seconds_between_consecutives_daily  ...  \\\n",
       "0                               5.0                                 5.0  ...   \n",
       "1                              55.0                                55.0  ...   \n",
       "2                              17.0                                17.0  ...   \n",
       "3                               2.0                                 2.0  ...   \n",
       "4                              12.0                                12.0  ...   \n",
       "\n",
       "   Level3_Category_Name_other_3  Level3_Category_Name_Çizme  \\\n",
       "0                             1                           0   \n",
       "1                             1                           0   \n",
       "2                             1                           0   \n",
       "3                             1                           0   \n",
       "4                             0                           0   \n",
       "\n",
       "   Level3_Category_Name_Çorap  day_name_Friday  day_name_Monday  \\\n",
       "0                           0                0                0   \n",
       "1                           0                0                0   \n",
       "2                           0                1                0   \n",
       "3                           0                1                0   \n",
       "4                           0                0                0   \n",
       "\n",
       "   day_name_Saturday  day_name_Sunday  day_name_Thursday  day_name_Tuesday  \\\n",
       "0                  0                0                  0                 0   \n",
       "1                  0                0                  1                 0   \n",
       "2                  0                0                  0                 0   \n",
       "3                  0                0                  0                 0   \n",
       "4                  1                0                  0                 0   \n",
       "\n",
       "   day_name_Wednesday  \n",
       "0                   1  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3e27b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw.set_index('ID',inplace=True)\n",
    "X_val_raw.set_index('ID',inplace=True)\n",
    "X_test_raw.set_index('ID',inplace=True)\n",
    "y_train_raw.set_index('ID',inplace=True)\n",
    "y_val_raw.set_index('ID',inplace=True)\n",
    "X_train_raw_under.set_index('ID',inplace=True)\n",
    "y_train_raw_under.set_index('ID',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8337015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_test_df = pd.read_csv('test_ids_in_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e353eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2380, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cd504cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw.sort_index(inplace=True)\n",
    "X_val_raw.sort_index(inplace=True)\n",
    "X_test_raw.sort_index(inplace=True)\n",
    "y_train_raw.sort_index(inplace=True)\n",
    "y_val_raw.sort_index(inplace=True)\n",
    "X_train_raw_under.sort_index(inplace=True)\n",
    "y_train_raw_under.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24ab4e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique_id = pd.read_csv('train_unique_id.csv')\n",
    "val_unique_id = pd.read_csv('val_unique_id.csv')\n",
    "test_unique_id = pd.read_csv('test_unique_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcc5388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique_id.set_index('ID',inplace=True)\n",
    "val_unique_id.set_index('ID',inplace=True)\n",
    "test_unique_id.set_index('ID',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c168bb",
   "metadata": {},
   "source": [
    "### Submission 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e759a5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cidem\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(max_depth=2,learning_rate=0.01,n_estimators=100,min_child_samples=100,colsample_bytree=0.5)\n",
    "lgbm.fit(X_train_raw,y_train_raw)\n",
    "\n",
    "pred_train = pd.DataFrame(lgbm.predict_proba(X_train_raw)[:,1],columns=['pred'],index=X_train_raw.index)\n",
    "pred_val = pd.DataFrame(lgbm.predict_proba(X_val_raw)[:,1],columns=['pred'],index=X_val_raw.index)\n",
    "pred_test = pd.DataFrame(lgbm.predict_proba(X_test_raw)[:,1],columns=['pred'],index=X_test_raw.index)\n",
    "\n",
    "pred_train = pd.merge(pred_train,y_train_raw,how='left',left_index=True, right_index=True)\n",
    "pred_val = pd.merge(pred_val,y_val_raw,how='left',left_index=True, right_index=True)\n",
    "\n",
    "roc_train = roc_auc_score(pred_train['female_label'],pred_train['pred'])\n",
    "roc_val = roc_auc_score(pred_val['female_label'],pred_val['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6666e4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC:  0.7890786122664951\n",
      "Val ROC:  0.7856708849975005\n"
     ]
    }
   ],
   "source": [
    "print('Train ROC: ',roc_train)\n",
    "print('Val ROC: ',roc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "828e45b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_rate_df = pd.DataFrame()\n",
    "\n",
    "for th in np.arange(0,1,0.1):\n",
    "\n",
    "    pred_train['pred_binary'] = np.where(pred_train['pred']>=th,1,0)\n",
    "    pred_val['pred_binary'] = np.where(pred_val['pred']>=th,1,0)\n",
    "\n",
    "    err_rate1_train = 1-(pred_train[pred_train['female_label']==1]['pred_binary'].sum()/pred_train[pred_train['female_label']==1]['pred_binary'].count())\n",
    "    err_rate0_train = pred_train[pred_train['female_label']==0]['pred_binary'].sum()/pred_train[pred_train['female_label']==0]['pred_binary'].count()\n",
    "    err_rate_train = err_rate1_train+err_rate0_train\n",
    "\n",
    "    err_rate1_val = 1-(pred_val[pred_val['female_label']==1]['pred_binary'].sum()/pred_val[pred_val['female_label']==1]['pred_binary'].count())\n",
    "    err_rate0_val = pred_val[pred_val['female_label']==0]['pred_binary'].sum()/pred_val[pred_val['female_label']==0]['pred_binary'].count()\n",
    "    err_rate_val = err_rate1_val+err_rate0_val\n",
    "\n",
    "    err_rate_df_tmp = pd.DataFrame({'threshold':[th],\n",
    "                                    'err_rate1_train':[err_rate1_train],\n",
    "                                    'err_rate0_train':[err_rate0_train],\n",
    "                                    'err_rate_train':[err_rate_train],\n",
    "                                    'err_rate1_val':[err_rate1_val],\n",
    "                                    'err_rate0_val':[err_rate0_val],\n",
    "                                    'err_rate_val':[err_rate_val]\n",
    "                                   })\n",
    "    err_rate_df = pd.concat([err_rate_df,err_rate_df_tmp])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e7a10a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>err_rate1_train</th>\n",
       "      <th>err_rate0_train</th>\n",
       "      <th>err_rate_train</th>\n",
       "      <th>err_rate1_val</th>\n",
       "      <th>err_rate0_val</th>\n",
       "      <th>err_rate_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.946540</td>\n",
       "      <td>0.950202</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.973433</td>\n",
       "      <td>0.976202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.056693</td>\n",
       "      <td>0.614519</td>\n",
       "      <td>0.671212</td>\n",
       "      <td>0.057549</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.652144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.099882</td>\n",
       "      <td>0.529106</td>\n",
       "      <td>0.628988</td>\n",
       "      <td>0.100565</td>\n",
       "      <td>0.501183</td>\n",
       "      <td>0.601749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.889543</td>\n",
       "      <td>0.016998</td>\n",
       "      <td>0.906541</td>\n",
       "      <td>0.881220</td>\n",
       "      <td>0.030496</td>\n",
       "      <td>0.911716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  err_rate1_train  err_rate0_train  err_rate_train  err_rate1_val  \\\n",
       "0        0.0         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.1         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.2         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.3         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.4         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.5         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.6         0.003662         0.946540        0.950202       0.002769   \n",
       "0        0.7         0.056693         0.614519        0.671212       0.057549   \n",
       "0        0.8         0.099882         0.529106        0.628988       0.100565   \n",
       "0        0.9         0.889543         0.016998        0.906541       0.881220   \n",
       "\n",
       "   err_rate0_val  err_rate_val  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       0.973433      0.976202  \n",
       "0       0.594595      0.652144  \n",
       "0       0.501183      0.601749  \n",
       "0       0.030496      0.911716  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_rate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e78aa4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TEST_0</th>\n",
       "      <td>0.886529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_1</th>\n",
       "      <td>0.874606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_10</th>\n",
       "      <td>0.798317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_100</th>\n",
       "      <td>0.886713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_1000</th>\n",
       "      <td>0.891372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_99995</th>\n",
       "      <td>0.869851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_99996</th>\n",
       "      <td>0.882476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_99997</th>\n",
       "      <td>0.630236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_99998</th>\n",
       "      <td>0.869851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_99999</th>\n",
       "      <td>0.630236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>877989 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                pred\n",
       "ID                  \n",
       "TEST_0      0.886529\n",
       "TEST_1      0.874606\n",
       "TEST_10     0.798317\n",
       "TEST_100    0.886713\n",
       "TEST_1000   0.891372\n",
       "...              ...\n",
       "TEST_99995  0.869851\n",
       "TEST_99996  0.882476\n",
       "TEST_99997  0.630236\n",
       "TEST_99998  0.869851\n",
       "TEST_99999  0.630236\n",
       "\n",
       "[877989 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17563a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test2 = pd.merge(pred_test,test_unique_id[['unique_id']],how='left',left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0356ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2380.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.812808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.063453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.588505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.793603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.829235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.857032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.904495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pred\n",
       "count  2380.000000\n",
       "mean      0.812808\n",
       "std       0.063453\n",
       "min       0.588505\n",
       "25%       0.793603\n",
       "50%       0.829235\n",
       "75%       0.857032\n",
       "max       0.904495"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = pred_test2.groupby('unique_id').agg({'pred':np.mean})\n",
    "pred_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c870afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a27e0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>108</td>\n",
       "      <td>0.865845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unique_id      pred\n",
       "28        108  0.865845"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test[pred_test['unique_id']==108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7abbd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "minn = pred_test['pred'].min()\n",
    "maxx = pred_test['pred'].max()\n",
    "\n",
    "pred_test['pred'] = (pred_test['pred']-minn)/(maxx-minn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce7199e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2380.000000</td>\n",
       "      <td>2380.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3922.168908</td>\n",
       "      <td>0.709841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2307.573917</td>\n",
       "      <td>0.200808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1938.500000</td>\n",
       "      <td>0.649066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3842.500000</td>\n",
       "      <td>0.761828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5925.250000</td>\n",
       "      <td>0.849795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7998.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         unique_id         pred\n",
       "count  2380.000000  2380.000000\n",
       "mean   3922.168908     0.709841\n",
       "std    2307.573917     0.200808\n",
       "min       9.000000     0.000000\n",
       "25%    1938.500000     0.649066\n",
       "50%    3842.500000     0.761828\n",
       "75%    5925.250000     0.849795\n",
       "max    7998.000000     1.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "369d8ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.896322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.870544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0.866504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.864755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>0.846263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>7982</td>\n",
       "      <td>2375</td>\n",
       "      <td>0.967845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>7990</td>\n",
       "      <td>2376</td>\n",
       "      <td>0.130801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>7993</td>\n",
       "      <td>2377</td>\n",
       "      <td>0.726886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>7994</td>\n",
       "      <td>2378</td>\n",
       "      <td>0.661322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>7998</td>\n",
       "      <td>2379</td>\n",
       "      <td>0.776639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2380 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id  index      pred\n",
       "0             9      0  0.896322\n",
       "1            18      1  0.870544\n",
       "2            21      2  0.866504\n",
       "3            25      3  0.864755\n",
       "4            31      4  0.846263\n",
       "...         ...    ...       ...\n",
       "2375       7982   2375  0.967845\n",
       "2376       7990   2376  0.130801\n",
       "2377       7993   2377  0.726886\n",
       "2378       7994   2378  0.661322\n",
       "2379       7998   2379  0.776639\n",
       "\n",
       "[2380 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub6 = pd.merge(id_test_df,pred_test.reset_index(),how='left',on='unique_id')\n",
    "sub6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32209a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub6['pred'] = sub6['pred'].apply(lambda x: round(x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f226660d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.896,0.871,0.867,0.865,0.846,0.905,0.514,0.427,0.801,0.866,0.502,0.233,0.815,0.917,0.847,0.799,0.576,0.266,0.828,0.786,0.939,0.764,0.818,0.815,0.863,0.896,0.912,0.893,0.878,0.76,0.898,0.786,0.922,0.787,0.928,0.859,0.712,0.751,0.896,0.839,0.811,0.807,0.874,0.706,0.865,0.832,0.84,0.715,0.903,0.702,0.354,0.903,0.736,0.342,0.607,0.311,0.758,0.835,0.842,0.822,0.787,0.684,0.31,0.775,0.919,0.754,0.902,0.749,0.769,0.826,0.876,0.887,0.85,0.92,0.782,0.844,0.655,0.851,0.938,0.847,0.66,0.783,0.783,0.377,0.883,0.877,0.75,0.924,0.875,0.776,0.831,0.792,0.773,0.843,0.652,0.881,0.887,0.788,0.71,0.823,0.761,0.831,0.811,0.835,0.723,0.737,0.73,0.71,0.774,0.708,0.845,0.85,0.808,0.824,0.716,0.766,0.743,0.884,0.877,0.845,0.851,0.865,0.646,0.692,0.812,0.842,0.924,0.904,0.312,0.468,0.903,0.605,0.544,0.906,0.79,0.819,0.807,0.918,0.777,0.796,0.693,0.661,0.886,0.762,0.769,0.908,0.693,0.796,0.377,0.837,0.787,0.863,0.811,0.913,0.705,0.835,0.891,0.792,0.857,0.507,0.844,0.791,0.85,0.821,0.823,0.882,0.738,0.928,0.86,0.311,0.811,0.549,0.769,0.949,0.853,0.693,0.822,0.854,0.774,0.801,0.63,0.239,0.783,0.694,0.631,0.903,0.82,0.862,0.927,0.843,0.825,0.815,0.804,0.773,0.91,0.59,0.795,0.695,0.815,0.771,0.753,0.906,0.944,0.827,0.773,0.731,0.586,0.765,0.233,0.421,0.873,0.824,0.527,0.827,0.892,0.694,0.804,0.865,0.711,0.884,0.77,0.874,0.682,0.807,0.803,0.409,0.583,0.789,0.628,0.586,0.392,0.791,0.746,0.93,0.538,0.937,0.914,0.801,0.868,0.875,0.502,0.841,0.85,0.882,0.833,0.733,0.615,0.446,0.837,0.706,0.699,0.204,0.822,0.921,0.228,0.766,0.866,0.873,0.576,0.536,0.795,0.73,0.689,0.83,0.817,0.839,0.659,0.835,0.867,0.496,0.775,0.769,0.78,0.7,0.859,0.867,0.805,0.836,0.843,0.779,0.912,0.877,0.336,0.827,0.53,0.505,0.873,0.856,0.76,0.865,0.658,0.361,0.573,0.81,0.655,0.645,0.729,0.633,0.557,0.838,0.864,0.772,0.859,0.815,0.916,0.767,0.833,0.91,0.937,0.797,0.888,0.778,0.452,0.784,0.836,0.546,0.88,0.666,0.723,0.451,0.845,0.727,0.625,0.667,0.874,0.795,0.724,0.645,0.76,0.771,0.642,0.872,0.554,0.835,0.55,0.797,0.804,0.805,0.337,0.783,0.837,0.888,0.749,0.888,0.807,0.762,0.876,0.679,0.77,0.912,0.509,0.564,0.953,0.809,0.695,0.889,0.739,0.823,0.89,0.873,0.928,0.905,0.374,0.902,0.76,0.884,0.616,0.873,0.83,0.613,0.815,0.844,0.912,0.928,0.773,0.83,0.822,0.913,0.765,0.825,0.836,0.866,0.479,0.774,0.877,0.824,0.407,0.948,0.983,0.917,0.642,0.883,0.718,0.877,0.794,0.902,0.911,0.87,0.898,0.81,0.759,0.892,0.858,0.859,0.848,0.881,0.101,0.403,0.698,0.373,0.477,0.611,0.72,0.749,0.924,0.414,0.737,0.316,0.643,0.791,0.898,0.766,0.816,0.922,0.234,0.486,0.664,0.141,0.804,0.753,0.796,0.246,0.573,0.918,0.746,0.799,0.838,0.739,0.586,0.811,0.167,0.884,0.832,0.55,0.811,0.796,0.654,0.901,0.373,0.697,0.789,0.824,0.62,0.849,0.859,0.788,0.916,0.938,0.875,0.819,0.914,0.703,0.798,0.782,0.841,0.923,0.581,0.595,0.446,0.834,0.8,0.581,0.358,0.83,0.736,0.85,0.712,0.803,0.664,0.848,0.512,0.911,0.951,0.361,0.483,0.562,0.814,0.855,0.868,0.423,0.318,0.71,0.655,0.803,0.731,0.945,0.862,0.71,0.652,0.248,0.882,0.847,0.866,0.735,0.371,0.865,0.713,0.922,0.77,0.792,0.893,0.922,0.751,0.655,0.675,0.565,0.264,0.918,0.787,0.37,0.685,0.709,0.453,0.6,0.852,0.897,0.844,0.94,0.893,0.765,0.224,0.819,0.708,0.595,0.931,0.773,0.676,0.18,0.804,0.845,0.576,0.906,0.659,0.497,0.833,0.683,0.366,0.829,0.708,0.678,0.858,0.811,0.715,0.899,0.767,0.877,0.143,0.68,0.693,0.787,0.947,0.458,0.701,0.924,0.535,0.928,0.817,0.656,0.528,0.86,0.884,0.592,0.248,0.338,0.89,0.811,0.641,0.738,0.917,0.806,0.879,0.229,0.852,0.9,0.593,0.904,0.939,0.744,0.805,0.788,0.684,0.862,0.758,0.37,0.801,0.44,0.934,0.691,0.665,0.699,0.821,0.937,0.578,0.886,0.595,0.767,0.664,0.869,0.956,0.853,0.84,0.84,0.246,0.713,0.319,0.862,0.718,0.505,0.193,0.351,0.819,0.955,0.787,0.833,0.884,0.597,0.364,0.859,0.791,0.901,0.789,0.806,0.702,0.329,0.884,0.741,0.608,0.435,0.769,0.862,0.846,0.882,0.872,0.727,0.806,0.309,0.709,0.843,0.875,0.77,0.923,0.651,0.359,0.612,0.814,0.893,0.819,0.538,0.808,0.918,0.766,0.777,0.453,0.715,0.589,0.641,0.825,0.911,0.93,0.941,0.357,0.814,0.744,0.664,0.741,0.717,0.929,0.801,0.646,0.622,0.709,0.569,0.576,0.906,0.785,0.807,0.426,0.765,0.851,0.624,0.474,0.425,0.783,0.736,0.827,0.797,0.863,0.93,0.592,0.801,0.933,0.826,0.617,0.915,0.776,0.769,0.792,0.649,0.902,0.536,0.789,0.665,0.838,0.59,0.787,0.831,0.882,0.772,0.746,0.753,0.778,0.915,0.894,0.325,0.817,0.866,0.508,0.911,0.387,0.598,0.858,0.642,0.697,0.783,0.786,0.827,0.929,0.898,0.855,0.866,0.82,0.81,0.702,0.816,0.884,0.67,0.601,0.861,0.713,0.824,0.789,0.628,0.695,0.846,0.68,0.795,0.95,0.513,0.717,0.912,0.944,0.852,0.537,0.816,0.936,0.897,0.81,0.754,0.778,0.573,0.455,0.809,0.9,0.561,0.554,0.515,0.482,0.503,0.757,0.668,0.919,0.677,0.834,0.758,0.898,0.691,0.461,0.781,0.929,0.233,0.161,0.884,0.724,0.759,0.556,0.722,0.855,0.683,0.936,0.764,0.656,0.603,0.797,0.163,0.764,0.876,0.794,0.744,0.893,0.906,0.925,0.67,0.747,0.759,0.687,0.706,0.945,0.824,0.807,0.936,0.874,0.783,0.832,0.876,0.809,0.712,0.805,0.714,0.725,0.894,0.84,0.851,0.78,0.687,0.681,0.792,0.696,0.339,0.766,0.721,0.931,0.741,0.89,0.931,0.869,0.883,0.887,0.817,0.865,0.757,0.744,0.762,0.725,0.516,0.69,0.958,0.855,0.431,0.799,0.82,0.867,0.902,0.735,0.84,0.662,0.394,0.389,0.912,0.703,0.671,0.911,0.739,0.895,0.807,0.564,0.868,0.819,0.832,0.421,0.628,0.518,0.518,0.866,0.775,0.777,0.506,0.884,0.661,0.72,0.668,0.904,0.652,0.476,0.672,0.88,0.816,0.815,0.327,0.63,0.763,0.498,0.8,0.791,0.662,0.635,0.822,0.439,0.476,0.478,0.75,0.335,0.237,0.939,0.884,0.905,0.761,0.893,0.761,0.516,0.866,0.846,0.476,0.882,0.8,0.788,0.237,0.84,0.722,0.662,0.539,0.824,0.909,0.957,0.844,0.619,0.821,0.861,0.222,0.82,0.709,0.828,0.376,0.524,0.962,0.822,0.866,0.802,0.781,0.8,0.493,0.816,0.609,0.378,0.892,0.802,0.794,0.845,0.922,0.942,0.718,0.93,0.754,0.719,0.878,0.781,0.94,0.883,0.32,0.922,0.391,0.624,0.68,0.496,0.958,0.915,0.847,0.794,0.769,0.818,0.692,0.91,0.758,0.833,0.442,0.936,0.324,0.844,0.721,0.861,0.882,0.868,0.941,0.909,0.836,0.553,0.85,0.781,0.735,0.79,0.938,0.836,0.731,0.703,0.867,0.846,0.827,0.651,0.437,0.849,0.812,0.298,0.847,0.761,0.906,0.798,0.108,0.653,0.842,0.635,0.873,0.3,0.886,0.741,0.86,0.245,0.756,0.716,0.579,0.675,0.888,0.814,0.84,0.894,0.73,0.781,0.724,0.736,0.43,0.91,0.712,0.446,0.415,0.591,0.643,0.343,0.572,0.856,0.916,0.948,0.921,0.915,0.729,0.886,0.842,0.925,0.812,0.86,0.189,0.778,0.845,0.788,0.663,0.826,0.915,0.846,0.946,0.824,0.768,0.939,0.798,0.822,0.566,0.873,0.818,0.735,0.824,0.818,0.92,0.602,0.81,0.613,0.728,0.673,0.642,0.734,0.727,0.661,0.751,0.702,0.266,0.706,0.552,0.773,0.359,0.661,0.667,0.827,0.87,0.52,0.889,0.705,0.468,0.271,0.73,0.739,0.199,0.728,0.756,0.622,0.181,0.656,0.811,0.877,0.815,0.657,0.667,0.219,0.869,0.79,0.568,0.206,0.9,0.711,0.499,0.81,0.8,0.498,0.779,0.846,0.701,0.529,0.928,0.348,0.837,0.674,0.881,0.873,0.788,0.876,0.387,0.721,0.684,0.787,0.722,0.855,0.662,0.778,0.196,0.791,0.815,0.789,0.195,0.777,0.697,0.818,0.663,0.903,0.917,0.443,0.479,0.627,0.749,0.934,0.87,0.762,0.948,0.804,0.919,0.845,0.742,0.727,0.912,0.202,0.875,0.682,0.868,0.666,0.77,0.303,0.939,0.8,0.697,0.695,0.568,0.888,0.719,0.911,0.496,0.885,0.525,0.326,0.884,0.429,0.451,0.754,0.646,0.824,0.738,0.803,0.661,0.785,0.814,0.774,0.679,0.763,0.518,0.777,0.583,0.746,0.867,0.938,0.711,0.939,0.831,0.874,0.797,0.851,0.646,0.588,0.789,0.785,0.901,0.851,0.645,0.152,0.58,0.742,0.418,0.508,0.748,0.242,0.29,0.778,0.721,0.823,0.802,0.699,0.898,0.725,0.657,0.326,0.502,0.853,0.794,0.423,0.759,0.755,0.936,0.778,0.7,0.795,0.862,0.886,0.614,0.694,0.452,0.805,0.755,0.78,0.667,0.852,0.726,0.942,0.463,0.655,0.305,0.22,0.922,0.94,0.594,0.794,0.191,0.664,0.84,0.845,0.771,0.302,0.792,0.725,0.898,0.913,0.642,0.775,0.769,0.656,0.849,0.74,0.511,0.937,0.79,0.761,0.72,0.718,0.353,0.3,0.757,0.549,0.817,0.868,0.744,0.96,0.717,0.553,0.716,0.479,0.863,0.656,0.789,0.295,0.808,0.781,0.895,0.403,0.369,0.878,0.698,0.828,0.858,0.599,0.264,0.736,0.987,0.94,0.615,0.91,0.436,0.586,0.745,0.73,0.888,0.611,0.903,0.81,0.686,0.753,0.845,0.685,0.785,0.705,0.573,0.554,0.948,0.54,0.773,0.411,0.788,0.924,0.839,0.83,0.284,0.919,0.661,0.743,0.742,0.734,0.647,0.729,0.864,0.604,0.621,0.963,0.685,0.368,0.652,0.864,0.652,0.509,0.899,0.276,0.709,0.875,0.851,0.732,0.811,0.918,0.654,0.723,0.631,0.716,0.741,0.512,0.727,0.715,0.538,0.721,0.837,0.703,0.721,0.111,0.721,0.734,0.87,0.749,0.697,0.723,0.673,0.727,0.698,0.763,0.653,0.776,0.686,0.693,0.912,0.592,0.799,0.626,0.679,0.662,0.826,0.68,0.769,0.724,0.661,0.69,0.382,0.697,0.309,0.673,0.585,0.19,0.676,0.658,0.9,0.846,0.672,0.765,0.847,0.652,0.634,0.685,0.706,0.534,0.766,0.888,0.77,0.667,0.636,0.561,0.693,0.696,0.849,0.706,0.384,0.666,0.826,0.668,0.234,0.437,0.736,0.729,0.497,0.482,0.786,0.625,0.506,0.55,0.824,0.509,0.966,0.938,0.665,0.418,0.865,0.427,0.66,0.493,0.951,0.714,0.474,0.709,0.739,0.757,0.747,0.895,0.7,0.546,0.948,0.112,0.367,0.89,0.948,0.817,0.687,0.618,0.791,0.846,0.601,0.824,0.536,0.958,0.29,0.908,0.926,0.618,0.741,0.688,0.908,0.443,0.684,0.613,0.715,0.915,0.899,0.746,0.912,0.769,0.788,0.961,0.862,0.739,0.447,0.357,0.853,0.271,0.886,0.186,0.917,0.757,0.897,0.835,0.837,0.959,0.613,0.738,0.95,0.859,0.653,0.188,0.791,0.372,0.818,0.978,0.244,0.88,0.153,0.087,0.802,0.167,0.71,0.88,0.897,0.901,0.865,0.17,0.066,0.313,0.804,0.184,0.139,0.107,0.784,0.419,0.316,0.966,0.429,0.84,0.722,0.936,0.949,0.171,0.281,0.725,0.348,0.94,0.804,0.915,0.729,0.595,0.766,0.666,0.949,0.741,0.818,0.935,0.209,0.957,0.476,0.627,0.848,0.249,0.947,0.274,0.522,0.939,0.332,0.973,0.63,0.932,0.955,0.835,0.939,0.22,0.954,0.422,0.916,0.763,0.387,0.733,0.77,0.946,0.685,0.94,0.714,0.29,0.42,0.6,0.218,0.79,0.512,0.214,0.872,0.876,0.552,0.724,0.893,0.216,0.657,0.833,0.254,0.836,0.793,0.836,0.651,0.878,0.592,0.725,0.657,0.219,0.782,0.419,0.539,0.003,0.222,0.798,0.947,0.804,0.894,0.94,0.179,0.862,0.809,0.0,0.338,0.437,0.921,0.838,0.637,0.954,0.935,0.91,0.886,0.886,0.795,0.311,0.938,0.798,0.802,0.951,0.265,0.133,0.931,0.872,0.44,0.866,0.752,0.966,0.841,0.918,0.881,0.918,0.871,0.95,0.923,0.797,1.0,0.37,0.25,0.732,0.254,0.923,0.273,0.981,0.949,0.182,0.269,0.968,0.131,0.944,0.786,0.841,0.798,0.904,0.346,0.151,0.895,0.956,0.213,0.909,0.603,0.469,0.681,0.458,0.74,0.955,0.884,0.328,0.865,0.877,0.965,0.762,0.906,0.464,0.832,0.927,0.806,0.884,0.804,0.879,0.777,0.921,0.811,0.883,0.796,0.652,0.309,0.259,0.296,0.217,0.743,0.965,0.866,0.338,0.894,0.944,0.464,0.876,0.866,0.367,0.248,0.192,0.231,0.841,0.929,0.887,0.401,0.856,0.655,0.531,0.591,0.231,0.322,0.314,0.957,0.607,0.166,0.961,0.934,0.258,0.676,0.539,0.913,0.085,0.658,0.654,0.918,0.589,0.376,0.457,0.32,0.602,0.972,0.817,0.141,0.783,0.98,0.934,0.863,0.094,0.732,0.273,0.91,0.985,0.873,0.912,0.879,0.741,0.867,0.862,0.91,0.704,0.982,0.814,0.869,0.88,0.014,0.362,0.421,0.412,0.855,0.371,0.464,0.858,0.31,0.783,0.592,0.446,0.758,0.406,0.037,0.841,0.091,0.675,0.091,0.531,0.742,0.654,0.689,0.774,0.751,0.752,0.659,0.815,0.749,0.675,0.838,0.754,0.752,0.746,0.579,0.777,0.751,0.817,0.582,0.786,0.667,0.797,0.756,0.788,0.565,0.767,0.736,0.792,0.721,0.731,0.735,0.731,0.764,0.467,0.739,0.767,0.808,0.323,0.73,0.597,0.668,0.722,0.718,0.749,0.84,0.707,0.679,0.347,0.68,0.614,0.77,0.845,0.738,0.723,0.721,0.737,0.734,0.229,0.164,0.306,0.869,0.652,0.444,0.795,0.798,0.798,0.787,0.777,0.881,0.796,0.803,0.801,0.787,0.801,0.769,0.81,0.784,0.819,0.79,0.822,0.794,0.734,0.838,0.825,0.76,0.771,0.743,0.797,0.753,0.757,0.811,0.773,0.773,0.656,0.832,0.934,0.94,0.799,0.947,0.877,0.856,0.729,0.721,0.554,0.637,0.862,0.725,0.691,0.721,0.909,0.907,0.338,0.947,0.366,0.892,0.837,0.715,0.353,0.866,0.148,0.944,0.485,0.777,0.923,0.713,0.335,0.554,0.838,0.378,0.88,0.639,0.548,0.87,0.229,0.935,0.633,0.682,0.946,0.869,0.174,0.287,0.814,0.301,0.779,0.836,0.809,0.555,0.937,0.95,0.984,0.791,0.584,0.805,0.784,0.727,0.223,0.159,0.646,0.724,0.872,0.278,0.683,0.53,0.345,0.789,0.77,0.394,0.719,0.44,0.722,0.723,0.363,0.662,0.717,0.778,0.549,0.715,0.818,0.767,0.779,0.754,0.735,0.769,0.724,0.904,0.739,0.776,0.741,0.848,0.726,0.765,0.693,0.719,0.721,0.733,0.703,0.54,0.735,0.704,0.675,0.81,0.865,0.812,0.943,0.727,0.788,0.832,0.876,0.894,0.734,0.715,0.731,0.585,0.712,0.82,0.91,0.721,0.66,0.601,0.698,0.654,0.688,0.813,0.654,0.648,0.58,0.532,0.735,0.673,0.703,0.861,0.83,0.777,0.8,0.666,0.564,0.755,0.792,0.665,0.797,0.723,0.693,0.714,0.783,0.655,0.645,0.645,0.764,0.71,0.515,0.608,0.699,0.871,0.661,0.811,0.852,0.696,0.664,0.831,0.826,0.771,0.704,0.736,0.732,0.689,0.743,0.63,0.778,0.784,0.752,0.771,0.771,0.797,0.522,0.698,0.564,0.723,0.738,0.675,0.761,0.87,0.678,0.649,0.819,0.721,0.822,0.59,0.32,0.742,0.658,0.859,0.918,0.25,0.248,0.953,0.792,0.727,0.721,0.76,0.626,0.615,0.664,0.669,0.452,0.803,0.481,0.86,0.06,0.546,0.058,0.856,0.906,0.969,0.187,0.967,0.25,0.941,0.562,0.995,0.93,0.19,0.968,0.498,0.531,0.224,0.743,0.754,0.318,0.743,0.743,0.721,0.721,0.763,0.775,0.77,0.71,0.676,0.797,0.688,0.674,0.891,0.847,0.77,0.949,0.787,0.87,0.864,0.772,0.553,0.251,0.612,1.0,0.787,0.598,0.769,0.529,0.935,0.763,0.721,0.717,0.608,0.727,0.712,0.714,0.748,0.732,0.702,0.723,0.586,0.837,0.945,0.91,0.847,0.819,0.173,0.655,0.649,0.649,0.735,0.608,0.768,0.728,0.685,0.77,0.674,0.655,0.655,0.782,0.531,0.787,0.701,0.726,0.773,0.791,0.714,0.802,0.751,0.454,0.604,0.732,0.931,0.727,0.669,0.681,0.984,0.004,0.94,0.815,1.0,0.482,0.958,0.958,0.821,0.984,0.888,0.958,1.0,0.091,0.089,0.091,0.754,0.754,0.743,0.664,0.721,0.732,0.67,0.124,0.22,0.951,0.947,0.14,0.431,0.73,0.927,0.137,0.72,0.224,0.718,0.716,0.904,0.898,0.751,0.13,0.797,0.755,0.797,0.791,0.747,0.771,0.943,0.874,0.728,0.732,0.735,0.676,0.593,0.732,0.716,0.673,0.955,0.015,0.184,0.184,0.918,0.721,0.789,0.787,0.607,0.556,0.754,0.812,0.721,0.947,0.817,0.857,0.658,0.727,0.643,0.806,0.771,0.72,0.727,0.667,0.666,0.664,0.198,0.145,1.0,0.089,0.447,0.526,0.751,0.719,0.794,0.947,0.167,0.721,0.721,0.732,0.685,0.789,0.813,0.673,0.664,1.0,0.322,0.184,1.0,0.533,0.716,0.69,0.178,0.947,0.93,0.714,0.73,0.96,0.649,0.655,0.685,0.661,0.655,0.102,0.102,0.431,0.693,0.806,0.554,0.14,0.838,0.732,0.732,0.743,0.905,0.643,0.797,0.789,0.735,0.754,0.721,0.426,0.743,0.945,0.732,0.771,0.721,0.732,0.905,0.643,1.0,0.921,0.909,0.909,0.947,0.732,0.608,0.685,0.905,0.029,0.968,0.131,0.727,0.661,0.777'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub6_txt = ''\n",
    "for prob in list(sub6['pred'].values):\n",
    "    sub6_txt = sub6_txt+','+str(prob)\n",
    "sub6_txt = sub6_txt[1:]\n",
    "\n",
    "sub6_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dabfd5d",
   "metadata": {},
   "source": [
    "### Submission 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f1b7fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cidem\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(max_depth=2,learning_rate=0.01,n_estimators=100,min_child_samples=100,colsample_bytree=0.5)\n",
    "lgbm.fit(X_train_raw_under,y_train_raw_under)\n",
    "\n",
    "pred_train = pd.DataFrame(lgbm.predict_proba(X_train_raw)[:,1],columns=['pred'],index=X_train_raw.index)\n",
    "pred_val = pd.DataFrame(lgbm.predict_proba(X_val_raw)[:,1],columns=['pred'],index=X_val_raw.index)\n",
    "pred_test = pd.DataFrame(lgbm.predict_proba(X_test_raw)[:,1],columns=['pred'],index=X_test_raw.index)\n",
    "\n",
    "pred_train = pd.merge(pred_train,y_train_raw,how='left',left_index=True, right_index=True)\n",
    "pred_val = pd.merge(pred_val,y_val_raw,how='left',left_index=True, right_index=True)\n",
    "\n",
    "roc_train = roc_auc_score(pred_train['female_label'],pred_train['pred'])\n",
    "roc_val = roc_auc_score(pred_val['female_label'],pred_val['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d518f4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC:  0.7889178376458337\n",
      "Val ROC:  0.7854915086904803\n"
     ]
    }
   ],
   "source": [
    "print('Train ROC: ',roc_train)\n",
    "print('Val ROC: ',roc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "298517fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_rate_df = pd.DataFrame()\n",
    "\n",
    "for th in np.arange(0,1,0.1):\n",
    "\n",
    "    pred_train['pred_binary'] = np.where(pred_train['pred']>=th,1,0)\n",
    "    pred_val['pred_binary'] = np.where(pred_val['pred']>=th,1,0)\n",
    "\n",
    "    err_rate1_train = 1-(pred_train[pred_train['female_label']==1]['pred_binary'].sum()/pred_train[pred_train['female_label']==1]['pred_binary'].count())\n",
    "    err_rate0_train = pred_train[pred_train['female_label']==0]['pred_binary'].sum()/pred_train[pred_train['female_label']==0]['pred_binary'].count()\n",
    "    err_rate_train = err_rate1_train+err_rate0_train\n",
    "\n",
    "    err_rate1_val = 1-(pred_val[pred_val['female_label']==1]['pred_binary'].sum()/pred_val[pred_val['female_label']==1]['pred_binary'].count())\n",
    "    err_rate0_val = pred_val[pred_val['female_label']==0]['pred_binary'].sum()/pred_val[pred_val['female_label']==0]['pred_binary'].count()\n",
    "    err_rate_val = err_rate1_val+err_rate0_val\n",
    "\n",
    "    err_rate_df_tmp = pd.DataFrame({'threshold':[th],\n",
    "                                    'err_rate1_train':[err_rate1_train],\n",
    "                                    'err_rate0_train':[err_rate0_train],\n",
    "                                    'err_rate_train':[err_rate_train],\n",
    "                                    'err_rate1_val':[err_rate1_val],\n",
    "                                    'err_rate0_val':[err_rate0_val],\n",
    "                                    'err_rate_val':[err_rate_val]\n",
    "                                   })\n",
    "    err_rate_df = pd.concat([err_rate_df,err_rate_df_tmp])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6bf82fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>err_rate1_train</th>\n",
       "      <th>err_rate0_train</th>\n",
       "      <th>err_rate_train</th>\n",
       "      <th>err_rate1_val</th>\n",
       "      <th>err_rate0_val</th>\n",
       "      <th>err_rate_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.040482</td>\n",
       "      <td>0.708379</td>\n",
       "      <td>0.748861</td>\n",
       "      <td>0.039817</td>\n",
       "      <td>0.713202</td>\n",
       "      <td>0.753019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.056693</td>\n",
       "      <td>0.614519</td>\n",
       "      <td>0.671212</td>\n",
       "      <td>0.057549</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.652144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.192887</td>\n",
       "      <td>0.374316</td>\n",
       "      <td>0.567204</td>\n",
       "      <td>0.195689</td>\n",
       "      <td>0.359985</td>\n",
       "      <td>0.555674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.624355</td>\n",
       "      <td>0.092771</td>\n",
       "      <td>0.717127</td>\n",
       "      <td>0.624844</td>\n",
       "      <td>0.106238</td>\n",
       "      <td>0.731082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  err_rate1_train  err_rate0_train  err_rate_train  err_rate1_val  \\\n",
       "0        0.0         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.1         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.2         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.3         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.4         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.5         0.040482         0.708379        0.748861       0.039817   \n",
       "0        0.6         0.056693         0.614519        0.671212       0.057549   \n",
       "0        0.7         0.192887         0.374316        0.567204       0.195689   \n",
       "0        0.8         0.624355         0.092771        0.717127       0.624844   \n",
       "0        0.9         1.000000         0.000000        1.000000       1.000000   \n",
       "\n",
       "   err_rate0_val  err_rate_val  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       0.713202      0.753019  \n",
       "0       0.594595      0.652144  \n",
       "0       0.359985      0.555674  \n",
       "0       0.106238      0.731082  \n",
       "0       0.000000      1.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_rate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e5bd228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TEST_0</th>\n",
       "      <td>0.798157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_1</th>\n",
       "      <td>0.779986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_10</th>\n",
       "      <td>0.667117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_100</th>\n",
       "      <td>0.798930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_1000</th>\n",
       "      <td>0.808469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_99995</th>\n",
       "      <td>0.769575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_99996</th>\n",
       "      <td>0.790180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_99997</th>\n",
       "      <td>0.489081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_99998</th>\n",
       "      <td>0.769575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_99999</th>\n",
       "      <td>0.489081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>877989 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                pred\n",
       "ID                  \n",
       "TEST_0      0.798157\n",
       "TEST_1      0.779986\n",
       "TEST_10     0.667117\n",
       "TEST_100    0.798930\n",
       "TEST_1000   0.808469\n",
       "...              ...\n",
       "TEST_99995  0.769575\n",
       "TEST_99996  0.790180\n",
       "TEST_99997  0.489081\n",
       "TEST_99998  0.769575\n",
       "TEST_99999  0.489081\n",
       "\n",
       "[877989 rows x 1 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8cfd29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test2 = pd.merge(pred_test,test_unique_id[['unique_id']],how='left',left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "568df968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2380.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.700609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.078219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.449356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.666345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.716065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.757860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.832121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pred\n",
       "count  2380.000000\n",
       "mean      0.700609\n",
       "std       0.078219\n",
       "min       0.449356\n",
       "25%       0.666345\n",
       "50%       0.716065\n",
       "75%       0.757860\n",
       "max       0.832121"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = pred_test2.groupby('unique_id').agg({'pred':np.mean})\n",
    "pred_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34562579",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8681e42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>108</td>\n",
       "      <td>0.77268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unique_id     pred\n",
       "28        108  0.77268"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test[pred_test['unique_id']==108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f129b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "minn = pred_test['pred'].min()\n",
    "maxx = pred_test['pred'].max()\n",
    "\n",
    "pred_test['pred'] = (pred_test['pred']-minn)/(maxx-minn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0cac4bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2380.000000</td>\n",
       "      <td>2380.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3922.168908</td>\n",
       "      <td>0.656414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2307.573917</td>\n",
       "      <td>0.204352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1938.500000</td>\n",
       "      <td>0.566899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3842.500000</td>\n",
       "      <td>0.696795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5925.250000</td>\n",
       "      <td>0.805988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7998.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         unique_id         pred\n",
       "count  2380.000000  2380.000000\n",
       "mean   3922.168908     0.656414\n",
       "std    2307.573917     0.204352\n",
       "min       9.000000     0.000000\n",
       "25%    1938.500000     0.566899\n",
       "50%    3842.500000     0.696795\n",
       "75%    5925.250000     0.805988\n",
       "max    7998.000000     1.000000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1ccd899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.871136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.841140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0.829149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.827655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>0.795869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>7982</td>\n",
       "      <td>2375</td>\n",
       "      <td>0.956234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>7990</td>\n",
       "      <td>2376</td>\n",
       "      <td>0.107890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>7993</td>\n",
       "      <td>2377</td>\n",
       "      <td>0.639419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>7994</td>\n",
       "      <td>2378</td>\n",
       "      <td>0.566899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>7998</td>\n",
       "      <td>2379</td>\n",
       "      <td>0.704001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2380 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id  index      pred\n",
       "0             9      0  0.871136\n",
       "1            18      1  0.841140\n",
       "2            21      2  0.829149\n",
       "3            25      3  0.827655\n",
       "4            31      4  0.795869\n",
       "...         ...    ...       ...\n",
       "2375       7982   2375  0.956234\n",
       "2376       7990   2376  0.107890\n",
       "2377       7993   2377  0.639419\n",
       "2378       7994   2378  0.566899\n",
       "2379       7998   2379  0.704001\n",
       "\n",
       "[2380 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub7 = pd.merge(id_test_df,pred_test.reset_index(),how='left',on='unique_id')\n",
    "sub7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9ce12c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub7['pred'] = sub7['pred'].apply(lambda x: round(x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6425d62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.871,0.841,0.829,0.828,0.796,0.872,0.468,0.383,0.745,0.831,0.448,0.191,0.772,0.889,0.812,0.741,0.515,0.221,0.797,0.72,0.914,0.707,0.767,0.769,0.815,0.864,0.877,0.857,0.845,0.689,0.869,0.727,0.9,0.734,0.909,0.812,0.63,0.684,0.856,0.805,0.763,0.758,0.832,0.651,0.827,0.792,0.78,0.638,0.865,0.636,0.291,0.871,0.684,0.288,0.531,0.254,0.69,0.785,0.795,0.77,0.725,0.608,0.266,0.714,0.886,0.704,0.87,0.69,0.703,0.771,0.833,0.856,0.821,0.901,0.729,0.799,0.603,0.8,0.922,0.8,0.575,0.745,0.718,0.328,0.847,0.848,0.699,0.897,0.839,0.73,0.776,0.753,0.709,0.795,0.593,0.849,0.851,0.725,0.639,0.768,0.705,0.781,0.752,0.782,0.688,0.667,0.654,0.639,0.715,0.633,0.809,0.8,0.756,0.777,0.658,0.699,0.691,0.849,0.846,0.795,0.802,0.821,0.6,0.634,0.748,0.79,0.892,0.879,0.274,0.404,0.865,0.545,0.482,0.879,0.742,0.767,0.747,0.891,0.705,0.746,0.616,0.608,0.854,0.733,0.714,0.876,0.658,0.758,0.348,0.786,0.722,0.824,0.752,0.886,0.632,0.788,0.854,0.744,0.822,0.481,0.811,0.742,0.81,0.763,0.772,0.845,0.695,0.907,0.836,0.264,0.764,0.489,0.703,0.928,0.807,0.66,0.774,0.802,0.727,0.75,0.564,0.214,0.714,0.604,0.559,0.873,0.774,0.813,0.9,0.806,0.768,0.769,0.773,0.74,0.879,0.525,0.73,0.622,0.759,0.728,0.682,0.876,0.921,0.781,0.705,0.67,0.513,0.692,0.205,0.36,0.836,0.766,0.461,0.77,0.872,0.611,0.738,0.82,0.657,0.857,0.705,0.833,0.588,0.747,0.738,0.364,0.51,0.725,0.564,0.518,0.325,0.735,0.682,0.904,0.482,0.912,0.878,0.751,0.826,0.832,0.44,0.789,0.803,0.846,0.785,0.663,0.58,0.382,0.794,0.668,0.627,0.174,0.78,0.892,0.195,0.691,0.82,0.831,0.506,0.472,0.73,0.693,0.613,0.78,0.753,0.783,0.592,0.783,0.817,0.425,0.722,0.7,0.729,0.623,0.825,0.825,0.746,0.785,0.79,0.716,0.88,0.836,0.289,0.771,0.494,0.432,0.83,0.823,0.687,0.822,0.584,0.31,0.505,0.753,0.588,0.581,0.675,0.56,0.504,0.795,0.82,0.705,0.817,0.762,0.886,0.697,0.786,0.885,0.915,0.738,0.849,0.722,0.392,0.729,0.794,0.479,0.842,0.571,0.669,0.385,0.801,0.659,0.555,0.614,0.831,0.752,0.644,0.612,0.701,0.699,0.575,0.835,0.489,0.785,0.504,0.726,0.74,0.742,0.294,0.72,0.801,0.852,0.691,0.854,0.747,0.689,0.851,0.604,0.705,0.882,0.451,0.498,0.933,0.772,0.619,0.854,0.692,0.769,0.852,0.83,0.902,0.889,0.322,0.865,0.711,0.843,0.529,0.838,0.789,0.553,0.776,0.799,0.885,0.897,0.718,0.769,0.782,0.897,0.696,0.771,0.793,0.832,0.426,0.701,0.84,0.783,0.349,0.929,0.975,0.887,0.575,0.853,0.646,0.84,0.744,0.867,0.874,0.824,0.863,0.773,0.69,0.853,0.81,0.813,0.797,0.845,0.1,0.35,0.666,0.309,0.424,0.519,0.669,0.674,0.893,0.36,0.676,0.279,0.577,0.722,0.866,0.704,0.763,0.891,0.198,0.425,0.569,0.092,0.74,0.706,0.735,0.217,0.502,0.888,0.671,0.737,0.802,0.692,0.525,0.772,0.13,0.852,0.775,0.486,0.756,0.74,0.574,0.865,0.323,0.615,0.754,0.771,0.548,0.811,0.811,0.719,0.882,0.914,0.833,0.761,0.883,0.626,0.735,0.724,0.81,0.899,0.5,0.559,0.404,0.789,0.765,0.547,0.316,0.778,0.66,0.809,0.657,0.75,0.569,0.821,0.459,0.88,0.931,0.321,0.412,0.487,0.765,0.801,0.838,0.365,0.273,0.675,0.561,0.745,0.684,0.921,0.821,0.629,0.568,0.218,0.85,0.814,0.826,0.657,0.32,0.822,0.636,0.891,0.712,0.73,0.855,0.893,0.694,0.571,0.604,0.498,0.21,0.889,0.72,0.319,0.627,0.636,0.39,0.545,0.812,0.86,0.793,0.92,0.856,0.719,0.193,0.762,0.657,0.518,0.905,0.704,0.622,0.144,0.756,0.818,0.503,0.878,0.565,0.442,0.78,0.592,0.311,0.767,0.634,0.59,0.812,0.759,0.65,0.866,0.724,0.85,0.124,0.622,0.615,0.717,0.929,0.412,0.638,0.886,0.471,0.903,0.763,0.595,0.472,0.815,0.849,0.548,0.21,0.294,0.859,0.756,0.591,0.699,0.891,0.745,0.843,0.191,0.806,0.864,0.552,0.871,0.909,0.677,0.756,0.727,0.634,0.826,0.696,0.312,0.74,0.405,0.909,0.622,0.581,0.661,0.776,0.913,0.539,0.848,0.523,0.72,0.575,0.826,0.94,0.8,0.789,0.797,0.2,0.647,0.276,0.816,0.646,0.447,0.175,0.289,0.765,0.934,0.73,0.787,0.837,0.542,0.324,0.814,0.745,0.866,0.757,0.753,0.613,0.279,0.844,0.666,0.529,0.368,0.696,0.815,0.796,0.852,0.839,0.645,0.753,0.252,0.622,0.792,0.831,0.715,0.89,0.559,0.32,0.586,0.766,0.861,0.76,0.479,0.747,0.895,0.691,0.736,0.419,0.635,0.522,0.57,0.77,0.878,0.906,0.926,0.324,0.756,0.69,0.571,0.671,0.656,0.903,0.743,0.578,0.551,0.655,0.506,0.541,0.876,0.743,0.746,0.37,0.699,0.825,0.588,0.412,0.366,0.71,0.667,0.795,0.733,0.82,0.905,0.528,0.761,0.906,0.773,0.555,0.885,0.706,0.736,0.749,0.57,0.868,0.48,0.721,0.592,0.786,0.516,0.721,0.776,0.853,0.701,0.682,0.679,0.746,0.877,0.859,0.274,0.76,0.819,0.448,0.874,0.347,0.523,0.808,0.586,0.645,0.73,0.719,0.775,0.906,0.858,0.807,0.827,0.766,0.747,0.643,0.761,0.841,0.577,0.535,0.835,0.644,0.771,0.726,0.559,0.65,0.801,0.594,0.727,0.932,0.46,0.636,0.88,0.921,0.804,0.476,0.754,0.911,0.878,0.755,0.686,0.712,0.532,0.406,0.75,0.866,0.49,0.508,0.453,0.408,0.451,0.696,0.639,0.888,0.582,0.78,0.698,0.864,0.617,0.399,0.733,0.903,0.186,0.14,0.848,0.65,0.695,0.505,0.651,0.808,0.608,0.909,0.697,0.576,0.523,0.736,0.139,0.692,0.834,0.736,0.7,0.851,0.87,0.901,0.579,0.704,0.689,0.633,0.662,0.924,0.793,0.755,0.909,0.83,0.725,0.781,0.837,0.745,0.641,0.753,0.685,0.649,0.866,0.799,0.81,0.71,0.624,0.598,0.724,0.621,0.295,0.715,0.647,0.908,0.665,0.847,0.905,0.838,0.861,0.872,0.758,0.817,0.709,0.669,0.705,0.646,0.477,0.597,0.941,0.807,0.372,0.733,0.76,0.833,0.868,0.658,0.792,0.587,0.353,0.333,0.889,0.646,0.6,0.879,0.665,0.853,0.746,0.528,0.826,0.76,0.777,0.365,0.538,0.474,0.436,0.834,0.705,0.719,0.447,0.842,0.567,0.641,0.599,0.869,0.58,0.404,0.629,0.84,0.755,0.758,0.276,0.559,0.696,0.428,0.777,0.736,0.594,0.56,0.768,0.374,0.423,0.426,0.713,0.28,0.205,0.911,0.849,0.864,0.69,0.862,0.697,0.428,0.825,0.806,0.425,0.844,0.755,0.746,0.216,0.782,0.646,0.605,0.474,0.767,0.88,0.941,0.801,0.558,0.775,0.821,0.191,0.76,0.66,0.783,0.307,0.495,0.95,0.771,0.817,0.751,0.718,0.734,0.435,0.765,0.565,0.319,0.858,0.768,0.728,0.798,0.895,0.916,0.648,0.906,0.681,0.641,0.843,0.726,0.924,0.858,0.278,0.899,0.351,0.568,0.607,0.44,0.942,0.885,0.799,0.726,0.709,0.757,0.621,0.872,0.687,0.793,0.391,0.907,0.286,0.791,0.638,0.808,0.848,0.825,0.924,0.877,0.783,0.489,0.821,0.717,0.701,0.728,0.903,0.793,0.653,0.634,0.839,0.804,0.789,0.589,0.379,0.794,0.754,0.253,0.804,0.721,0.878,0.731,0.088,0.596,0.79,0.547,0.832,0.252,0.846,0.665,0.819,0.187,0.681,0.639,0.519,0.583,0.852,0.761,0.805,0.863,0.653,0.733,0.647,0.703,0.366,0.88,0.669,0.39,0.35,0.518,0.581,0.293,0.505,0.825,0.883,0.92,0.901,0.886,0.668,0.849,0.809,0.9,0.755,0.814,0.166,0.709,0.802,0.726,0.568,0.765,0.878,0.803,0.922,0.785,0.709,0.921,0.73,0.794,0.495,0.832,0.761,0.663,0.774,0.791,0.891,0.551,0.762,0.533,0.652,0.577,0.564,0.657,0.672,0.567,0.702,0.627,0.231,0.626,0.489,0.701,0.311,0.567,0.601,0.775,0.833,0.472,0.853,0.654,0.412,0.228,0.653,0.693,0.172,0.652,0.699,0.554,0.16,0.571,0.758,0.842,0.756,0.589,0.598,0.189,0.819,0.734,0.534,0.167,0.866,0.637,0.43,0.756,0.735,0.433,0.714,0.8,0.638,0.465,0.9,0.296,0.792,0.582,0.84,0.844,0.716,0.832,0.336,0.642,0.648,0.713,0.645,0.804,0.572,0.706,0.16,0.759,0.76,0.721,0.17,0.706,0.649,0.762,0.605,0.86,0.882,0.405,0.429,0.55,0.676,0.911,0.829,0.705,0.931,0.74,0.883,0.795,0.695,0.652,0.88,0.161,0.84,0.609,0.826,0.575,0.7,0.261,0.913,0.732,0.621,0.614,0.502,0.843,0.654,0.875,0.433,0.859,0.469,0.283,0.847,0.374,0.393,0.689,0.574,0.768,0.663,0.757,0.572,0.715,0.748,0.704,0.615,0.712,0.449,0.714,0.537,0.671,0.832,0.916,0.632,0.91,0.779,0.837,0.728,0.805,0.587,0.536,0.719,0.72,0.87,0.81,0.582,0.119,0.514,0.674,0.362,0.446,0.674,0.201,0.25,0.722,0.659,0.771,0.74,0.619,0.866,0.65,0.564,0.274,0.433,0.806,0.746,0.369,0.698,0.732,0.915,0.709,0.66,0.733,0.812,0.848,0.529,0.648,0.41,0.755,0.678,0.707,0.573,0.804,0.659,0.921,0.406,0.583,0.26,0.164,0.891,0.917,0.534,0.729,0.146,0.595,0.794,0.792,0.707,0.26,0.748,0.648,0.861,0.885,0.555,0.706,0.701,0.583,0.802,0.668,0.446,0.916,0.724,0.687,0.64,0.644,0.297,0.26,0.684,0.507,0.761,0.828,0.695,0.946,0.638,0.483,0.67,0.391,0.834,0.587,0.726,0.233,0.77,0.718,0.861,0.337,0.314,0.842,0.609,0.771,0.81,0.542,0.21,0.661,0.982,0.919,0.55,0.872,0.376,0.513,0.669,0.654,0.85,0.543,0.877,0.754,0.598,0.682,0.793,0.61,0.716,0.632,0.522,0.497,0.93,0.498,0.703,0.361,0.718,0.897,0.786,0.769,0.224,0.884,0.567,0.689,0.669,0.656,0.57,0.655,0.82,0.551,0.576,0.948,0.596,0.301,0.561,0.828,0.602,0.456,0.863,0.226,0.634,0.827,0.807,0.655,0.746,0.893,0.562,0.649,0.55,0.641,0.667,0.461,0.652,0.648,0.496,0.643,0.79,0.628,0.646,0.09,0.646,0.696,0.84,0.688,0.612,0.646,0.596,0.649,0.618,0.693,0.583,0.711,0.597,0.616,0.886,0.525,0.732,0.564,0.59,0.573,0.779,0.591,0.701,0.651,0.567,0.596,0.336,0.631,0.267,0.576,0.541,0.148,0.583,0.569,0.861,0.8,0.58,0.694,0.8,0.559,0.559,0.62,0.623,0.479,0.696,0.849,0.699,0.571,0.566,0.509,0.619,0.649,0.794,0.629,0.331,0.574,0.775,0.585,0.188,0.385,0.653,0.649,0.427,0.419,0.719,0.577,0.44,0.474,0.767,0.448,0.952,0.912,0.57,0.358,0.828,0.373,0.618,0.432,0.929,0.666,0.442,0.623,0.693,0.685,0.674,0.857,0.661,0.504,0.927,0.076,0.341,0.852,0.937,0.787,0.633,0.592,0.726,0.803,0.561,0.78,0.503,0.936,0.248,0.88,0.9,0.564,0.67,0.661,0.877,0.407,0.629,0.565,0.657,0.882,0.866,0.675,0.879,0.7,0.747,0.943,0.817,0.667,0.387,0.309,0.805,0.231,0.841,0.151,0.885,0.69,0.847,0.788,0.808,0.94,0.582,0.667,0.933,0.811,0.615,0.131,0.743,0.314,0.794,0.969,0.211,0.835,0.118,0.068,0.744,0.146,0.677,0.839,0.859,0.867,0.825,0.138,0.048,0.268,0.752,0.151,0.116,0.096,0.751,0.367,0.291,0.952,0.374,0.803,0.657,0.912,0.925,0.138,0.244,0.692,0.293,0.917,0.737,0.884,0.697,0.539,0.702,0.64,0.928,0.709,0.755,0.923,0.166,0.944,0.427,0.568,0.815,0.219,0.929,0.227,0.479,0.919,0.288,0.961,0.565,0.906,0.933,0.779,0.919,0.197,0.932,0.372,0.888,0.714,0.341,0.701,0.715,0.929,0.641,0.91,0.665,0.241,0.369,0.534,0.186,0.733,0.453,0.192,0.827,0.831,0.511,0.656,0.856,0.156,0.585,0.778,0.211,0.778,0.721,0.777,0.576,0.856,0.527,0.677,0.586,0.174,0.715,0.376,0.478,0.002,0.187,0.76,0.93,0.785,0.857,0.921,0.119,0.815,0.754,0.0,0.3,0.367,0.894,0.789,0.586,0.932,0.911,0.879,0.846,0.848,0.727,0.256,0.914,0.74,0.738,0.926,0.213,0.102,0.903,0.828,0.375,0.826,0.69,0.954,0.828,0.882,0.848,0.893,0.829,0.923,0.896,0.733,0.999,0.335,0.215,0.66,0.226,0.886,0.245,0.971,0.922,0.133,0.206,0.955,0.115,0.922,0.724,0.788,0.739,0.865,0.286,0.113,0.858,0.94,0.163,0.877,0.534,0.407,0.624,0.408,0.668,0.938,0.847,0.287,0.815,0.836,0.951,0.693,0.878,0.401,0.778,0.906,0.745,0.847,0.744,0.84,0.717,0.891,0.752,0.84,0.742,0.601,0.249,0.199,0.244,0.166,0.684,0.952,0.818,0.295,0.861,0.914,0.393,0.845,0.827,0.332,0.197,0.158,0.184,0.818,0.907,0.866,0.326,0.825,0.6,0.501,0.559,0.19,0.274,0.251,0.941,0.539,0.114,0.941,0.91,0.214,0.643,0.475,0.877,0.078,0.594,0.625,0.892,0.538,0.31,0.403,0.266,0.519,0.963,0.757,0.08,0.711,0.972,0.912,0.847,0.071,0.656,0.254,0.883,0.978,0.827,0.881,0.833,0.663,0.817,0.835,0.875,0.617,0.971,0.752,0.82,0.845,0.007,0.304,0.361,0.354,0.799,0.322,0.396,0.813,0.243,0.721,0.52,0.389,0.686,0.367,0.025,0.787,0.043,0.615,0.043,0.501,0.663,0.582,0.617,0.699,0.672,0.672,0.588,0.752,0.67,0.605,0.777,0.674,0.672,0.667,0.508,0.704,0.671,0.76,0.513,0.715,0.591,0.735,0.681,0.722,0.503,0.7,0.661,0.729,0.645,0.654,0.659,0.654,0.689,0.401,0.666,0.693,0.746,0.276,0.653,0.528,0.584,0.644,0.643,0.673,0.783,0.652,0.607,0.298,0.61,0.54,0.701,0.795,0.66,0.647,0.645,0.659,0.657,0.196,0.143,0.255,0.811,0.594,0.397,0.725,0.73,0.731,0.716,0.715,0.837,0.727,0.737,0.733,0.72,0.731,0.699,0.748,0.716,0.754,0.717,0.763,0.723,0.657,0.782,0.769,0.696,0.706,0.671,0.728,0.678,0.682,0.747,0.702,0.701,0.572,0.782,0.897,0.904,0.733,0.912,0.831,0.806,0.655,0.645,0.484,0.564,0.823,0.646,0.622,0.645,0.863,0.864,0.291,0.912,0.31,0.846,0.781,0.633,0.292,0.817,0.121,0.913,0.428,0.71,0.883,0.654,0.277,0.483,0.78,0.317,0.832,0.575,0.481,0.82,0.181,0.896,0.547,0.599,0.912,0.825,0.138,0.241,0.752,0.239,0.706,0.779,0.739,0.521,0.915,0.933,0.978,0.719,0.52,0.742,0.712,0.65,0.182,0.132,0.559,0.645,0.806,0.232,0.606,0.467,0.302,0.727,0.696,0.326,0.653,0.372,0.659,0.646,0.323,0.579,0.641,0.705,0.476,0.635,0.754,0.695,0.715,0.674,0.659,0.695,0.643,0.871,0.664,0.703,0.663,0.796,0.65,0.695,0.604,0.641,0.645,0.655,0.622,0.472,0.658,0.621,0.586,0.743,0.812,0.751,0.91,0.649,0.719,0.773,0.827,0.848,0.657,0.636,0.649,0.506,0.637,0.76,0.868,0.645,0.566,0.514,0.612,0.561,0.625,0.769,0.56,0.556,0.496,0.457,0.657,0.588,0.621,0.811,0.768,0.704,0.728,0.607,0.516,0.679,0.723,0.577,0.73,0.64,0.61,0.631,0.711,0.563,0.553,0.554,0.687,0.626,0.436,0.536,0.612,0.831,0.567,0.742,0.8,0.627,0.599,0.77,0.772,0.698,0.635,0.659,0.655,0.603,0.666,0.574,0.705,0.708,0.679,0.701,0.701,0.722,0.459,0.614,0.484,0.647,0.679,0.589,0.69,0.829,0.583,0.557,0.757,0.645,0.768,0.543,0.285,0.67,0.585,0.808,0.889,0.205,0.21,0.94,0.722,0.651,0.645,0.685,0.559,0.539,0.569,0.573,0.384,0.746,0.47,0.811,0.06,0.49,0.054,0.83,0.867,0.954,0.162,0.954,0.213,0.92,0.51,0.992,0.895,0.163,0.956,0.426,0.501,0.168,0.665,0.674,0.259,0.665,0.664,0.645,0.645,0.694,0.706,0.696,0.646,0.604,0.728,0.615,0.599,0.85,0.806,0.693,0.924,0.724,0.819,0.814,0.714,0.474,0.211,0.562,1.0,0.714,0.516,0.695,0.457,0.906,0.69,0.647,0.639,0.54,0.652,0.633,0.633,0.674,0.654,0.621,0.646,0.515,0.78,0.91,0.865,0.792,0.763,0.147,0.563,0.555,0.558,0.664,0.518,0.717,0.65,0.587,0.701,0.578,0.563,0.563,0.706,0.469,0.714,0.619,0.651,0.703,0.718,0.65,0.739,0.684,0.398,0.535,0.655,0.901,0.652,0.572,0.589,0.976,0.002,0.906,0.777,1.0,0.433,0.936,0.936,0.766,0.977,0.846,0.936,1.0,0.043,0.042,0.043,0.674,0.674,0.664,0.575,0.645,0.655,0.586,0.105,0.164,0.922,0.912,0.11,0.377,0.64,0.883,0.087,0.642,0.168,0.643,0.641,0.873,0.854,0.679,0.087,0.722,0.678,0.722,0.721,0.674,0.701,0.911,0.831,0.652,0.655,0.658,0.58,0.518,0.655,0.641,0.576,0.934,0.008,0.133,0.133,0.884,0.645,0.722,0.716,0.564,0.487,0.674,0.754,0.645,0.912,0.753,0.812,0.565,0.65,0.552,0.733,0.701,0.645,0.65,0.571,0.571,0.569,0.188,0.126,1.0,0.042,0.417,0.462,0.672,0.643,0.725,0.912,0.144,0.645,0.645,0.655,0.596,0.716,0.753,0.576,0.569,1.0,0.283,0.133,1.0,0.464,0.641,0.605,0.151,0.912,0.888,0.619,0.654,0.939,0.555,0.563,0.596,0.567,0.563,0.079,0.079,0.385,0.626,0.738,0.483,0.11,0.782,0.655,0.655,0.664,0.864,0.552,0.722,0.716,0.658,0.674,0.645,0.371,0.664,0.908,0.655,0.701,0.645,0.655,0.864,0.552,1.0,0.888,0.862,0.862,0.912,0.655,0.546,0.587,0.864,0.015,0.956,0.108,0.639,0.567,0.704'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub7_txt = ''\n",
    "for prob in list(sub7['pred'].values):\n",
    "    sub7_txt = sub7_txt+','+str(prob)\n",
    "sub7_txt = sub7_txt[1:]\n",
    "\n",
    "sub7_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8df3e13",
   "metadata": {},
   "source": [
    "### KMeans - 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "869d68ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw_50 = pd.read_csv('X_train_raw_50.csv')\n",
    "X_val_raw_50 = pd.read_csv('X_val_raw_50.csv')\n",
    "X_test_raw_50 = pd.read_csv('X_test_raw_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e24bbd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv('y_train_50.csv')\n",
    "y_val = pd.read_csv('y_val_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed449294",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw_50.set_index('unique_id',inplace=True)\n",
    "X_val_raw_50.set_index('unique_id',inplace=True)\n",
    "X_test_raw_50.set_index('unique_id',inplace=True)\n",
    "y_train.set_index('unique_id',inplace=True)\n",
    "y_val.set_index('unique_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49607337",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw_50.sort_index(inplace=True)\n",
    "X_val_raw_50.sort_index(inplace=True)\n",
    "X_test_raw_50.sort_index(inplace=True)\n",
    "y_train.sort_index(inplace=True)\n",
    "y_val.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bf95d8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cidem\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(max_depth=2,learning_rate=0.01,n_estimators=100,min_child_samples=100,colsample_bytree=0.5)\n",
    "lgbm.fit(X_train_raw_50,y_train)\n",
    "\n",
    "pred_train = pd.DataFrame(lgbm.predict_proba(X_train_raw_50)[:,1],columns=['pred'],index=X_train_raw_50.index)\n",
    "pred_val = pd.DataFrame(lgbm.predict_proba(X_val_raw_50)[:,1],columns=['pred'],index=X_val_raw_50.index)\n",
    "pred_test = pd.DataFrame(lgbm.predict_proba(X_test_raw_50)[:,1],columns=['pred'],index=X_test_raw_50.index)\n",
    "\n",
    "pred_train = pd.merge(pred_train,y_train,how='left',left_index=True, right_index=True)\n",
    "pred_val = pd.merge(pred_val,y_val,how='left',left_index=True, right_index=True)\n",
    "\n",
    "roc_train = roc_auc_score(pred_train['female_label'],pred_train['pred'])\n",
    "roc_val = roc_auc_score(pred_val['female_label'],pred_val['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e44f761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC:  0.8338222385360966\n",
      "Val ROC:  0.8170476020180983\n"
     ]
    }
   ],
   "source": [
    "print('Train ROC: ',roc_train)\n",
    "print('Val ROC: ',roc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e0dd00b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_rate_df = pd.DataFrame()\n",
    "\n",
    "for th in np.arange(0,1,0.1):\n",
    "\n",
    "    pred_train['pred_binary'] = np.where(pred_train['pred']>=th,1,0)\n",
    "    pred_val['pred_binary'] = np.where(pred_val['pred']>=th,1,0)\n",
    "\n",
    "    err_rate1_train = 1-(pred_train[pred_train['female_label']==1]['pred_binary'].sum()/pred_train[pred_train['female_label']==1]['pred_binary'].count())\n",
    "    err_rate0_train = pred_train[pred_train['female_label']==0]['pred_binary'].sum()/pred_train[pred_train['female_label']==0]['pred_binary'].count()\n",
    "    err_rate_train = err_rate1_train+err_rate0_train\n",
    "\n",
    "    err_rate1_val = 1-(pred_val[pred_val['female_label']==1]['pred_binary'].sum()/pred_val[pred_val['female_label']==1]['pred_binary'].count())\n",
    "    err_rate0_val = pred_val[pred_val['female_label']==0]['pred_binary'].sum()/pred_val[pred_val['female_label']==0]['pred_binary'].count()\n",
    "    err_rate_val = err_rate1_val+err_rate0_val\n",
    "\n",
    "    err_rate_df_tmp = pd.DataFrame({'threshold':[th],\n",
    "                                    'err_rate1_train':[err_rate1_train],\n",
    "                                    'err_rate0_train':[err_rate0_train],\n",
    "                                    'err_rate_train':[err_rate_train],\n",
    "                                    'err_rate1_val':[err_rate1_val],\n",
    "                                    'err_rate0_val':[err_rate0_val],\n",
    "                                    'err_rate_val':[err_rate_val]\n",
    "                                   })\n",
    "    err_rate_df = pd.concat([err_rate_df,err_rate_df_tmp])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9e1de854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>err_rate1_train</th>\n",
       "      <th>err_rate0_train</th>\n",
       "      <th>err_rate_train</th>\n",
       "      <th>err_rate1_val</th>\n",
       "      <th>err_rate0_val</th>\n",
       "      <th>err_rate_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.957474</td>\n",
       "      <td>0.958834</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.956072</td>\n",
       "      <td>0.957429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.020394</td>\n",
       "      <td>0.793814</td>\n",
       "      <td>0.814209</td>\n",
       "      <td>0.031208</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.852913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.354861</td>\n",
       "      <td>0.144330</td>\n",
       "      <td>0.499191</td>\n",
       "      <td>0.374491</td>\n",
       "      <td>0.124031</td>\n",
       "      <td>0.498522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.470088</td>\n",
       "      <td>0.073454</td>\n",
       "      <td>0.543542</td>\n",
       "      <td>0.497965</td>\n",
       "      <td>0.041344</td>\n",
       "      <td>0.539308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.672332</td>\n",
       "      <td>0.016108</td>\n",
       "      <td>0.688440</td>\n",
       "      <td>0.702849</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.726105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  err_rate1_train  err_rate0_train  err_rate_train  err_rate1_val  \\\n",
       "0        0.0         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.1         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.2         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.3         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.4         0.001360         0.957474        0.958834       0.001357   \n",
       "0        0.5         0.020394         0.793814        0.814209       0.031208   \n",
       "0        0.6         0.354861         0.144330        0.499191       0.374491   \n",
       "0        0.7         0.470088         0.073454        0.543542       0.497965   \n",
       "0        0.8         0.672332         0.016108        0.688440       0.702849   \n",
       "0        0.9         1.000000         0.000000        1.000000       1.000000   \n",
       "\n",
       "   err_rate0_val  err_rate_val  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       0.956072      0.957429  \n",
       "0       0.821705      0.852913  \n",
       "0       0.124031      0.498522  \n",
       "0       0.041344      0.539308  \n",
       "0       0.023256      0.726105  \n",
       "0       0.000000      1.000000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_rate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ad10db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.823875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.791611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.840235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.819388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.841512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7982</th>\n",
       "      <td>0.590442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7990</th>\n",
       "      <td>0.564747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7993</th>\n",
       "      <td>0.590442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>0.590442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>0.590442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2380 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred\n",
       "unique_id          \n",
       "9          0.823875\n",
       "18         0.791611\n",
       "21         0.840235\n",
       "25         0.819388\n",
       "31         0.841512\n",
       "...             ...\n",
       "7982       0.590442\n",
       "7990       0.564747\n",
       "7993       0.590442\n",
       "7994       0.590442\n",
       "7998       0.590442\n",
       "\n",
       "[2380 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "efb4cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16691228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>108</td>\n",
       "      <td>0.791611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unique_id      pred\n",
       "28        108  0.791611"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test[pred_test['unique_id']==108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66f94f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.823875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.791611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0.840235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.819388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>0.841512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>7982</td>\n",
       "      <td>2375</td>\n",
       "      <td>0.590442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>7990</td>\n",
       "      <td>2376</td>\n",
       "      <td>0.564747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>7993</td>\n",
       "      <td>2377</td>\n",
       "      <td>0.590442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>7994</td>\n",
       "      <td>2378</td>\n",
       "      <td>0.590442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>7998</td>\n",
       "      <td>2379</td>\n",
       "      <td>0.590442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2380 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id  index      pred\n",
       "0             9      0  0.823875\n",
       "1            18      1  0.791611\n",
       "2            21      2  0.840235\n",
       "3            25      3  0.819388\n",
       "4            31      4  0.841512\n",
       "...         ...    ...       ...\n",
       "2375       7982   2375  0.590442\n",
       "2376       7990   2376  0.564747\n",
       "2377       7993   2377  0.590442\n",
       "2378       7994   2378  0.590442\n",
       "2379       7998   2379  0.590442\n",
       "\n",
       "[2380 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub8 = pd.merge(id_test_df,pred_test.reset_index(),how='left',on='unique_id')\n",
    "sub8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a9f114fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub8['pred'] = sub8['pred'].apply(lambda x: round(x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ff032c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.824,0.792,0.84,0.819,0.842,0.847,0.683,0.416,0.7,0.8,0.595,0.398,0.782,0.845,0.807,0.821,0.636,0.474,0.794,0.798,0.84,0.708,0.8,0.8,0.847,0.843,0.793,0.846,0.792,0.663,0.82,0.821,0.789,0.823,0.846,0.817,0.559,0.598,0.84,0.817,0.795,0.804,0.683,0.831,0.839,0.818,0.845,0.574,0.598,0.764,0.381,0.807,0.751,0.388,0.562,0.401,0.79,0.829,0.846,0.842,0.826,0.55,0.476,0.799,0.845,0.802,0.842,0.811,0.808,0.836,0.846,0.817,0.802,0.825,0.788,0.574,0.791,0.845,0.847,0.818,0.547,0.797,0.847,0.425,0.845,0.845,0.786,0.845,0.805,0.797,0.845,0.827,0.771,0.846,0.531,0.753,0.691,0.684,0.645,0.844,0.836,0.827,0.838,0.69,0.785,0.69,0.588,0.6,0.826,0.648,0.818,0.819,0.816,0.798,0.506,0.815,0.677,0.846,0.799,0.755,0.842,0.845,0.569,0.623,0.813,0.792,0.844,0.829,0.425,0.448,0.842,0.689,0.522,0.821,0.807,0.754,0.545,0.699,0.588,0.842,0.485,0.78,0.819,0.797,0.7,0.841,0.789,0.798,0.471,0.794,0.785,0.752,0.776,0.846,0.639,0.744,0.847,0.81,0.847,0.785,0.814,0.842,0.829,0.537,0.847,0.843,0.731,0.847,0.817,0.518,0.825,0.698,0.723,0.847,0.812,0.793,0.728,0.687,0.782,0.745,0.598,0.547,0.836,0.559,0.708,0.846,0.84,0.845,0.835,0.843,0.793,0.502,0.643,0.815,0.74,0.523,0.798,0.582,0.844,0.823,0.79,0.845,0.843,0.796,0.7,0.719,0.547,0.5,0.603,0.568,0.829,0.805,0.499,0.847,0.794,0.655,0.826,0.845,0.564,0.827,0.676,0.789,0.559,0.731,0.842,0.64,0.499,0.812,0.559,0.425,0.382,0.825,0.656,0.845,0.56,0.839,0.845,0.738,0.843,0.846,0.436,0.825,0.793,0.845,0.846,0.574,0.785,0.438,0.827,0.792,0.607,0.421,0.836,0.83,0.393,0.587,0.842,0.84,0.569,0.391,0.821,0.773,0.551,0.839,0.804,0.847,0.687,0.841,0.795,0.471,0.65,0.739,0.817,0.559,0.789,0.719,0.735,0.744,0.727,0.81,0.84,0.836,0.672,0.716,0.69,0.427,0.822,0.83,0.588,0.841,0.53,0.403,0.518,0.779,0.559,0.406,0.818,0.427,0.729,0.816,0.841,0.811,0.826,0.84,0.847,0.803,0.837,0.847,0.843,0.819,0.847,0.715,0.413,0.842,0.793,0.563,0.846,0.559,0.774,0.549,0.779,0.719,0.533,0.481,0.826,0.777,0.588,0.793,0.818,0.59,0.48,0.818,0.475,0.846,0.703,0.596,0.706,0.845,0.427,0.53,0.781,0.84,0.745,0.829,0.75,0.823,0.79,0.538,0.795,0.845,0.45,0.532,0.84,0.827,0.559,0.846,0.774,0.67,0.819,0.847,0.847,0.793,0.569,0.815,0.802,0.826,0.518,0.794,0.84,0.44,0.842,0.828,0.836,0.84,0.711,0.759,0.826,0.791,0.797,0.782,0.68,0.794,0.436,0.669,0.817,0.846,0.52,0.821,0.847,0.839,0.448,0.845,0.574,0.8,0.814,0.835,0.792,0.847,0.846,0.796,0.588,0.804,0.781,0.735,0.84,0.69,0.59,0.669,0.827,0.622,0.663,0.59,0.794,0.587,0.747,0.464,0.799,0.694,0.526,0.697,0.82,0.793,0.658,0.836,0.598,0.514,0.559,0.402,0.754,0.742,0.754,0.572,0.379,0.846,0.485,0.561,0.847,0.772,0.721,0.847,0.421,0.734,0.79,0.723,0.827,0.53,0.601,0.842,0.699,0.559,0.795,0.816,0.559,0.846,0.607,0.781,0.84,0.847,0.813,0.845,0.847,0.572,0.821,0.664,0.841,0.842,0.53,0.784,0.54,0.817,0.59,0.711,0.37,0.846,0.582,0.686,0.826,0.84,0.559,0.793,0.529,0.836,0.847,0.424,0.471,0.514,0.822,0.812,0.794,0.539,0.539,0.815,0.559,0.823,0.68,0.847,0.836,0.552,0.546,0.486,0.824,0.815,0.845,0.59,0.448,0.847,0.588,0.843,0.821,0.59,0.761,0.805,0.845,0.537,0.452,0.384,0.388,0.596,0.677,0.513,0.605,0.485,0.457,0.588,0.812,0.842,0.775,0.847,0.842,0.827,0.514,0.821,0.718,0.53,0.846,0.712,0.715,0.497,0.72,0.631,0.53,0.831,0.562,0.471,0.839,0.559,0.47,0.628,0.588,0.559,0.833,0.806,0.792,0.847,0.793,0.816,0.356,0.809,0.572,0.589,0.827,0.508,0.557,0.801,0.572,0.776,0.833,0.44,0.606,0.598,0.793,0.594,0.374,0.486,0.826,0.806,0.782,0.781,0.819,0.82,0.847,0.507,0.819,0.845,0.805,0.847,0.844,0.607,0.83,0.79,0.792,0.826,0.69,0.374,0.754,0.728,0.846,0.448,0.559,0.751,0.827,0.846,0.78,0.788,0.53,0.793,0.559,0.842,0.841,0.755,0.844,0.843,0.408,0.587,0.523,0.836,0.682,0.419,0.457,0.547,0.81,0.812,0.82,0.843,0.789,0.59,0.426,0.833,0.79,0.84,0.784,0.813,0.572,0.418,0.839,0.588,0.59,0.375,0.645,0.828,0.799,0.822,0.653,0.588,0.812,0.522,0.562,0.683,0.819,0.71,0.839,0.559,0.443,0.817,0.779,0.768,0.605,0.519,0.793,0.843,0.559,0.768,0.415,0.588,0.559,0.554,0.842,0.847,0.846,0.807,0.521,0.818,0.816,0.559,0.685,0.684,0.842,0.837,0.548,0.492,0.705,0.451,0.584,0.831,0.846,0.769,0.393,0.679,0.747,0.66,0.429,0.641,0.573,0.694,0.573,0.671,0.842,0.843,0.588,0.825,0.799,0.789,0.555,0.836,0.611,0.815,0.794,0.486,0.81,0.483,0.827,0.588,0.835,0.511,0.751,0.789,0.842,0.687,0.764,0.435,0.746,0.598,0.846,0.404,0.813,0.773,0.469,0.838,0.562,0.464,0.75,0.563,0.8,0.821,0.8,0.621,0.838,0.846,0.813,0.839,0.781,0.831,0.778,0.816,0.825,0.559,0.58,0.798,0.635,0.738,0.838,0.472,0.773,0.814,0.559,0.589,0.84,0.53,0.559,0.836,0.836,0.846,0.421,0.598,0.847,0.792,0.607,0.491,0.843,0.703,0.388,0.598,0.836,0.559,0.574,0.588,0.596,0.553,0.75,0.765,0.822,0.59,0.847,0.775,0.845,0.573,0.604,0.798,0.831,0.512,0.559,0.8,0.663,0.71,0.741,0.574,0.781,0.428,0.833,0.63,0.559,0.426,0.818,0.479,0.673,0.843,0.752,0.769,0.837,0.84,0.846,0.559,0.815,0.574,0.734,0.794,0.841,0.846,0.823,0.805,0.842,0.84,0.602,0.766,0.771,0.636,0.846,0.785,0.588,0.845,0.801,0.83,0.766,0.598,0.559,0.589,0.59,0.498,0.801,0.588,0.846,0.587,0.745,0.8,0.846,0.823,0.819,0.56,0.805,0.691,0.6,0.762,0.574,0.568,0.559,0.821,0.668,0.579,0.794,0.694,0.829,0.847,0.606,0.847,0.597,0.557,0.512,0.811,0.767,0.536,0.833,0.663,0.718,0.598,0.795,0.835,0.705,0.84,0.37,0.533,0.751,0.559,0.794,0.602,0.566,0.378,0.845,0.59,0.572,0.579,0.783,0.427,0.537,0.674,0.839,0.84,0.771,0.441,0.386,0.666,0.463,0.794,0.759,0.588,0.572,0.671,0.497,0.445,0.703,0.795,0.595,0.609,0.834,0.842,0.59,0.657,0.843,0.753,0.59,0.819,0.796,0.393,0.81,0.499,0.632,0.494,0.811,0.588,0.629,0.494,0.681,0.843,0.847,0.82,0.598,0.825,0.847,0.399,0.736,0.794,0.836,0.59,0.694,0.83,0.841,0.81,0.784,0.792,0.775,0.391,0.823,0.728,0.508,0.846,0.68,0.764,0.845,0.816,0.756,0.669,0.802,0.559,0.574,0.598,0.809,0.837,0.757,0.468,0.833,0.55,0.77,0.588,0.536,0.842,0.821,0.781,0.805,0.79,0.645,0.596,0.84,0.657,0.785,0.588,0.768,0.559,0.847,0.559,0.613,0.847,0.797,0.846,0.719,0.808,0.427,0.817,0.818,0.787,0.77,0.622,0.752,0.59,0.573,0.84,0.819,0.821,0.536,0.452,0.803,0.718,0.415,0.843,0.588,0.815,0.747,0.59,0.572,0.843,0.588,0.845,0.608,0.55,0.588,0.815,0.483,0.588,0.59,0.598,0.59,0.846,0.845,0.831,0.818,0.588,0.84,0.588,0.782,0.402,0.598,0.83,0.353,0.59,0.588,0.452,0.546,0.485,0.822,0.823,0.59,0.825,0.834,0.573,0.773,0.837,0.65,0.819,0.843,0.597,0.609,0.796,0.7,0.59,0.843,0.813,0.797,0.842,0.818,0.793,0.797,0.572,0.791,0.474,0.773,0.77,0.574,0.765,0.725,0.805,0.781,0.813,0.522,0.59,0.562,0.549,0.59,0.768,0.559,0.754,0.547,0.631,0.588,0.596,0.603,0.48,0.562,0.653,0.799,0.789,0.793,0.847,0.787,0.551,0.569,0.559,0.693,0.504,0.68,0.572,0.566,0.483,0.533,0.824,0.84,0.559,0.574,0.59,0.564,0.608,0.559,0.68,0.551,0.847,0.588,0.573,0.598,0.729,0.565,0.671,0.702,0.537,0.401,0.782,0.498,0.841,0.562,0.602,0.825,0.59,0.846,0.438,0.559,0.738,0.588,0.588,0.773,0.481,0.59,0.411,0.837,0.573,0.598,0.559,0.573,0.798,0.815,0.611,0.79,0.812,0.569,0.461,0.537,0.559,0.847,0.816,0.649,0.72,0.59,0.705,0.622,0.607,0.572,0.843,0.477,0.806,0.515,0.833,0.559,0.574,0.367,0.795,0.684,0.588,0.69,0.59,0.782,0.664,0.807,0.522,0.826,0.575,0.451,0.831,0.566,0.543,0.577,0.477,0.613,0.598,0.598,0.596,0.588,0.588,0.585,0.53,0.694,0.537,0.678,0.803,0.59,0.839,0.794,0.588,0.827,0.823,0.817,0.598,0.845,0.75,0.804,0.574,0.607,0.827,0.664,0.585,0.579,0.53,0.676,0.414,0.539,0.588,0.361,0.569,0.72,0.533,0.782,0.805,0.559,0.845,0.588,0.559,0.353,0.534,0.821,0.841,0.477,0.711,0.747,0.831,0.767,0.795,0.598,0.843,0.777,0.559,0.836,0.75,0.799,0.559,0.588,0.559,0.769,0.465,0.847,0.629,0.663,0.565,0.59,0.796,0.843,0.576,0.638,0.425,0.576,0.77,0.841,0.733,0.465,0.785,0.588,0.842,0.842,0.501,0.739,0.773,0.559,0.576,0.706,0.53,0.71,0.613,0.59,0.559,0.588,0.493,0.426,0.613,0.384,0.68,0.758,0.742,0.842,0.59,0.434,0.735,0.521,0.846,0.559,0.841,0.424,0.77,0.598,0.818,0.562,0.534,0.588,0.559,0.771,0.847,0.59,0.454,0.559,0.742,0.842,0.559,0.785,0.559,0.548,0.6,0.596,0.847,0.596,0.751,0.574,0.559,0.59,0.768,0.53,0.607,0.59,0.486,0.464,0.846,0.558,0.59,0.55,0.588,0.6,0.843,0.792,0.521,0.804,0.59,0.6,0.6,0.574,0.537,0.613,0.68,0.806,0.792,0.836,0.559,0.562,0.559,0.807,0.654,0.413,0.843,0.426,0.559,0.674,0.783,0.588,0.596,0.607,0.559,0.588,0.562,0.59,0.588,0.569,0.588,0.502,0.582,0.588,0.808,0.588,0.59,0.397,0.59,0.706,0.777,0.764,0.559,0.59,0.579,0.59,0.559,0.588,0.564,0.611,0.559,0.559,0.836,0.537,0.61,0.598,0.588,0.59,0.816,0.559,0.588,0.69,0.59,0.588,0.527,0.699,0.566,0.59,0.596,0.383,0.588,0.6,0.773,0.677,0.59,0.77,0.729,0.59,0.656,0.545,0.59,0.572,0.51,0.845,0.59,0.59,0.735,0.598,0.572,0.821,0.6,0.537,0.59,0.559,0.767,0.45,0.38,0.554,0.59,0.697,0.588,0.59,0.574,0.501,0.551,0.59,0.607,0.53,0.821,0.586,0.59,0.572,0.827,0.559,0.664,0.684,0.833,0.547,0.591,0.588,0.54,0.59,0.572,0.68,0.606,0.51,0.751,0.466,0.582,0.719,0.818,0.788,0.759,0.6,0.699,0.809,0.492,0.75,0.59,0.59,0.444,0.673,0.793,0.595,0.587,0.794,0.831,0.654,0.735,0.65,0.776,0.823,0.838,0.59,0.825,0.666,0.802,0.684,0.781,0.588,0.588,0.436,0.806,0.537,0.603,0.427,0.781,0.562,0.59,0.706,0.576,0.831,0.747,0.59,0.817,0.839,0.763,0.59,0.78,0.465,0.842,0.834,0.466,0.833,0.5,0.404,0.594,0.492,0.73,0.83,0.559,0.795,0.786,0.411,0.486,0.418,0.678,0.51,0.486,0.569,0.841,0.45,0.504,0.838,0.57,0.767,0.811,0.745,0.796,0.533,0.582,0.707,0.507,0.669,0.622,0.773,0.835,0.566,0.59,0.769,0.843,0.774,0.572,0.829,0.532,0.683,0.463,0.59,0.818,0.671,0.827,0.438,0.67,0.821,0.518,0.796,0.55,0.678,0.581,0.779,0.792,0.554,0.842,0.478,0.778,0.574,0.457,0.764,0.78,0.843,0.678,0.698,0.573,0.505,0.574,0.565,0.394,0.592,0.559,0.554,0.786,0.753,0.602,0.677,0.847,0.454,0.588,0.741,0.537,0.805,0.579,0.683,0.559,0.845,0.569,0.596,0.559,0.497,0.606,0.484,0.588,0.59,0.481,0.785,0.805,0.797,0.678,0.82,0.537,0.603,0.804,0.59,0.565,0.512,0.829,0.81,0.754,0.595,0.814,0.735,0.715,0.838,0.53,0.477,0.753,0.719,0.671,0.741,0.457,0.515,0.829,0.679,0.547,0.735,0.749,0.834,0.786,0.841,0.765,0.798,0.787,0.687,0.838,0.59,0.59,0.685,0.56,0.644,0.59,0.734,0.553,0.814,0.78,0.508,0.551,0.59,0.582,0.824,0.588,0.711,0.706,0.649,0.569,0.554,0.811,0.796,0.576,0.838,0.524,0.526,0.699,0.59,0.573,0.831,0.78,0.576,0.731,0.805,0.8,0.587,0.822,0.432,0.765,0.741,0.608,0.728,0.771,0.598,0.534,0.796,0.6,0.6,0.572,0.669,0.582,0.403,0.383,0.433,0.512,0.829,0.622,0.492,0.797,0.648,0.443,0.61,0.606,0.597,0.505,0.429,0.477,0.581,0.717,0.741,0.544,0.818,0.487,0.659,0.74,0.579,0.463,0.492,0.681,0.669,0.495,0.619,0.814,0.471,0.584,0.592,0.749,0.59,0.586,0.592,0.781,0.75,0.508,0.582,0.449,0.559,0.835,0.772,0.562,0.59,0.704,0.598,0.771,0.576,0.588,0.59,0.678,0.606,0.711,0.65,0.565,0.579,0.689,0.608,0.778,0.59,0.606,0.581,0.684,0.799,0.59,0.552,0.576,0.569,0.603,0.59,0.425,0.699,0.59,0.821,0.491,0.552,0.588,0.582,0.552,0.589,0.533,0.709,0.533,0.659,0.59,0.562,0.588,0.596,0.59,0.59,0.565,0.59,0.59,0.562,0.559,0.59,0.59,0.606,0.486,0.588,0.59,0.669,0.529,0.588,0.559,0.6,0.588,0.598,0.462,0.598,0.597,0.641,0.588,0.588,0.59,0.59,0.588,0.448,0.596,0.559,0.59,0.562,0.59,0.492,0.573,0.588,0.59,0.59,0.59,0.65,0.59,0.579,0.59,0.59,0.695,0.598,0.59,0.59,0.59,0.606,0.59,0.554,0.562,0.562,0.569,0.562,0.554,0.59,0.588,0.588,0.703,0.686,0.596,0.59,0.598,0.59,0.598,0.59,0.63,0.559,0.562,0.59,0.636,0.59,0.641,0.559,0.603,0.59,0.607,0.769,0.59,0.59,0.59,0.559,0.622,0.59,0.639,0.566,0.603,0.613,0.781,0.613,0.613,0.588,0.59,0.559,0.588,0.588,0.588,0.743,0.588,0.59,0.59,0.59,0.59,0.518,0.59,0.536,0.59,0.59,0.588,0.576,0.588,0.59,0.59,0.596,0.59,0.596,0.7,0.566,0.566,0.572,0.569,0.588,0.547,0.566,0.59,0.569,0.59,0.569,0.572,0.59,0.613,0.492,0.534,0.59,0.495,0.611,0.6,0.565,0.661,0.699,0.707,0.699,0.597,0.491,0.59,0.588,0.588,0.565,0.565,0.59,0.575,0.565,0.554,0.59,0.562,0.562,0.743,0.559,0.565,0.603,0.59,0.59,0.588,0.59,0.559,0.588,0.588,0.576,0.559,0.68,0.596,0.68,0.588,0.59,0.59,0.588,0.613,0.588,0.598,0.59,0.606,0.588,0.598,0.59,0.59,0.59,0.562,0.59,0.588,0.59,0.588,0.559,0.59,0.613,0.694,0.59,0.588,0.598,0.598,0.613,0.59,0.588,0.59,0.59,0.559,0.588,0.598,0.59,0.588,0.559,0.559,0.59,0.59,0.596,0.7,0.559,0.559,0.569,0.588,0.59,0.559,0.587,0.592,0.598,0.588,0.59,0.484,0.502,0.588,0.598,0.562,0.596,0.562,0.559,0.59,0.59,0.59,0.562,0.59,0.562,0.59,0.477,0.669,0.559,0.606,0.59,0.59,0.6,0.559,0.641,0.59,0.596,0.59,0.559,0.559,0.59,0.59,0.587,0.59,0.59,0.59,0.562,0.59,0.59,0.59,0.573,0.59,0.566,0.588,0.652,0.559,0.59,0.77,0.559,0.559,0.615,0.588,0.641,0.549,0.565,0.666,0.659,0.65,0.596,0.537,0.559,0.59,0.559,0.588,0.59,0.59,0.588,0.588,0.59,0.59,0.588,0.588,0.59,0.6,0.533,0.59,0.59,0.669,0.606,0.745,0.48,0.699,0.533,0.735,0.59,0.669,0.6,0.59,0.59,0.554,0.659,0.59,0.588,0.59,0.59,0.59,0.59,0.588,0.59,0.596,0.596,0.59,0.562,0.518,0.59,0.569,0.59,0.674,0.59,0.59,0.59,0.559,0.588,0.59,0.59,0.59,0.566,0.59,0.746,0.59,0.54,0.588,0.59,0.769,0.596,0.588,0.588,0.562,0.59,0.59,0.59,0.588,0.588,0.59,0.59,0.59,0.598,0.59,0.59,0.59,0.59,0.59,0.59,0.559,0.559,0.572,0.537,0.588,0.562,0.59,0.59,0.59,0.59,0.59,0.59,0.562,0.588,0.59,0.59,0.59,0.59,0.59,0.596,0.598,0.59,0.588,0.59,0.598,0.59,0.59,0.59,0.641,0.59,0.59,0.599,0.59,0.585,0.59,0.596,0.672,0.669,0.598,0.59,0.669,0.533,0.533,0.533,0.59,0.59,0.59,0.59,0.588,0.59,0.562,0.488,0.59,0.669,0.59,0.569,0.569,0.59,0.59,0.59,0.588,0.59,0.59,0.588,0.598,0.607,0.596,0.59,0.59,0.59,0.59,0.59,0.59,0.59,0.59,0.59,0.59,0.59,0.59,0.59,0.533,0.59,0.59,0.59,0.596,0.59,0.576,0.576,0.702,0.59,0.59,0.59,0.59,0.59,0.59,0.596,0.59,0.59,0.59,0.606,0.559,0.588,0.562,0.59,0.59,0.59,0.59,0.59,0.59,0.59,0.59,0.582,0.641,0.533,0.59,0.515,0.59,0.59,0.59,0.611,0.59,0.59,0.59,0.59,0.59,0.59,0.59,0.59,0.59,0.59,0.59,0.576,0.59,0.59,0.59,0.59,0.59,0.59,0.59,0.59,0.59,0.621,0.59,0.59,0.59,0.59,0.59,0.59,0.59,0.59,0.562,0.59,0.59,0.569,0.596,0.59,0.59,0.59,0.596,0.59,0.59,0.59,0.59,0.59,0.59,0.562,0.59,0.59,0.59,0.59,0.59,0.59,0.59,0.59,0.606,0.6,0.59,0.59,0.59,0.59,0.59,0.59,0.596,0.59,0.59,0.565,0.59,0.59,0.59'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub8_txt = ''\n",
    "for prob in list(sub8['pred'].values):\n",
    "    sub8_txt = sub8_txt+','+str(prob)\n",
    "sub8_txt = sub8_txt[1:]\n",
    "\n",
    "sub8_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4326ad7",
   "metadata": {},
   "source": [
    "### Random Tree - 10-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2403bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bag_df_10_20 = pd.read_csv('train_bag_df_10_20.csv')\n",
    "val_bag_df_10_20 = pd.read_csv('val_bag_df_10_20.csv')\n",
    "test_bag_df_10_20 = pd.read_csv('test_bag_df_10_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ef93d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv('y_train_50.csv')\n",
    "y_val = pd.read_csv('y_val_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c3b78d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bag_df_10_20.set_index('unique_id',inplace=True)\n",
    "val_bag_df_10_20.set_index('unique_id',inplace=True)\n",
    "test_bag_df_10_20.set_index('unique_id',inplace=True)\n",
    "y_train.set_index('unique_id',inplace=True)\n",
    "y_val.set_index('unique_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3468b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bag_df_10_20.sort_index(inplace=True)\n",
    "val_bag_df_10_20.sort_index(inplace=True)\n",
    "test_bag_df_10_20.sort_index(inplace=True)\n",
    "y_train.sort_index(inplace=True)\n",
    "y_val.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e0e610df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bag_df_10_20.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "val_bag_df_10_20.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "test_bag_df_10_20.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0a9e6fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cidem\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(max_depth=2,learning_rate=0.01,n_estimators=100,min_child_samples=100,colsample_bytree=0.5)\n",
    "lgbm.fit(train_bag_df_10_20,y_train)\n",
    "\n",
    "pred_train = pd.DataFrame(lgbm.predict_proba(train_bag_df_10_20)[:,1],columns=['pred'],index=train_bag_df_10_20.index)\n",
    "pred_val = pd.DataFrame(lgbm.predict_proba(val_bag_df_10_20)[:,1],columns=['pred'],index=val_bag_df_10_20.index)\n",
    "pred_test = pd.DataFrame(lgbm.predict_proba(test_bag_df_10_20)[:,1],columns=['pred'],index=test_bag_df_10_20.index)\n",
    "\n",
    "pred_train = pd.merge(pred_train,y_train,how='left',left_index=True, right_index=True)\n",
    "pred_val = pd.merge(pred_val,y_val,how='left',left_index=True, right_index=True)\n",
    "\n",
    "roc_train = roc_auc_score(pred_train['female_label'],pred_train['pred'])\n",
    "roc_val = roc_auc_score(pred_val['female_label'],pred_val['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cb2d6f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC:  0.8277067987973676\n",
      "Val ROC:  0.8226310308920515\n"
     ]
    }
   ],
   "source": [
    "print('Train ROC: ',roc_train)\n",
    "print('Val ROC: ',roc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8cd539c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_rate_df = pd.DataFrame()\n",
    "\n",
    "for th in np.arange(0,1,0.1):\n",
    "\n",
    "    pred_train['pred_binary'] = np.where(pred_train['pred']>=th,1,0)\n",
    "    pred_val['pred_binary'] = np.where(pred_val['pred']>=th,1,0)\n",
    "\n",
    "    err_rate1_train = 1-(pred_train[pred_train['female_label']==1]['pred_binary'].sum()/pred_train[pred_train['female_label']==1]['pred_binary'].count())\n",
    "    err_rate0_train = pred_train[pred_train['female_label']==0]['pred_binary'].sum()/pred_train[pred_train['female_label']==0]['pred_binary'].count()\n",
    "    err_rate_train = err_rate1_train+err_rate0_train\n",
    "\n",
    "    err_rate1_val = 1-(pred_val[pred_val['female_label']==1]['pred_binary'].sum()/pred_val[pred_val['female_label']==1]['pred_binary'].count())\n",
    "    err_rate0_val = pred_val[pred_val['female_label']==0]['pred_binary'].sum()/pred_val[pred_val['female_label']==0]['pred_binary'].count()\n",
    "    err_rate_val = err_rate1_val+err_rate0_val\n",
    "\n",
    "    err_rate_df_tmp = pd.DataFrame({'threshold':[th],\n",
    "                                    'err_rate1_train':[err_rate1_train],\n",
    "                                    'err_rate0_train':[err_rate0_train],\n",
    "                                    'err_rate_train':[err_rate_train],\n",
    "                                    'err_rate1_val':[err_rate1_val],\n",
    "                                    'err_rate0_val':[err_rate0_val],\n",
    "                                    'err_rate_val':[err_rate_val]\n",
    "                                   })\n",
    "    err_rate_df = pd.concat([err_rate_df,err_rate_df_tmp])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "02190e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>err_rate1_train</th>\n",
       "      <th>err_rate0_train</th>\n",
       "      <th>err_rate_train</th>\n",
       "      <th>err_rate1_val</th>\n",
       "      <th>err_rate0_val</th>\n",
       "      <th>err_rate_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>0.952964</td>\n",
       "      <td>0.956363</td>\n",
       "      <td>0.008141</td>\n",
       "      <td>0.943152</td>\n",
       "      <td>0.951294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.058124</td>\n",
       "      <td>0.645619</td>\n",
       "      <td>0.703742</td>\n",
       "      <td>0.065129</td>\n",
       "      <td>0.669251</td>\n",
       "      <td>0.734380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.139361</td>\n",
       "      <td>0.449742</td>\n",
       "      <td>0.589103</td>\n",
       "      <td>0.150611</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.595055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.447995</td>\n",
       "      <td>0.068943</td>\n",
       "      <td>0.516938</td>\n",
       "      <td>0.476255</td>\n",
       "      <td>0.064599</td>\n",
       "      <td>0.540855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.651937</td>\n",
       "      <td>0.011598</td>\n",
       "      <td>0.663535</td>\n",
       "      <td>0.663501</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.679005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  err_rate1_train  err_rate0_train  err_rate_train  err_rate1_val  \\\n",
       "0        0.0         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.1         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.2         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.3         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.4         0.003399         0.952964        0.956363       0.008141   \n",
       "0        0.5         0.058124         0.645619        0.703742       0.065129   \n",
       "0        0.6         0.139361         0.449742        0.589103       0.150611   \n",
       "0        0.7         0.447995         0.068943        0.516938       0.476255   \n",
       "0        0.8         0.651937         0.011598        0.663535       0.663501   \n",
       "0        0.9         1.000000         0.000000        1.000000       1.000000   \n",
       "\n",
       "   err_rate0_val  err_rate_val  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       0.943152      0.951294  \n",
       "0       0.669251      0.734380  \n",
       "0       0.444444      0.595055  \n",
       "0       0.064599      0.540855  \n",
       "0       0.015504      0.679005  \n",
       "0       0.000000      1.000000  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_rate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a50af8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.789218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.815701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.792594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.826026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.816466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7982</th>\n",
       "      <td>0.619746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7990</th>\n",
       "      <td>0.616601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7993</th>\n",
       "      <td>0.619746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>0.619746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>0.619746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2380 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred\n",
       "unique_id          \n",
       "9          0.789218\n",
       "18         0.815701\n",
       "21         0.792594\n",
       "25         0.826026\n",
       "31         0.816466\n",
       "...             ...\n",
       "7982       0.619746\n",
       "7990       0.616601\n",
       "7993       0.619746\n",
       "7994       0.619746\n",
       "7998       0.619746\n",
       "\n",
       "[2380 rows x 1 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a6d5da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1ba35015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>108</td>\n",
       "      <td>0.715972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unique_id      pred\n",
       "28        108  0.715972"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test[pred_test['unique_id']==108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "184a41b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.789218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.815701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0.792594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.826026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>0.816466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>7982</td>\n",
       "      <td>2375</td>\n",
       "      <td>0.619746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>7990</td>\n",
       "      <td>2376</td>\n",
       "      <td>0.616601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>7993</td>\n",
       "      <td>2377</td>\n",
       "      <td>0.619746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>7994</td>\n",
       "      <td>2378</td>\n",
       "      <td>0.619746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>7998</td>\n",
       "      <td>2379</td>\n",
       "      <td>0.619746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2380 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id  index      pred\n",
       "0             9      0  0.789218\n",
       "1            18      1  0.815701\n",
       "2            21      2  0.792594\n",
       "3            25      3  0.826026\n",
       "4            31      4  0.816466\n",
       "...         ...    ...       ...\n",
       "2375       7982   2375  0.619746\n",
       "2376       7990   2376  0.616601\n",
       "2377       7993   2377  0.619746\n",
       "2378       7994   2378  0.619746\n",
       "2379       7998   2379  0.619746\n",
       "\n",
       "[2380 rows x 3 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub9 = pd.merge(id_test_df,pred_test.reset_index(),how='left',on='unique_id')\n",
    "sub9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "af9ffaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub9['pred'] = sub9['pred'].apply(lambda x: round(x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "201ebc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.789,0.816,0.793,0.826,0.816,0.842,0.731,0.41,0.558,0.745,0.673,0.463,0.791,0.842,0.721,0.839,0.43,0.402,0.7,0.809,0.842,0.62,0.781,0.808,0.839,0.842,0.821,0.837,0.716,0.546,0.838,0.837,0.786,0.82,0.842,0.818,0.62,0.54,0.809,0.77,0.801,0.841,0.803,0.693,0.84,0.778,0.842,0.543,0.609,0.837,0.449,0.842,0.842,0.399,0.493,0.473,0.842,0.842,0.842,0.725,0.842,0.519,0.402,0.789,0.842,0.838,0.842,0.761,0.84,0.842,0.842,0.799,0.775,0.775,0.73,0.722,0.772,0.842,0.818,0.763,0.543,0.818,0.842,0.497,0.816,0.838,0.806,0.839,0.804,0.737,0.842,0.81,0.668,0.839,0.458,0.805,0.789,0.751,0.598,0.826,0.842,0.842,0.799,0.841,0.735,0.58,0.62,0.582,0.745,0.603,0.818,0.842,0.788,0.823,0.531,0.841,0.702,0.836,0.814,0.691,0.825,0.842,0.543,0.616,0.842,0.742,0.842,0.752,0.402,0.402,0.839,0.498,0.402,0.815,0.74,0.814,0.592,0.808,0.62,0.762,0.464,0.822,0.822,0.817,0.673,0.842,0.69,0.811,0.402,0.842,0.841,0.832,0.841,0.839,0.504,0.766,0.842,0.818,0.819,0.69,0.838,0.825,0.84,0.732,0.781,0.839,0.78,0.73,0.773,0.547,0.77,0.659,0.774,0.842,0.842,0.798,0.801,0.765,0.583,0.796,0.494,0.402,0.786,0.62,0.495,0.839,0.828,0.842,0.842,0.753,0.839,0.528,0.677,0.779,0.842,0.484,0.838,0.543,0.826,0.75,0.613,0.823,0.842,0.81,0.631,0.794,0.599,0.521,0.655,0.455,0.824,0.633,0.47,0.842,0.827,0.812,0.842,0.838,0.604,0.839,0.841,0.576,0.62,0.793,0.839,0.555,0.442,0.832,0.629,0.408,0.408,0.804,0.682,0.842,0.558,0.842,0.842,0.504,0.842,0.842,0.445,0.832,0.791,0.838,0.839,0.605,0.832,0.399,0.768,0.717,0.528,0.402,0.834,0.823,0.399,0.62,0.842,0.842,0.644,0.399,0.839,0.706,0.457,0.842,0.82,0.84,0.776,0.842,0.538,0.449,0.734,0.835,0.837,0.557,0.805,0.549,0.778,0.79,0.75,0.785,0.841,0.842,0.399,0.785,0.704,0.464,0.838,0.791,0.62,0.804,0.457,0.408,0.47,0.664,0.504,0.46,0.719,0.411,0.762,0.818,0.84,0.758,0.78,0.767,0.842,0.732,0.822,0.78,0.842,0.76,0.842,0.834,0.399,0.781,0.822,0.473,0.842,0.62,0.723,0.569,0.701,0.71,0.559,0.399,0.808,0.837,0.62,0.801,0.793,0.62,0.399,0.838,0.402,0.817,0.739,0.62,0.739,0.816,0.402,0.588,0.803,0.788,0.731,0.764,0.825,0.839,0.78,0.433,0.629,0.823,0.411,0.54,0.806,0.725,0.607,0.826,0.751,0.836,0.842,0.842,0.842,0.739,0.494,0.781,0.794,0.842,0.481,0.769,0.782,0.423,0.816,0.842,0.838,0.842,0.772,0.633,0.789,0.821,0.642,0.49,0.784,0.838,0.399,0.62,0.825,0.819,0.458,0.842,0.84,0.826,0.399,0.842,0.727,0.84,0.814,0.842,0.81,0.842,0.842,0.797,0.62,0.84,0.79,0.592,0.839,0.651,0.481,0.439,0.803,0.541,0.563,0.542,0.825,0.631,0.62,0.399,0.82,0.402,0.408,0.617,0.826,0.82,0.773,0.84,0.579,0.494,0.62,0.458,0.815,0.781,0.759,0.399,0.399,0.842,0.421,0.773,0.785,0.593,0.433,0.825,0.521,0.74,0.723,0.675,0.823,0.605,0.568,0.842,0.399,0.62,0.804,0.828,0.493,0.798,0.668,0.7,0.842,0.786,0.784,0.839,0.842,0.494,0.839,0.639,0.708,0.84,0.447,0.713,0.59,0.773,0.607,0.69,0.399,0.842,0.622,0.694,0.79,0.748,0.62,0.717,0.402,0.749,0.842,0.409,0.402,0.613,0.842,0.754,0.766,0.484,0.399,0.785,0.62,0.738,0.602,0.842,0.842,0.542,0.684,0.399,0.822,0.839,0.842,0.62,0.399,0.842,0.604,0.842,0.681,0.62,0.666,0.826,0.825,0.611,0.413,0.444,0.399,0.62,0.62,0.402,0.561,0.442,0.399,0.474,0.809,0.822,0.68,0.842,0.842,0.781,0.399,0.842,0.576,0.445,0.842,0.734,0.797,0.442,0.592,0.474,0.408,0.769,0.62,0.402,0.811,0.62,0.411,0.768,0.589,0.62,0.842,0.825,0.805,0.842,0.804,0.78,0.399,0.824,0.617,0.62,0.842,0.399,0.682,0.814,0.494,0.842,0.799,0.484,0.556,0.657,0.84,0.408,0.399,0.399,0.842,0.654,0.691,0.814,0.824,0.818,0.842,0.489,0.825,0.842,0.687,0.838,0.842,0.58,0.809,0.83,0.723,0.84,0.704,0.455,0.741,0.758,0.842,0.46,0.613,0.69,0.797,0.836,0.795,0.767,0.457,0.754,0.62,0.832,0.826,0.8,0.799,0.769,0.402,0.649,0.456,0.84,0.494,0.402,0.488,0.466,0.835,0.842,0.84,0.838,0.706,0.501,0.402,0.841,0.785,0.842,0.805,0.789,0.62,0.408,0.809,0.62,0.592,0.399,0.732,0.824,0.842,0.842,0.807,0.62,0.827,0.451,0.62,0.795,0.84,0.671,0.836,0.62,0.399,0.707,0.72,0.842,0.622,0.399,0.814,0.826,0.62,0.762,0.46,0.62,0.457,0.463,0.842,0.842,0.842,0.775,0.411,0.841,0.81,0.62,0.712,0.503,0.842,0.842,0.451,0.46,0.604,0.402,0.667,0.824,0.762,0.801,0.471,0.607,0.642,0.543,0.412,0.712,0.62,0.797,0.67,0.63,0.836,0.842,0.447,0.821,0.751,0.825,0.454,0.842,0.62,0.835,0.805,0.527,0.84,0.454,0.842,0.617,0.784,0.421,0.786,0.689,0.84,0.753,0.842,0.445,0.799,0.62,0.839,0.402,0.842,0.645,0.54,0.842,0.605,0.445,0.835,0.573,0.777,0.815,0.719,0.743,0.842,0.842,0.842,0.842,0.62,0.814,0.795,0.84,0.838,0.62,0.686,0.83,0.474,0.809,0.803,0.449,0.791,0.828,0.62,0.543,0.841,0.402,0.62,0.841,0.842,0.83,0.399,0.535,0.842,0.723,0.753,0.511,0.841,0.77,0.567,0.742,0.842,0.47,0.583,0.547,0.543,0.606,0.797,0.804,0.84,0.62,0.839,0.795,0.842,0.716,0.745,0.839,0.842,0.406,0.454,0.808,0.617,0.681,0.748,0.473,0.784,0.421,0.806,0.673,0.553,0.411,0.78,0.399,0.643,0.842,0.832,0.741,0.839,0.842,0.842,0.62,0.753,0.616,0.46,0.782,0.842,0.765,0.814,0.789,0.842,0.84,0.54,0.838,0.729,0.576,0.774,0.81,0.62,0.826,0.773,0.839,0.72,0.553,0.592,0.62,0.576,0.399,0.798,0.62,0.842,0.729,0.842,0.832,0.837,0.838,0.838,0.648,0.576,0.556,0.62,0.833,0.62,0.578,0.62,0.842,0.742,0.488,0.814,0.753,0.84,0.842,0.62,0.842,0.613,0.563,0.525,0.824,0.759,0.409,0.842,0.771,0.801,0.617,0.779,0.839,0.615,0.808,0.399,0.592,0.741,0.549,0.824,0.695,0.585,0.444,0.842,0.62,0.62,0.556,0.815,0.399,0.543,0.589,0.84,0.841,0.794,0.677,0.416,0.712,0.449,0.765,0.592,0.543,0.576,0.806,0.466,0.521,0.702,0.531,0.411,0.627,0.842,0.842,0.62,0.774,0.842,0.654,0.617,0.79,0.589,0.432,0.804,0.461,0.66,0.484,0.826,0.62,0.809,0.451,0.737,0.842,0.84,0.822,0.473,0.839,0.836,0.399,0.838,0.611,0.838,0.526,0.713,0.842,0.842,0.801,0.837,0.815,0.839,0.402,0.842,0.749,0.402,0.842,0.65,0.802,0.842,0.842,0.805,0.524,0.842,0.62,0.617,0.62,0.736,0.828,0.764,0.425,0.842,0.576,0.722,0.589,0.402,0.842,0.839,0.671,0.841,0.839,0.732,0.532,0.84,0.58,0.799,0.543,0.75,0.559,0.808,0.62,0.62,0.807,0.827,0.842,0.806,0.812,0.494,0.823,0.776,0.813,0.8,0.62,0.744,0.62,0.62,0.82,0.827,0.818,0.643,0.492,0.719,0.711,0.509,0.814,0.657,0.842,0.796,0.409,0.402,0.841,0.616,0.842,0.598,0.804,0.62,0.838,0.399,0.62,0.62,0.543,0.62,0.842,0.84,0.822,0.804,0.62,0.842,0.62,0.494,0.402,0.644,0.804,0.406,0.572,0.526,0.58,0.5,0.519,0.842,0.839,0.62,0.795,0.839,0.506,0.671,0.815,0.842,0.842,0.812,0.518,0.619,0.587,0.512,0.62,0.842,0.814,0.82,0.842,0.837,0.81,0.842,0.605,0.819,0.445,0.714,0.842,0.604,0.793,0.527,0.832,0.702,0.839,0.543,0.62,0.62,0.589,0.62,0.483,0.62,0.837,0.499,0.664,0.617,0.543,0.704,0.399,0.62,0.702,0.768,0.842,0.702,0.842,0.826,0.467,0.559,0.62,0.721,0.408,0.576,0.617,0.563,0.484,0.617,0.838,0.842,0.62,0.557,0.62,0.399,0.714,0.543,0.665,0.448,0.84,0.589,0.572,0.62,0.783,0.543,0.628,0.841,0.544,0.402,0.789,0.402,0.84,0.62,0.62,0.816,0.62,0.842,0.402,0.62,0.779,0.62,0.62,0.84,0.563,0.62,0.408,0.73,0.784,0.62,0.399,0.648,0.791,0.831,0.714,0.839,0.842,0.534,0.484,0.501,0.62,0.842,0.838,0.622,0.772,0.62,0.827,0.648,0.591,0.62,0.839,0.411,0.825,0.589,0.842,0.62,0.62,0.399,0.836,0.62,0.592,0.665,0.526,0.671,0.557,0.774,0.411,0.806,0.413,0.399,0.75,0.454,0.449,0.524,0.484,0.62,0.609,0.719,0.62,0.62,0.592,0.722,0.46,0.655,0.494,0.62,0.818,0.62,0.842,0.777,0.62,0.751,0.796,0.84,0.62,0.838,0.768,0.789,0.62,0.749,0.815,0.77,0.421,0.484,0.489,0.545,0.55,0.748,0.62,0.473,0.49,0.802,0.621,0.839,0.772,0.62,0.839,0.62,0.62,0.399,0.58,0.839,0.799,0.402,0.739,0.792,0.837,0.839,0.675,0.62,0.795,0.71,0.55,0.824,0.61,0.832,0.62,0.62,0.62,0.841,0.494,0.836,0.667,0.6,0.514,0.616,0.842,0.842,0.556,0.801,0.454,0.543,0.826,0.823,0.434,0.53,0.765,0.62,0.842,0.84,0.535,0.831,0.723,0.411,0.642,0.705,0.543,0.806,0.62,0.62,0.62,0.616,0.46,0.406,0.62,0.402,0.672,0.815,0.804,0.842,0.556,0.402,0.63,0.572,0.84,0.583,0.841,0.421,0.606,0.616,0.827,0.576,0.436,0.806,0.62,0.642,0.842,0.598,0.409,0.645,0.815,0.842,0.576,0.825,0.613,0.543,0.62,0.62,0.839,0.493,0.813,0.643,0.62,0.616,0.797,0.58,0.535,0.62,0.494,0.399,0.842,0.473,0.62,0.54,0.62,0.717,0.842,0.841,0.457,0.722,0.62,0.566,0.631,0.592,0.507,0.592,0.677,0.597,0.75,0.842,0.62,0.51,0.62,0.803,0.484,0.399,0.838,0.399,0.576,0.697,0.842,0.62,0.62,0.77,0.62,0.62,0.565,0.62,0.62,0.463,0.617,0.583,0.654,0.62,0.831,0.616,0.62,0.408,0.62,0.54,0.825,0.541,0.62,0.62,0.424,0.62,0.592,0.62,0.504,0.62,0.62,0.535,0.842,0.595,0.547,0.543,0.62,0.62,0.822,0.467,0.62,0.613,0.62,0.62,0.412,0.682,0.505,0.62,0.695,0.399,0.62,0.617,0.645,0.772,0.62,0.797,0.671,0.62,0.457,0.411,0.62,0.504,0.592,0.84,0.62,0.62,0.725,0.542,0.476,0.799,0.62,0.617,0.543,0.62,0.796,0.501,0.402,0.402,0.62,0.72,0.553,0.617,0.62,0.415,0.415,0.576,0.749,0.46,0.842,0.589,0.62,0.62,0.841,0.522,0.74,0.452,0.842,0.702,0.608,0.62,0.752,0.631,0.738,0.763,0.549,0.436,0.84,0.444,0.594,0.671,0.825,0.837,0.75,0.596,0.781,0.84,0.554,0.772,0.569,0.62,0.399,0.801,0.804,0.482,0.609,0.748,0.842,0.682,0.674,0.666,0.64,0.842,0.842,0.62,0.842,0.556,0.786,0.62,0.62,0.617,0.672,0.399,0.806,0.411,0.62,0.399,0.777,0.617,0.62,0.667,0.62,0.84,0.8,0.62,0.842,0.842,0.738,0.543,0.783,0.442,0.77,0.804,0.399,0.842,0.402,0.399,0.634,0.399,0.759,0.825,0.62,0.612,0.84,0.402,0.399,0.399,0.713,0.402,0.439,0.399,0.82,0.399,0.429,0.815,0.408,0.809,0.723,0.801,0.726,0.543,0.448,0.8,0.399,0.541,0.62,0.808,0.837,0.424,0.471,0.826,0.839,0.797,0.512,0.842,0.402,0.806,0.399,0.532,0.839,0.657,0.806,0.402,0.411,0.804,0.464,0.838,0.447,0.678,0.75,0.842,0.766,0.46,0.84,0.399,0.841,0.454,0.643,0.841,0.838,0.84,0.729,0.631,0.696,0.411,0.399,0.424,0.402,0.63,0.543,0.411,0.806,0.765,0.457,0.829,0.816,0.559,0.487,0.718,0.408,0.806,0.614,0.668,0.544,0.824,0.451,0.617,0.49,0.616,0.669,0.466,0.442,0.48,0.447,0.762,0.839,0.712,0.657,0.842,0.559,0.633,0.841,0.519,0.402,0.457,0.841,0.778,0.757,0.749,0.825,0.772,0.755,0.815,0.839,0.408,0.766,0.748,0.62,0.806,0.399,0.402,0.842,0.74,0.543,0.842,0.549,0.806,0.811,0.842,0.754,0.77,0.8,0.808,0.842,0.62,0.738,0.589,0.58,0.719,0.543,0.603,0.402,0.827,0.806,0.402,0.489,0.806,0.543,0.842,0.738,0.766,0.617,0.6,0.576,0.399,0.804,0.842,0.46,0.841,0.402,0.429,0.807,0.553,0.622,0.778,0.806,0.48,0.682,0.806,0.791,0.62,0.839,0.438,0.62,0.804,0.732,0.842,0.62,0.62,0.528,0.804,0.741,0.62,0.541,0.585,0.504,0.51,0.399,0.411,0.553,0.842,0.738,0.474,0.819,0.671,0.436,0.795,0.675,0.642,0.543,0.402,0.479,0.665,0.826,0.82,0.446,0.82,0.559,0.547,0.451,0.634,0.399,0.46,0.777,0.682,0.46,0.732,0.806,0.399,0.544,0.556,0.671,0.563,0.494,0.649,0.764,0.54,0.46,0.553,0.46,0.476,0.801,0.746,0.454,0.553,0.789,0.825,0.842,0.525,0.604,0.616,0.764,0.675,0.747,0.74,0.622,0.62,0.631,0.775,0.738,0.62,0.741,0.721,0.631,0.826,0.526,0.405,0.455,0.464,0.675,0.535,0.407,0.592,0.62,0.784,0.509,0.553,0.668,0.412,0.451,0.592,0.526,0.745,0.526,0.547,0.62,0.473,0.616,0.62,0.62,0.62,0.572,0.631,0.62,0.618,0.569,0.62,0.62,0.62,0.477,0.609,0.62,0.55,0.467,0.62,0.596,0.716,0.62,0.62,0.501,0.62,0.62,0.72,0.62,0.62,0.62,0.62,0.62,0.444,0.62,0.62,0.62,0.494,0.62,0.543,0.544,0.62,0.62,0.62,0.62,0.639,0.617,0.494,0.535,0.529,0.777,0.62,0.62,0.62,0.62,0.62,0.62,0.494,0.617,0.543,0.62,0.616,0.466,0.62,0.62,0.62,0.781,0.532,0.62,0.62,0.616,0.62,0.62,0.62,0.708,0.648,0.62,0.62,0.62,0.62,0.738,0.576,0.62,0.631,0.563,0.553,0.535,0.62,0.62,0.62,0.62,0.62,0.716,0.543,0.675,0.62,0.658,0.62,0.62,0.62,0.62,0.616,0.62,0.616,0.617,0.668,0.62,0.617,0.62,0.62,0.62,0.467,0.62,0.543,0.62,0.62,0.62,0.543,0.572,0.549,0.62,0.556,0.62,0.62,0.572,0.556,0.573,0.62,0.532,0.62,0.556,0.549,0.62,0.47,0.62,0.576,0.543,0.62,0.592,0.488,0.609,0.62,0.617,0.62,0.672,0.62,0.806,0.835,0.808,0.806,0.62,0.5,0.62,0.62,0.62,0.54,0.543,0.506,0.556,0.62,0.406,0.617,0.605,0.543,0.62,0.62,0.556,0.592,0.47,0.593,0.62,0.542,0.613,0.62,0.62,0.607,0.62,0.75,0.62,0.616,0.62,0.62,0.62,0.62,0.62,0.62,0.592,0.62,0.631,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.539,0.62,0.62,0.62,0.62,0.62,0.704,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.556,0.589,0.62,0.62,0.62,0.62,0.526,0.62,0.62,0.791,0.592,0.62,0.62,0.616,0.609,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.641,0.457,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.569,0.517,0.62,0.62,0.62,0.62,0.62,0.544,0.718,0.62,0.622,0.62,0.541,0.62,0.62,0.62,0.62,0.556,0.62,0.62,0.524,0.62,0.62,0.62,0.547,0.62,0.607,0.62,0.773,0.62,0.62,0.761,0.62,0.62,0.717,0.62,0.729,0.616,0.47,0.622,0.607,0.738,0.62,0.544,0.572,0.623,0.62,0.62,0.62,0.62,0.616,0.592,0.62,0.62,0.576,0.62,0.535,0.62,0.451,0.406,0.483,0.616,0.62,0.74,0.544,0.668,0.604,0.748,0.62,0.777,0.62,0.526,0.631,0.493,0.547,0.617,0.62,0.62,0.607,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.553,0.51,0.62,0.592,0.617,0.727,0.535,0.62,0.631,0.62,0.62,0.741,0.592,0.617,0.46,0.616,0.806,0.62,0.609,0.62,0.613,0.792,0.62,0.62,0.62,0.617,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.617,0.62,0.62,0.62,0.62,0.623,0.617,0.62,0.62,0.62,0.62,0.617,0.764,0.62,0.62,0.623,0.62,0.62,0.62,0.62,0.553,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.592,0.471,0.576,0.62,0.62,0.62,0.62,0.62,0.732,0.523,0.62,0.604,0.729,0.5,0.62,0.62,0.62,0.73,0.721,0.62,0.72,0.526,0.526,0.526,0.62,0.62,0.62,0.62,0.62,0.62,0.536,0.544,0.592,0.62,0.62,0.617,0.617,0.62,0.62,0.617,0.62,0.609,0.62,0.62,0.631,0.631,0.62,0.47,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.617,0.62,0.62,0.62,0.62,0.535,0.62,0.62,0.631,0.62,0.62,0.62,0.616,0.592,0.62,0.62,0.62,0.62,0.62,0.741,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.47,0.483,0.729,0.533,0.588,0.583,0.62,0.62,0.62,0.62,0.589,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.675,0.535,0.607,0.738,0.62,0.62,0.62,0.617,0.62,0.62,0.62,0.62,0.622,0.62,0.62,0.62,0.62,0.62,0.616,0.617,0.617,0.617,0.62,0.592,0.592,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.617,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.72,0.62,0.62,0.62,0.62,0.62,0.616,0.62,0.62,0.535,0.62,0.617,0.62,0.62,0.62'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub9_txt = ''\n",
    "for prob in list(sub9['pred'].values):\n",
    "    sub9_txt = sub9_txt+','+str(prob)\n",
    "sub9_txt = sub9_txt[1:]\n",
    "\n",
    "sub9_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc56150",
   "metadata": {},
   "source": [
    "### Random Tree - 20-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8ce4357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bag_df_20_10 = pd.read_csv('train_bag_df_20_10.csv')\n",
    "val_bag_df_20_10 = pd.read_csv('val_bag_df_20_10.csv')\n",
    "test_bag_df_20_10 = pd.read_csv('test_bag_df_20_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "be21e743",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv('y_train_50.csv')\n",
    "y_val = pd.read_csv('y_val_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cad9eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bag_df_20_10.set_index('unique_id',inplace=True)\n",
    "val_bag_df_20_10.set_index('unique_id',inplace=True)\n",
    "test_bag_df_20_10.set_index('unique_id',inplace=True)\n",
    "y_train.set_index('unique_id',inplace=True)\n",
    "y_val.set_index('unique_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9351d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bag_df_20_10.sort_index(inplace=True)\n",
    "val_bag_df_20_10.sort_index(inplace=True)\n",
    "test_bag_df_20_10.sort_index(inplace=True)\n",
    "y_train.sort_index(inplace=True)\n",
    "y_val.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "deabad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bag_df_20_10.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "val_bag_df_20_10.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "test_bag_df_20_10.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "721ea01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cidem\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(max_depth=2,learning_rate=0.01,n_estimators=100,min_child_samples=100,colsample_bytree=0.5)\n",
    "lgbm.fit(train_bag_df_20_10,y_train)\n",
    "\n",
    "pred_train = pd.DataFrame(lgbm.predict_proba(train_bag_df_20_10)[:,1],columns=['pred'],index=train_bag_df_20_10.index)\n",
    "pred_val = pd.DataFrame(lgbm.predict_proba(val_bag_df_20_10)[:,1],columns=['pred'],index=val_bag_df_20_10.index)\n",
    "pred_test = pd.DataFrame(lgbm.predict_proba(test_bag_df_20_10)[:,1],columns=['pred'],index=test_bag_df_20_10.index)\n",
    "\n",
    "pred_train = pd.merge(pred_train,y_train,how='left',left_index=True, right_index=True)\n",
    "pred_val = pd.merge(pred_val,y_val,how='left',left_index=True, right_index=True)\n",
    "\n",
    "roc_train = roc_auc_score(pred_train['female_label'],pred_train['pred'])\n",
    "roc_val = roc_auc_score(pred_val['female_label'],pred_val['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8adb90ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC:  0.8326132986887383\n",
      "Val ROC:  0.8171825860128532\n"
     ]
    }
   ],
   "source": [
    "print('Train ROC: ',roc_train)\n",
    "print('Val ROC: ',roc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cf917efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_rate_df = pd.DataFrame()\n",
    "\n",
    "for th in np.arange(0,1,0.1):\n",
    "\n",
    "    pred_train['pred_binary'] = np.where(pred_train['pred']>=th,1,0)\n",
    "    pred_val['pred_binary'] = np.where(pred_val['pred']>=th,1,0)\n",
    "\n",
    "    err_rate1_train = 1-(pred_train[pred_train['female_label']==1]['pred_binary'].sum()/pred_train[pred_train['female_label']==1]['pred_binary'].count())\n",
    "    err_rate0_train = pred_train[pred_train['female_label']==0]['pred_binary'].sum()/pred_train[pred_train['female_label']==0]['pred_binary'].count()\n",
    "    err_rate_train = err_rate1_train+err_rate0_train\n",
    "\n",
    "    err_rate1_val = 1-(pred_val[pred_val['female_label']==1]['pred_binary'].sum()/pred_val[pred_val['female_label']==1]['pred_binary'].count())\n",
    "    err_rate0_val = pred_val[pred_val['female_label']==0]['pred_binary'].sum()/pred_val[pred_val['female_label']==0]['pred_binary'].count()\n",
    "    err_rate_val = err_rate1_val+err_rate0_val\n",
    "\n",
    "    err_rate_df_tmp = pd.DataFrame({'threshold':[th],\n",
    "                                    'err_rate1_train':[err_rate1_train],\n",
    "                                    'err_rate0_train':[err_rate0_train],\n",
    "                                    'err_rate_train':[err_rate_train],\n",
    "                                    'err_rate1_val':[err_rate1_val],\n",
    "                                    'err_rate0_val':[err_rate0_val],\n",
    "                                    'err_rate_val':[err_rate_val]\n",
    "                                   })\n",
    "    err_rate_df = pd.concat([err_rate_df,err_rate_df_tmp])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "646b62e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>err_rate1_train</th>\n",
       "      <th>err_rate0_train</th>\n",
       "      <th>err_rate_train</th>\n",
       "      <th>err_rate1_val</th>\n",
       "      <th>err_rate0_val</th>\n",
       "      <th>err_rate_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.029232</td>\n",
       "      <td>0.769330</td>\n",
       "      <td>0.798562</td>\n",
       "      <td>0.037992</td>\n",
       "      <td>0.801034</td>\n",
       "      <td>0.839025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.148199</td>\n",
       "      <td>0.411727</td>\n",
       "      <td>0.559925</td>\n",
       "      <td>0.168250</td>\n",
       "      <td>0.431525</td>\n",
       "      <td>0.599774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.485384</td>\n",
       "      <td>0.064433</td>\n",
       "      <td>0.549817</td>\n",
       "      <td>0.508820</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.555331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.745071</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.752159</td>\n",
       "      <td>0.758480</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>0.763648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  err_rate1_train  err_rate0_train  err_rate_train  err_rate1_val  \\\n",
       "0        0.0         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.1         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.2         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.3         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.4         0.000000         1.000000        1.000000       0.000000   \n",
       "0        0.5         0.029232         0.769330        0.798562       0.037992   \n",
       "0        0.6         0.148199         0.411727        0.559925       0.168250   \n",
       "0        0.7         0.485384         0.064433        0.549817       0.508820   \n",
       "0        0.8         0.745071         0.007088        0.752159       0.758480   \n",
       "0        0.9         1.000000         0.000000        1.000000       1.000000   \n",
       "\n",
       "   err_rate0_val  err_rate_val  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       1.000000      1.000000  \n",
       "0       0.801034      0.839025  \n",
       "0       0.431525      0.599774  \n",
       "0       0.046512      0.555331  \n",
       "0       0.005168      0.763648  \n",
       "0       0.000000      1.000000  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_rate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "34f71b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.812072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.772804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.806367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.840528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.812865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7982</th>\n",
       "      <td>0.624551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7990</th>\n",
       "      <td>0.603584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7993</th>\n",
       "      <td>0.619567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>0.619567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>0.619567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2380 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred\n",
       "unique_id          \n",
       "9          0.812072\n",
       "18         0.772804\n",
       "21         0.806367\n",
       "25         0.840528\n",
       "31         0.812865\n",
       "...             ...\n",
       "7982       0.624551\n",
       "7990       0.603584\n",
       "7993       0.619567\n",
       "7994       0.619567\n",
       "7998       0.619567\n",
       "\n",
       "[2380 rows x 1 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b3782a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f04b4ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>108</td>\n",
       "      <td>0.772804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unique_id      pred\n",
       "28        108  0.772804"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test[pred_test['unique_id']==108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "af876b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>index</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.772804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0.806367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.840528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>0.812865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>7982</td>\n",
       "      <td>2375</td>\n",
       "      <td>0.624551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>7990</td>\n",
       "      <td>2376</td>\n",
       "      <td>0.603584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>7993</td>\n",
       "      <td>2377</td>\n",
       "      <td>0.619567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>7994</td>\n",
       "      <td>2378</td>\n",
       "      <td>0.619567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>7998</td>\n",
       "      <td>2379</td>\n",
       "      <td>0.619567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2380 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id  index      pred\n",
       "0             9      0  0.812072\n",
       "1            18      1  0.772804\n",
       "2            21      2  0.806367\n",
       "3            25      3  0.840528\n",
       "4            31      4  0.812865\n",
       "...         ...    ...       ...\n",
       "2375       7982   2375  0.624551\n",
       "2376       7990   2376  0.603584\n",
       "2377       7993   2377  0.619567\n",
       "2378       7994   2378  0.619567\n",
       "2379       7998   2379  0.619567\n",
       "\n",
       "[2380 rows x 3 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub10 = pd.merge(id_test_df,pred_test.reset_index(),how='left',on='unique_id')\n",
    "sub10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ca82e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub10['pred'] = sub10['pred'].apply(lambda x: round(x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "450d3b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.812\n",
       "1       0.773\n",
       "2       0.806\n",
       "3       0.841\n",
       "4       0.813\n",
       "        ...  \n",
       "2375    0.625\n",
       "2376    0.604\n",
       "2377    0.620\n",
       "2378    0.620\n",
       "2379    0.620\n",
       "Name: pred, Length: 2380, dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub10['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f5848d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.812,\n",
       " 0.773,\n",
       " 0.806,\n",
       " 0.841,\n",
       " 0.813,\n",
       " 0.844,\n",
       " 0.738,\n",
       " 0.567,\n",
       " 0.759,\n",
       " 0.783,\n",
       " 0.512,\n",
       " 0.536,\n",
       " 0.8,\n",
       " 0.844,\n",
       " 0.773,\n",
       " 0.783,\n",
       " 0.584,\n",
       " 0.557,\n",
       " 0.772,\n",
       " 0.694,\n",
       " 0.822,\n",
       " 0.674,\n",
       " 0.813,\n",
       " 0.799,\n",
       " 0.844,\n",
       " 0.807,\n",
       " 0.81,\n",
       " 0.844,\n",
       " 0.773,\n",
       " 0.716,\n",
       " 0.829,\n",
       " 0.776,\n",
       " 0.772,\n",
       " 0.82,\n",
       " 0.806,\n",
       " 0.841,\n",
       " 0.62,\n",
       " 0.524,\n",
       " 0.669,\n",
       " 0.813,\n",
       " 0.791,\n",
       " 0.821,\n",
       " 0.703,\n",
       " 0.763,\n",
       " 0.823,\n",
       " 0.801,\n",
       " 0.844,\n",
       " 0.499,\n",
       " 0.606,\n",
       " 0.755,\n",
       " 0.542,\n",
       " 0.805,\n",
       " 0.782,\n",
       " 0.423,\n",
       " 0.559,\n",
       " 0.589,\n",
       " 0.841,\n",
       " 0.834,\n",
       " 0.834,\n",
       " 0.808,\n",
       " 0.829,\n",
       " 0.626,\n",
       " 0.468,\n",
       " 0.755,\n",
       " 0.844,\n",
       " 0.662,\n",
       " 0.843,\n",
       " 0.751,\n",
       " 0.826,\n",
       " 0.828,\n",
       " 0.844,\n",
       " 0.8,\n",
       " 0.773,\n",
       " 0.772,\n",
       " 0.791,\n",
       " 0.738,\n",
       " 0.773,\n",
       " 0.811,\n",
       " 0.806,\n",
       " 0.793,\n",
       " 0.537,\n",
       " 0.788,\n",
       " 0.822,\n",
       " 0.442,\n",
       " 0.841,\n",
       " 0.805,\n",
       " 0.751,\n",
       " 0.844,\n",
       " 0.8,\n",
       " 0.76,\n",
       " 0.818,\n",
       " 0.778,\n",
       " 0.751,\n",
       " 0.817,\n",
       " 0.556,\n",
       " 0.758,\n",
       " 0.667,\n",
       " 0.779,\n",
       " 0.549,\n",
       " 0.808,\n",
       " 0.779,\n",
       " 0.84,\n",
       " 0.841,\n",
       " 0.739,\n",
       " 0.704,\n",
       " 0.739,\n",
       " 0.62,\n",
       " 0.671,\n",
       " 0.805,\n",
       " 0.546,\n",
       " 0.791,\n",
       " 0.844,\n",
       " 0.791,\n",
       " 0.79,\n",
       " 0.537,\n",
       " 0.798,\n",
       " 0.791,\n",
       " 0.802,\n",
       " 0.79,\n",
       " 0.567,\n",
       " 0.813,\n",
       " 0.844,\n",
       " 0.531,\n",
       " 0.663,\n",
       " 0.79,\n",
       " 0.642,\n",
       " 0.844,\n",
       " 0.812,\n",
       " 0.438,\n",
       " 0.47,\n",
       " 0.829,\n",
       " 0.657,\n",
       " 0.502,\n",
       " 0.819,\n",
       " 0.774,\n",
       " 0.777,\n",
       " 0.611,\n",
       " 0.812,\n",
       " 0.615,\n",
       " 0.772,\n",
       " 0.532,\n",
       " 0.795,\n",
       " 0.772,\n",
       " 0.759,\n",
       " 0.671,\n",
       " 0.824,\n",
       " 0.753,\n",
       " 0.764,\n",
       " 0.474,\n",
       " 0.826,\n",
       " 0.835,\n",
       " 0.832,\n",
       " 0.83,\n",
       " 0.812,\n",
       " 0.654,\n",
       " 0.63,\n",
       " 0.775,\n",
       " 0.754,\n",
       " 0.814,\n",
       " 0.733,\n",
       " 0.82,\n",
       " 0.8,\n",
       " 0.841,\n",
       " 0.593,\n",
       " 0.817,\n",
       " 0.834,\n",
       " 0.73,\n",
       " 0.841,\n",
       " 0.773,\n",
       " 0.528,\n",
       " 0.76,\n",
       " 0.576,\n",
       " 0.695,\n",
       " 0.844,\n",
       " 0.828,\n",
       " 0.751,\n",
       " 0.784,\n",
       " 0.761,\n",
       " 0.717,\n",
       " 0.769,\n",
       " 0.506,\n",
       " 0.525,\n",
       " 0.843,\n",
       " 0.615,\n",
       " 0.651,\n",
       " 0.843,\n",
       " 0.817,\n",
       " 0.835,\n",
       " 0.83,\n",
       " 0.744,\n",
       " 0.77,\n",
       " 0.681,\n",
       " 0.564,\n",
       " 0.802,\n",
       " 0.795,\n",
       " 0.492,\n",
       " 0.834,\n",
       " 0.536,\n",
       " 0.775,\n",
       " 0.731,\n",
       " 0.806,\n",
       " 0.841,\n",
       " 0.822,\n",
       " 0.84,\n",
       " 0.735,\n",
       " 0.772,\n",
       " 0.533,\n",
       " 0.563,\n",
       " 0.631,\n",
       " 0.62,\n",
       " 0.83,\n",
       " 0.844,\n",
       " 0.434,\n",
       " 0.844,\n",
       " 0.811,\n",
       " 0.663,\n",
       " 0.844,\n",
       " 0.841,\n",
       " 0.619,\n",
       " 0.79,\n",
       " 0.731,\n",
       " 0.623,\n",
       " 0.615,\n",
       " 0.78,\n",
       " 0.825,\n",
       " 0.612,\n",
       " 0.641,\n",
       " 0.795,\n",
       " 0.552,\n",
       " 0.518,\n",
       " 0.446,\n",
       " 0.769,\n",
       " 0.767,\n",
       " 0.844,\n",
       " 0.494,\n",
       " 0.822,\n",
       " 0.844,\n",
       " 0.615,\n",
       " 0.844,\n",
       " 0.842,\n",
       " 0.474,\n",
       " 0.802,\n",
       " 0.842,\n",
       " 0.827,\n",
       " 0.8,\n",
       " 0.559,\n",
       " 0.785,\n",
       " 0.47,\n",
       " 0.812,\n",
       " 0.753,\n",
       " 0.592,\n",
       " 0.432,\n",
       " 0.803,\n",
       " 0.833,\n",
       " 0.429,\n",
       " 0.682,\n",
       " 0.844,\n",
       " 0.826,\n",
       " 0.652,\n",
       " 0.454,\n",
       " 0.843,\n",
       " 0.72,\n",
       " 0.524,\n",
       " 0.78,\n",
       " 0.805,\n",
       " 0.821,\n",
       " 0.558,\n",
       " 0.842,\n",
       " 0.794,\n",
       " 0.494,\n",
       " 0.681,\n",
       " 0.787,\n",
       " 0.812,\n",
       " 0.644,\n",
       " 0.782,\n",
       " 0.614,\n",
       " 0.832,\n",
       " 0.806,\n",
       " 0.752,\n",
       " 0.764,\n",
       " 0.821,\n",
       " 0.828,\n",
       " 0.489,\n",
       " 0.79,\n",
       " 0.707,\n",
       " 0.431,\n",
       " 0.818,\n",
       " 0.797,\n",
       " 0.62,\n",
       " 0.826,\n",
       " 0.561,\n",
       " 0.527,\n",
       " 0.616,\n",
       " 0.737,\n",
       " 0.503,\n",
       " 0.547,\n",
       " 0.792,\n",
       " 0.478,\n",
       " 0.645,\n",
       " 0.765,\n",
       " 0.811,\n",
       " 0.738,\n",
       " 0.807,\n",
       " 0.841,\n",
       " 0.844,\n",
       " 0.801,\n",
       " 0.807,\n",
       " 0.829,\n",
       " 0.815,\n",
       " 0.802,\n",
       " 0.84,\n",
       " 0.752,\n",
       " 0.467,\n",
       " 0.796,\n",
       " 0.809,\n",
       " 0.475,\n",
       " 0.844,\n",
       " 0.615,\n",
       " 0.763,\n",
       " 0.588,\n",
       " 0.686,\n",
       " 0.656,\n",
       " 0.546,\n",
       " 0.528,\n",
       " 0.777,\n",
       " 0.795,\n",
       " 0.615,\n",
       " 0.706,\n",
       " 0.716,\n",
       " 0.62,\n",
       " 0.498,\n",
       " 0.813,\n",
       " 0.536,\n",
       " 0.844,\n",
       " 0.711,\n",
       " 0.62,\n",
       " 0.689,\n",
       " 0.818,\n",
       " 0.428,\n",
       " 0.717,\n",
       " 0.77,\n",
       " 0.804,\n",
       " 0.782,\n",
       " 0.822,\n",
       " 0.704,\n",
       " 0.818,\n",
       " 0.773,\n",
       " 0.492,\n",
       " 0.642,\n",
       " 0.838,\n",
       " 0.498,\n",
       " 0.434,\n",
       " 0.763,\n",
       " 0.811,\n",
       " 0.564,\n",
       " 0.844,\n",
       " 0.768,\n",
       " 0.721,\n",
       " 0.831,\n",
       " 0.843,\n",
       " 0.844,\n",
       " 0.761,\n",
       " 0.512,\n",
       " 0.79,\n",
       " 0.773,\n",
       " 0.789,\n",
       " 0.539,\n",
       " 0.802,\n",
       " 0.815,\n",
       " 0.599,\n",
       " 0.806,\n",
       " 0.812,\n",
       " 0.826,\n",
       " 0.842,\n",
       " 0.772,\n",
       " 0.815,\n",
       " 0.772,\n",
       " 0.811,\n",
       " 0.826,\n",
       " 0.649,\n",
       " 0.704,\n",
       " 0.812,\n",
       " 0.428,\n",
       " 0.625,\n",
       " 0.827,\n",
       " 0.765,\n",
       " 0.447,\n",
       " 0.839,\n",
       " 0.839,\n",
       " 0.779,\n",
       " 0.476,\n",
       " 0.812,\n",
       " 0.595,\n",
       " 0.816,\n",
       " 0.768,\n",
       " 0.826,\n",
       " 0.803,\n",
       " 0.844,\n",
       " 0.844,\n",
       " 0.789,\n",
       " 0.666,\n",
       " 0.801,\n",
       " 0.814,\n",
       " 0.65,\n",
       " 0.795,\n",
       " 0.663,\n",
       " 0.546,\n",
       " 0.588,\n",
       " 0.769,\n",
       " 0.67,\n",
       " 0.517,\n",
       " 0.597,\n",
       " 0.779,\n",
       " 0.711,\n",
       " 0.625,\n",
       " 0.47,\n",
       " 0.81,\n",
       " 0.592,\n",
       " 0.524,\n",
       " 0.572,\n",
       " 0.83,\n",
       " 0.736,\n",
       " 0.736,\n",
       " 0.774,\n",
       " 0.701,\n",
       " 0.54,\n",
       " 0.613,\n",
       " 0.47,\n",
       " 0.802,\n",
       " 0.727,\n",
       " 0.613,\n",
       " 0.512,\n",
       " 0.436,\n",
       " 0.844,\n",
       " 0.517,\n",
       " 0.783,\n",
       " 0.816,\n",
       " 0.561,\n",
       " 0.69,\n",
       " 0.806,\n",
       " 0.552,\n",
       " 0.749,\n",
       " 0.83,\n",
       " 0.621,\n",
       " 0.783,\n",
       " 0.59,\n",
       " 0.511,\n",
       " 0.844,\n",
       " 0.446,\n",
       " 0.6,\n",
       " 0.815,\n",
       " 0.818,\n",
       " 0.539,\n",
       " 0.83,\n",
       " 0.712,\n",
       " 0.782,\n",
       " 0.794,\n",
       " 0.844,\n",
       " 0.829,\n",
       " 0.844,\n",
       " 0.844,\n",
       " 0.482,\n",
       " 0.775,\n",
       " 0.652,\n",
       " 0.73,\n",
       " 0.836,\n",
       " 0.515,\n",
       " 0.738,\n",
       " 0.433,\n",
       " 0.808,\n",
       " 0.518,\n",
       " 0.6,\n",
       " 0.444,\n",
       " 0.815,\n",
       " 0.59,\n",
       " 0.727,\n",
       " 0.808,\n",
       " 0.775,\n",
       " 0.613,\n",
       " 0.746,\n",
       " 0.512,\n",
       " 0.701,\n",
       " 0.821,\n",
       " 0.465,\n",
       " 0.462,\n",
       " 0.467,\n",
       " 0.838,\n",
       " 0.785,\n",
       " 0.773,\n",
       " 0.518,\n",
       " 0.488,\n",
       " 0.751,\n",
       " 0.615,\n",
       " 0.662,\n",
       " 0.788,\n",
       " 0.842,\n",
       " 0.821,\n",
       " 0.553,\n",
       " 0.553,\n",
       " 0.437,\n",
       " 0.838,\n",
       " 0.759,\n",
       " 0.844,\n",
       " 0.62,\n",
       " 0.458,\n",
       " 0.838,\n",
       " 0.553,\n",
       " 0.844,\n",
       " 0.8,\n",
       " 0.62,\n",
       " 0.784,\n",
       " 0.797,\n",
       " 0.759,\n",
       " 0.524,\n",
       " 0.553,\n",
       " 0.515,\n",
       " 0.429,\n",
       " 0.62,\n",
       " 0.663,\n",
       " 0.458,\n",
       " 0.578,\n",
       " 0.512,\n",
       " 0.475,\n",
       " 0.564,\n",
       " 0.802,\n",
       " 0.834,\n",
       " 0.841,\n",
       " 0.843,\n",
       " 0.833,\n",
       " 0.773,\n",
       " 0.427,\n",
       " 0.843,\n",
       " 0.715,\n",
       " 0.526,\n",
       " 0.844,\n",
       " 0.719,\n",
       " 0.703,\n",
       " 0.53,\n",
       " 0.703,\n",
       " 0.571,\n",
       " 0.498,\n",
       " 0.812,\n",
       " 0.62,\n",
       " 0.444,\n",
       " 0.817,\n",
       " 0.613,\n",
       " 0.501,\n",
       " 0.724,\n",
       " 0.593,\n",
       " 0.62,\n",
       " 0.844,\n",
       " 0.795,\n",
       " 0.791,\n",
       " 0.81,\n",
       " 0.798,\n",
       " 0.774,\n",
       " 0.427,\n",
       " 0.745,\n",
       " 0.581,\n",
       " 0.676,\n",
       " 0.843,\n",
       " 0.438,\n",
       " 0.633,\n",
       " 0.781,\n",
       " 0.474,\n",
       " 0.811,\n",
       " 0.755,\n",
       " 0.495,\n",
       " 0.573,\n",
       " 0.709,\n",
       " 0.84,\n",
       " 0.556,\n",
       " 0.427,\n",
       " 0.43,\n",
       " 0.841,\n",
       " 0.811,\n",
       " 0.736,\n",
       " 0.72,\n",
       " 0.843,\n",
       " 0.809,\n",
       " 0.816,\n",
       " 0.46,\n",
       " 0.748,\n",
       " 0.841,\n",
       " 0.642,\n",
       " 0.844,\n",
       " 0.84,\n",
       " 0.553,\n",
       " 0.837,\n",
       " 0.746,\n",
       " 0.753,\n",
       " 0.84,\n",
       " 0.512,\n",
       " 0.562,\n",
       " 0.694,\n",
       " 0.679,\n",
       " 0.844,\n",
       " 0.513,\n",
       " 0.579,\n",
       " 0.69,\n",
       " 0.827,\n",
       " 0.844,\n",
       " 0.725,\n",
       " 0.741,\n",
       " 0.498,\n",
       " 0.679,\n",
       " 0.62,\n",
       " 0.823,\n",
       " 0.83,\n",
       " 0.704,\n",
       " 0.811,\n",
       " 0.842,\n",
       " 0.436,\n",
       " 0.558,\n",
       " 0.561,\n",
       " 0.807,\n",
       " 0.614,\n",
       " 0.468,\n",
       " 0.498,\n",
       " 0.466,\n",
       " 0.826,\n",
       " 0.788,\n",
       " 0.783,\n",
       " 0.84,\n",
       " 0.778,\n",
       " 0.47,\n",
       " 0.467,\n",
       " 0.806,\n",
       " 0.831,\n",
       " 0.818,\n",
       " 0.692,\n",
       " 0.816,\n",
       " 0.615,\n",
       " 0.458,\n",
       " 0.811,\n",
       " 0.62,\n",
       " 0.557,\n",
       " 0.466,\n",
       " 0.686,\n",
       " 0.794,\n",
       " 0.842,\n",
       " 0.84,\n",
       " 0.769,\n",
       " 0.615,\n",
       " 0.844,\n",
       " 0.513,\n",
       " 0.615,\n",
       " 0.799,\n",
       " 0.838,\n",
       " 0.592,\n",
       " 0.84,\n",
       " 0.62,\n",
       " 0.42,\n",
       " 0.754,\n",
       " 0.799,\n",
       " 0.809,\n",
       " 0.716,\n",
       " 0.64,\n",
       " 0.791,\n",
       " 0.839,\n",
       " 0.626,\n",
       " 0.643,\n",
       " 0.475,\n",
       " 0.62,\n",
       " 0.503,\n",
       " 0.537,\n",
       " 0.83,\n",
       " 0.844,\n",
       " 0.83,\n",
       " 0.687,\n",
       " 0.475,\n",
       " 0.803,\n",
       " 0.767,\n",
       " 0.62,\n",
       " 0.553,\n",
       " 0.671,\n",
       " 0.824,\n",
       " 0.817,\n",
       " 0.511,\n",
       " 0.509,\n",
       " 0.749,\n",
       " 0.51,\n",
       " 0.481,\n",
       " 0.843,\n",
       " 0.791,\n",
       " 0.84,\n",
       " 0.607,\n",
       " 0.629,\n",
       " 0.779,\n",
       " 0.516,\n",
       " 0.452,\n",
       " 0.564,\n",
       " 0.631,\n",
       " 0.71,\n",
       " 0.74,\n",
       " 0.816,\n",
       " 0.844,\n",
       " 0.844,\n",
       " 0.512,\n",
       " 0.753,\n",
       " 0.821,\n",
       " 0.812,\n",
       " 0.443,\n",
       " 0.784,\n",
       " 0.666,\n",
       " 0.749,\n",
       " 0.806,\n",
       " 0.611,\n",
       " 0.8,\n",
       " 0.485,\n",
       " 0.843,\n",
       " 0.586,\n",
       " 0.796,\n",
       " 0.524,\n",
       " 0.743,\n",
       " 0.809,\n",
       " 0.756,\n",
       " 0.597,\n",
       " 0.758,\n",
       " 0.542,\n",
       " 0.766,\n",
       " 0.625,\n",
       " 0.844,\n",
       " 0.49,\n",
       " 0.823,\n",
       " 0.761,\n",
       " 0.528,\n",
       " 0.812,\n",
       " 0.543,\n",
       " 0.518,\n",
       " 0.83,\n",
       " 0.573,\n",
       " 0.74,\n",
       " 0.794,\n",
       " 0.655,\n",
       " 0.617,\n",
       " 0.819,\n",
       " 0.844,\n",
       " 0.822,\n",
       " 0.844,\n",
       " 0.821,\n",
       " 0.728,\n",
       " 0.788,\n",
       " 0.843,\n",
       " 0.825,\n",
       " 0.613,\n",
       " 0.567,\n",
       " 0.815,\n",
       " 0.62,\n",
       " 0.723,\n",
       " 0.801,\n",
       " 0.565,\n",
       " 0.791,\n",
       " 0.82,\n",
       " 0.62,\n",
       " 0.602,\n",
       " 0.822,\n",
       " 0.472,\n",
       " 0.62,\n",
       " 0.787,\n",
       " 0.821,\n",
       " 0.842,\n",
       " 0.491,\n",
       " 0.613,\n",
       " 0.844,\n",
       " 0.789,\n",
       " 0.676,\n",
       " 0.598,\n",
       " 0.841,\n",
       " 0.69,\n",
       " 0.428,\n",
       " 0.644,\n",
       " 0.797,\n",
       " 0.559,\n",
       " 0.522,\n",
       " 0.546,\n",
       " 0.507,\n",
       " 0.573,\n",
       " 0.803,\n",
       " 0.685,\n",
       " 0.803,\n",
       " 0.613,\n",
       " 0.822,\n",
       " 0.703,\n",
       " 0.808,\n",
       " 0.575,\n",
       " 0.706,\n",
       " 0.752,\n",
       " 0.843,\n",
       " 0.487,\n",
       " 0.503,\n",
       " 0.742,\n",
       " 0.614,\n",
       " 0.763,\n",
       " 0.617,\n",
       " 0.581,\n",
       " 0.811,\n",
       " 0.48,\n",
       " 0.692,\n",
       " 0.554,\n",
       " 0.557,\n",
       " 0.488,\n",
       " 0.818,\n",
       " 0.425,\n",
       " 0.62,\n",
       " 0.834,\n",
       " 0.831,\n",
       " 0.719,\n",
       " 0.843,\n",
       " 0.816,\n",
       " 0.843,\n",
       " 0.62,\n",
       " 0.771,\n",
       " 0.586,\n",
       " 0.558,\n",
       " 0.752,\n",
       " 0.832,\n",
       " 0.807,\n",
       " 0.774,\n",
       " 0.72,\n",
       " 0.844,\n",
       " 0.825,\n",
       " 0.612,\n",
       " 0.774,\n",
       " 0.718,\n",
       " 0.564,\n",
       " 0.824,\n",
       " 0.728,\n",
       " 0.62,\n",
       " 0.826,\n",
       " 0.806,\n",
       " 0.842,\n",
       " 0.567,\n",
       " 0.564,\n",
       " 0.569,\n",
       " 0.691,\n",
       " 0.586,\n",
       " 0.42,\n",
       " 0.712,\n",
       " 0.62,\n",
       " 0.844,\n",
       " 0.609,\n",
       " 0.811,\n",
       " 0.792,\n",
       " 0.81,\n",
       " 0.789,\n",
       " 0.82,\n",
       " 0.616,\n",
       " 0.657,\n",
       " 0.445,\n",
       " 0.625,\n",
       " 0.812,\n",
       " 0.635,\n",
       " 0.555,\n",
       " 0.613,\n",
       " 0.843,\n",
       " 0.754,\n",
       " 0.507,\n",
       " 0.811,\n",
       " 0.679,\n",
       " 0.832,\n",
       " 0.84,\n",
       " 0.666,\n",
       " 0.843,\n",
       " 0.517,\n",
       " 0.537,\n",
       " 0.625,\n",
       " 0.821,\n",
       " 0.62,\n",
       " 0.493,\n",
       " 0.784,\n",
       " 0.729,\n",
       " 0.791,\n",
       " 0.602,\n",
       " 0.709,\n",
       " 0.821,\n",
       " 0.749,\n",
       " 0.74,\n",
       " 0.437,\n",
       " 0.599,\n",
       " 0.689,\n",
       " 0.564,\n",
       " 0.789,\n",
       " 0.644,\n",
       " 0.756,\n",
       " 0.599,\n",
       " 0.844,\n",
       " 0.62,\n",
       " 0.604,\n",
       " 0.564,\n",
       " 0.799,\n",
       " 0.474,\n",
       " 0.546,\n",
       " 0.564,\n",
       " 0.837,\n",
       " 0.83,\n",
       " 0.737,\n",
       " 0.61,\n",
       " 0.484,\n",
       " 0.557,\n",
       " 0.512,\n",
       " 0.775,\n",
       " 0.674,\n",
       " 0.503,\n",
       " 0.579,\n",
       " 0.652,\n",
       " 0.476,\n",
       " 0.469,\n",
       " 0.733,\n",
       " 0.756,\n",
       " 0.472,\n",
       " 0.526,\n",
       " 0.841,\n",
       " 0.803,\n",
       " 0.62,\n",
       " 0.84,\n",
       " 0.824,\n",
       " 0.73,\n",
       " 0.604,\n",
       " 0.764,\n",
       " 0.722,\n",
       " 0.469,\n",
       " 0.753,\n",
       " 0.589,\n",
       " 0.692,\n",
       " 0.466,\n",
       " 0.753,\n",
       " 0.62,\n",
       " 0.796,\n",
       " 0.51,\n",
       " 0.807,\n",
       " 0.83,\n",
       " 0.835,\n",
       " 0.813,\n",
       " 0.512,\n",
       " 0.808,\n",
       " 0.829,\n",
       " 0.472,\n",
       " 0.81,\n",
       " 0.627,\n",
       " 0.741,\n",
       " 0.512,\n",
       " 0.469,\n",
       " 0.843,\n",
       " 0.807,\n",
       " 0.735,\n",
       " 0.749,\n",
       " 0.794,\n",
       " 0.786,\n",
       " 0.425,\n",
       " 0.808,\n",
       " 0.699,\n",
       " 0.477,\n",
       " 0.833,\n",
       " 0.707,\n",
       " 0.768,\n",
       " 0.844,\n",
       " 0.832,\n",
       " 0.781,\n",
       " 0.584,\n",
       " 0.843,\n",
       " 0.62,\n",
       " 0.604,\n",
       " 0.62,\n",
       " 0.794,\n",
       " 0.791,\n",
       " 0.67,\n",
       " 0.44,\n",
       " 0.741,\n",
       " 0.61,\n",
       " 0.79,\n",
       " 0.556,\n",
       " 0.496,\n",
       " 0.82,\n",
       " 0.822,\n",
       " 0.786,\n",
       " 0.798,\n",
       " 0.81,\n",
       " 0.689,\n",
       " 0.524,\n",
       " 0.818,\n",
       " 0.633,\n",
       " 0.815,\n",
       " 0.507,\n",
       " 0.71,\n",
       " 0.504,\n",
       " 0.839,\n",
       " 0.62,\n",
       " 0.679,\n",
       " 0.809,\n",
       " 0.821,\n",
       " 0.843,\n",
       " 0.625,\n",
       " 0.822,\n",
       " 0.447,\n",
       " 0.794,\n",
       " 0.556,\n",
       " 0.775,\n",
       " 0.658,\n",
       " 0.685,\n",
       " ...]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sub10['pred'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5df8872c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.812,0.773,0.806,0.841,0.813,0.844,0.738,0.567,0.759,0.783,0.512,0.536,0.8,0.844,0.773,0.783,0.584,0.557,0.772,0.694,0.822,0.674,0.813,0.799,0.844,0.807,0.81,0.844,0.773,0.716,0.829,0.776,0.772,0.82,0.806,0.841,0.62,0.524,0.669,0.813,0.791,0.821,0.703,0.763,0.823,0.801,0.844,0.499,0.606,0.755,0.542,0.805,0.782,0.423,0.559,0.589,0.841,0.834,0.834,0.808,0.829,0.626,0.468,0.755,0.844,0.662,0.843,0.751,0.826,0.828,0.844,0.8,0.773,0.772,0.791,0.738,0.773,0.811,0.806,0.793,0.537,0.788,0.822,0.442,0.841,0.805,0.751,0.844,0.8,0.76,0.818,0.778,0.751,0.817,0.556,0.758,0.667,0.779,0.549,0.808,0.779,0.84,0.841,0.739,0.704,0.739,0.62,0.671,0.805,0.546,0.791,0.844,0.791,0.79,0.537,0.798,0.791,0.802,0.79,0.567,0.813,0.844,0.531,0.663,0.79,0.642,0.844,0.812,0.438,0.47,0.829,0.657,0.502,0.819,0.774,0.777,0.611,0.812,0.615,0.772,0.532,0.795,0.772,0.759,0.671,0.824,0.753,0.764,0.474,0.826,0.835,0.832,0.83,0.812,0.654,0.63,0.775,0.754,0.814,0.733,0.82,0.8,0.841,0.593,0.817,0.834,0.73,0.841,0.773,0.528,0.76,0.576,0.695,0.844,0.828,0.751,0.784,0.761,0.717,0.769,0.506,0.525,0.843,0.615,0.651,0.843,0.817,0.835,0.83,0.744,0.77,0.681,0.564,0.802,0.795,0.492,0.834,0.536,0.775,0.731,0.806,0.841,0.822,0.84,0.735,0.772,0.533,0.563,0.631,0.62,0.83,0.844,0.434,0.844,0.811,0.663,0.844,0.841,0.619,0.79,0.731,0.623,0.615,0.78,0.825,0.612,0.641,0.795,0.552,0.518,0.446,0.769,0.767,0.844,0.494,0.822,0.844,0.615,0.844,0.842,0.474,0.802,0.842,0.827,0.8,0.559,0.785,0.47,0.812,0.753,0.592,0.432,0.803,0.833,0.429,0.682,0.844,0.826,0.652,0.454,0.843,0.72,0.524,0.78,0.805,0.821,0.558,0.842,0.794,0.494,0.681,0.787,0.812,0.644,0.782,0.614,0.832,0.806,0.752,0.764,0.821,0.828,0.489,0.79,0.707,0.431,0.818,0.797,0.62,0.826,0.561,0.527,0.616,0.737,0.503,0.547,0.792,0.478,0.645,0.765,0.811,0.738,0.807,0.841,0.844,0.801,0.807,0.829,0.815,0.802,0.84,0.752,0.467,0.796,0.809,0.475,0.844,0.615,0.763,0.588,0.686,0.656,0.546,0.528,0.777,0.795,0.615,0.706,0.716,0.62,0.498,0.813,0.536,0.844,0.711,0.62,0.689,0.818,0.428,0.717,0.77,0.804,0.782,0.822,0.704,0.818,0.773,0.492,0.642,0.838,0.498,0.434,0.763,0.811,0.564,0.844,0.768,0.721,0.831,0.843,0.844,0.761,0.512,0.79,0.773,0.789,0.539,0.802,0.815,0.599,0.806,0.812,0.826,0.842,0.772,0.815,0.772,0.811,0.826,0.649,0.704,0.812,0.428,0.625,0.827,0.765,0.447,0.839,0.839,0.779,0.476,0.812,0.595,0.816,0.768,0.826,0.803,0.844,0.844,0.789,0.666,0.801,0.814,0.65,0.795,0.663,0.546,0.588,0.769,0.67,0.517,0.597,0.779,0.711,0.625,0.47,0.81,0.592,0.524,0.572,0.83,0.736,0.736,0.774,0.701,0.54,0.613,0.47,0.802,0.727,0.613,0.512,0.436,0.844,0.517,0.783,0.816,0.561,0.69,0.806,0.552,0.749,0.83,0.621,0.783,0.59,0.511,0.844,0.446,0.6,0.815,0.818,0.539,0.83,0.712,0.782,0.794,0.844,0.829,0.844,0.844,0.482,0.775,0.652,0.73,0.836,0.515,0.738,0.433,0.808,0.518,0.6,0.444,0.815,0.59,0.727,0.808,0.775,0.613,0.746,0.512,0.701,0.821,0.465,0.462,0.467,0.838,0.785,0.773,0.518,0.488,0.751,0.615,0.662,0.788,0.842,0.821,0.553,0.553,0.437,0.838,0.759,0.844,0.62,0.458,0.838,0.553,0.844,0.8,0.62,0.784,0.797,0.759,0.524,0.553,0.515,0.429,0.62,0.663,0.458,0.578,0.512,0.475,0.564,0.802,0.834,0.841,0.843,0.833,0.773,0.427,0.843,0.715,0.526,0.844,0.719,0.703,0.53,0.703,0.571,0.498,0.812,0.62,0.444,0.817,0.613,0.501,0.724,0.593,0.62,0.844,0.795,0.791,0.81,0.798,0.774,0.427,0.745,0.581,0.676,0.843,0.438,0.633,0.781,0.474,0.811,0.755,0.495,0.573,0.709,0.84,0.556,0.427,0.43,0.841,0.811,0.736,0.72,0.843,0.809,0.816,0.46,0.748,0.841,0.642,0.844,0.84,0.553,0.837,0.746,0.753,0.84,0.512,0.562,0.694,0.679,0.844,0.513,0.579,0.69,0.827,0.844,0.725,0.741,0.498,0.679,0.62,0.823,0.83,0.704,0.811,0.842,0.436,0.558,0.561,0.807,0.614,0.468,0.498,0.466,0.826,0.788,0.783,0.84,0.778,0.47,0.467,0.806,0.831,0.818,0.692,0.816,0.615,0.458,0.811,0.62,0.557,0.466,0.686,0.794,0.842,0.84,0.769,0.615,0.844,0.513,0.615,0.799,0.838,0.592,0.84,0.62,0.42,0.754,0.799,0.809,0.716,0.64,0.791,0.839,0.626,0.643,0.475,0.62,0.503,0.537,0.83,0.844,0.83,0.687,0.475,0.803,0.767,0.62,0.553,0.671,0.824,0.817,0.511,0.509,0.749,0.51,0.481,0.843,0.791,0.84,0.607,0.629,0.779,0.516,0.452,0.564,0.631,0.71,0.74,0.816,0.844,0.844,0.512,0.753,0.821,0.812,0.443,0.784,0.666,0.749,0.806,0.611,0.8,0.485,0.843,0.586,0.796,0.524,0.743,0.809,0.756,0.597,0.758,0.542,0.766,0.625,0.844,0.49,0.823,0.761,0.528,0.812,0.543,0.518,0.83,0.573,0.74,0.794,0.655,0.617,0.819,0.844,0.822,0.844,0.821,0.728,0.788,0.843,0.825,0.613,0.567,0.815,0.62,0.723,0.801,0.565,0.791,0.82,0.62,0.602,0.822,0.472,0.62,0.787,0.821,0.842,0.491,0.613,0.844,0.789,0.676,0.598,0.841,0.69,0.428,0.644,0.797,0.559,0.522,0.546,0.507,0.573,0.803,0.685,0.803,0.613,0.822,0.703,0.808,0.575,0.706,0.752,0.843,0.487,0.503,0.742,0.614,0.763,0.617,0.581,0.811,0.48,0.692,0.554,0.557,0.488,0.818,0.425,0.62,0.834,0.831,0.719,0.843,0.816,0.843,0.62,0.771,0.586,0.558,0.752,0.832,0.807,0.774,0.72,0.844,0.825,0.612,0.774,0.718,0.564,0.824,0.728,0.62,0.826,0.806,0.842,0.567,0.564,0.569,0.691,0.586,0.42,0.712,0.62,0.844,0.609,0.811,0.792,0.81,0.789,0.82,0.616,0.657,0.445,0.625,0.812,0.635,0.555,0.613,0.843,0.754,0.507,0.811,0.679,0.832,0.84,0.666,0.843,0.517,0.537,0.625,0.821,0.62,0.493,0.784,0.729,0.791,0.602,0.709,0.821,0.749,0.74,0.437,0.599,0.689,0.564,0.789,0.644,0.756,0.599,0.844,0.62,0.604,0.564,0.799,0.474,0.546,0.564,0.837,0.83,0.737,0.61,0.484,0.557,0.512,0.775,0.674,0.503,0.579,0.652,0.476,0.469,0.733,0.756,0.472,0.526,0.841,0.803,0.62,0.84,0.824,0.73,0.604,0.764,0.722,0.469,0.753,0.589,0.692,0.466,0.753,0.62,0.796,0.51,0.807,0.83,0.835,0.813,0.512,0.808,0.829,0.472,0.81,0.627,0.741,0.512,0.469,0.843,0.807,0.735,0.749,0.794,0.786,0.425,0.808,0.699,0.477,0.833,0.707,0.768,0.844,0.832,0.781,0.584,0.843,0.62,0.604,0.62,0.794,0.791,0.67,0.44,0.741,0.61,0.79,0.556,0.496,0.82,0.822,0.786,0.798,0.81,0.689,0.524,0.818,0.633,0.815,0.507,0.71,0.504,0.839,0.62,0.679,0.809,0.821,0.843,0.625,0.822,0.447,0.794,0.556,0.775,0.658,0.685,0.826,0.666,0.559,0.782,0.784,0.809,0.526,0.467,0.784,0.742,0.436,0.836,0.668,0.806,0.716,0.512,0.474,0.844,0.586,0.844,0.692,0.728,0.62,0.802,0.461,0.62,0.613,0.564,0.613,0.817,0.839,0.838,0.837,0.62,0.77,0.62,0.732,0.445,0.62,0.753,0.452,0.59,0.546,0.45,0.42,0.506,0.797,0.834,0.62,0.767,0.768,0.55,0.747,0.771,0.734,0.831,0.843,0.577,0.663,0.817,0.78,0.62,0.844,0.691,0.774,0.829,0.814,0.79,0.776,0.593,0.79,0.474,0.663,0.807,0.616,0.659,0.771,0.84,0.599,0.791,0.537,0.62,0.613,0.543,0.629,0.737,0.62,0.674,0.712,0.637,0.597,0.512,0.62,0.503,0.62,0.677,0.84,0.835,0.617,0.835,0.77,0.504,0.512,0.613,0.731,0.467,0.624,0.586,0.529,0.506,0.604,0.84,0.842,0.62,0.527,0.62,0.633,0.689,0.541,0.572,0.499,0.844,0.591,0.539,0.62,0.767,0.546,0.74,0.81,0.512,0.452,0.742,0.438,0.819,0.613,0.675,0.84,0.62,0.844,0.431,0.62,0.765,0.62,0.62,0.765,0.532,0.62,0.431,0.754,0.747,0.62,0.478,0.661,0.748,0.832,0.72,0.816,0.817,0.571,0.498,0.526,0.629,0.844,0.786,0.659,0.768,0.62,0.787,0.668,0.538,0.62,0.796,0.439,0.783,0.586,0.82,0.613,0.629,0.533,0.774,0.645,0.613,0.748,0.51,0.811,0.59,0.675,0.496,0.783,0.654,0.459,0.774,0.512,0.475,0.625,0.48,0.758,0.613,0.577,0.62,0.62,0.604,0.703,0.526,0.71,0.505,0.742,0.744,0.62,0.819,0.771,0.62,0.813,0.775,0.839,0.62,0.843,0.585,0.711,0.618,0.695,0.795,0.666,0.533,0.448,0.552,0.737,0.531,0.741,0.62,0.499,0.512,0.76,0.552,0.834,0.762,0.62,0.844,0.62,0.62,0.43,0.51,0.844,0.73,0.504,0.603,0.781,0.843,0.739,0.708,0.62,0.818,0.774,0.536,0.757,0.604,0.814,0.613,0.62,0.615,0.759,0.514,0.844,0.533,0.725,0.564,0.604,0.831,0.819,0.555,0.675,0.487,0.512,0.756,0.805,0.767,0.467,0.836,0.62,0.781,0.82,0.579,0.792,0.793,0.491,0.738,0.62,0.503,0.742,0.674,0.62,0.62,0.604,0.485,0.524,0.674,0.484,0.708,0.782,0.772,0.826,0.586,0.459,0.733,0.564,0.794,0.595,0.832,0.436,0.802,0.604,0.817,0.525,0.48,0.703,0.615,0.74,0.843,0.553,0.472,0.557,0.739,0.827,0.505,0.775,0.564,0.521,0.63,0.62,0.84,0.546,0.789,0.602,0.613,0.613,0.778,0.537,0.589,0.62,0.547,0.469,0.834,0.575,0.62,0.512,0.62,0.63,0.808,0.844,0.47,0.822,0.62,0.625,0.635,0.597,0.531,0.66,0.702,0.611,0.745,0.824,0.618,0.475,0.62,0.801,0.479,0.463,0.826,0.429,0.535,0.699,0.778,0.62,0.629,0.742,0.613,0.62,0.532,0.62,0.62,0.522,0.705,0.539,0.581,0.613,0.729,0.604,0.62,0.439,0.62,0.609,0.782,0.597,0.62,0.62,0.546,0.62,0.599,0.62,0.554,0.666,0.613,0.584,0.793,0.527,0.663,0.531,0.62,0.62,0.806,0.567,0.629,0.689,0.613,0.613,0.538,0.638,0.518,0.615,0.629,0.447,0.613,0.619,0.788,0.663,0.613,0.709,0.776,0.613,0.539,0.48,0.615,0.627,0.698,0.801,0.615,0.615,0.627,0.586,0.569,0.75,0.663,0.599,0.505,0.613,0.776,0.557,0.429,0.469,0.615,0.674,0.526,0.594,0.613,0.542,0.498,0.559,0.703,0.507,0.781,0.594,0.613,0.507,0.765,0.49,0.688,0.657,0.777,0.737,0.595,0.62,0.642,0.623,0.634,0.711,0.546,0.45,0.751,0.436,0.511,0.787,0.826,0.745,0.719,0.553,0.751,0.818,0.481,0.719,0.546,0.62,0.501,0.774,0.753,0.512,0.663,0.778,0.841,0.713,0.687,0.554,0.643,0.832,0.821,0.62,0.834,0.586,0.796,0.774,0.788,0.586,0.485,0.479,0.82,0.503,0.681,0.514,0.788,0.6,0.62,0.586,0.528,0.776,0.796,0.62,0.823,0.818,0.642,0.546,0.63,0.445,0.775,0.656,0.433,0.783,0.469,0.43,0.78,0.476,0.661,0.834,0.62,0.782,0.774,0.461,0.445,0.427,0.742,0.489,0.512,0.512,0.691,0.44,0.654,0.824,0.626,0.684,0.732,0.824,0.821,0.512,0.543,0.717,0.433,0.738,0.724,0.785,0.784,0.51,0.629,0.665,0.839,0.786,0.663,0.735,0.491,0.62,0.46,0.604,0.793,0.481,0.8,0.436,0.692,0.719,0.472,0.747,0.507,0.703,0.701,0.815,0.774,0.503,0.83,0.466,0.774,0.505,0.598,0.643,0.804,0.837,0.55,0.716,0.534,0.466,0.489,0.531,0.467,0.65,0.499,0.534,0.709,0.586,0.579,0.712,0.844,0.503,0.559,0.759,0.467,0.704,0.665,0.803,0.529,0.838,0.508,0.604,0.581,0.635,0.736,0.497,0.478,0.546,0.503,0.813,0.703,0.694,0.74,0.812,0.475,0.703,0.716,0.531,0.507,0.468,0.805,0.789,0.798,0.663,0.774,0.738,0.777,0.822,0.711,0.445,0.722,0.81,0.703,0.712,0.469,0.43,0.83,0.713,0.494,0.776,0.713,0.808,0.768,0.823,0.74,0.77,0.796,0.741,0.764,0.62,0.62,0.533,0.468,0.604,0.515,0.751,0.46,0.782,0.72,0.466,0.633,0.663,0.534,0.746,0.62,0.62,0.647,0.693,0.546,0.469,0.772,0.753,0.494,0.777,0.433,0.559,0.641,0.564,0.663,0.776,0.628,0.494,0.809,0.726,0.704,0.62,0.789,0.43,0.741,0.741,0.62,0.835,0.818,0.62,0.637,0.704,0.633,0.634,0.57,0.694,0.507,0.626,0.43,0.466,0.607,0.774,0.681,0.466,0.818,0.734,0.469,0.773,0.62,0.533,0.445,0.457,0.469,0.602,0.77,0.746,0.468,0.752,0.586,0.649,0.475,0.472,0.497,0.475,0.703,0.546,0.512,0.703,0.666,0.469,0.674,0.541,0.747,0.546,0.544,0.55,0.734,0.707,0.466,0.525,0.466,0.531,0.816,0.579,0.503,0.536,0.703,0.663,0.772,0.528,0.611,0.604,0.625,0.62,0.75,0.743,0.657,0.625,0.687,0.663,0.738,0.62,0.62,0.663,0.625,0.703,0.512,0.521,0.44,0.512,0.625,0.604,0.534,0.607,0.586,0.695,0.515,0.564,0.742,0.499,0.488,0.613,0.564,0.546,0.564,0.649,0.62,0.562,0.564,0.62,0.62,0.62,0.546,0.625,0.62,0.552,0.555,0.62,0.62,0.666,0.538,0.604,0.62,0.663,0.498,0.663,0.536,0.672,0.62,0.62,0.453,0.606,0.63,0.62,0.62,0.62,0.62,0.62,0.62,0.46,0.62,0.62,0.62,0.531,0.62,0.531,0.656,0.613,0.62,0.62,0.62,0.582,0.604,0.512,0.604,0.557,0.816,0.62,0.62,0.62,0.62,0.666,0.62,0.503,0.595,0.537,0.611,0.595,0.537,0.626,0.62,0.627,0.626,0.597,0.62,0.626,0.61,0.62,0.629,0.62,0.613,0.624,0.62,0.625,0.627,0.62,0.62,0.586,0.666,0.625,0.576,0.537,0.604,0.62,0.62,0.618,0.682,0.629,0.691,0.531,0.62,0.681,0.727,0.678,0.674,0.62,0.62,0.599,0.62,0.604,0.59,0.703,0.62,0.604,0.62,0.62,0.62,0.564,0.62,0.507,0.62,0.62,0.613,0.512,0.564,0.546,0.62,0.564,0.62,0.629,0.726,0.512,0.503,0.622,0.476,0.629,0.522,0.505,0.62,0.546,0.629,0.564,0.587,0.629,0.66,0.506,0.475,0.62,0.586,0.666,0.676,0.629,0.604,0.739,0.739,0.739,0.669,0.492,0.62,0.621,0.62,0.512,0.512,0.564,0.537,0.62,0.472,0.604,0.564,0.512,0.663,0.62,0.546,0.651,0.564,0.586,0.615,0.604,0.562,0.62,0.62,0.523,0.62,0.731,0.62,0.642,0.62,0.62,0.62,0.618,0.672,0.62,0.613,0.62,0.629,0.574,0.629,0.615,0.62,0.62,0.62,0.62,0.526,0.62,0.618,0.62,0.62,0.674,0.629,0.62,0.629,0.629,0.629,0.674,0.629,0.629,0.62,0.629,0.564,0.586,0.615,0.62,0.62,0.62,0.564,0.62,0.62,0.574,0.7,0.62,0.618,0.586,0.604,0.62,0.62,0.676,0.628,0.62,0.62,0.62,0.549,0.517,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.534,0.604,0.62,0.63,0.62,0.623,0.62,0.532,0.564,0.634,0.742,0.62,0.537,0.62,0.62,0.62,0.666,0.581,0.62,0.615,0.577,0.62,0.62,0.62,0.528,0.62,0.564,0.62,0.533,0.62,0.62,0.682,0.615,0.62,0.618,0.62,0.62,0.55,0.54,0.663,0.586,0.625,0.62,0.564,0.564,0.62,0.62,0.62,0.62,0.615,0.604,0.604,0.613,0.613,0.564,0.623,0.604,0.62,0.525,0.481,0.564,0.607,0.63,0.703,0.497,0.734,0.528,0.742,0.564,0.625,0.629,0.564,0.667,0.555,0.649,0.604,0.62,0.62,0.564,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.555,0.604,0.62,0.604,0.604,0.699,0.604,0.62,0.625,0.62,0.62,0.62,0.604,0.604,0.5,0.604,0.63,0.62,0.604,0.62,0.586,0.699,0.623,0.62,0.62,0.595,0.62,0.62,0.62,0.625,0.629,0.62,0.62,0.586,0.62,0.62,0.62,0.62,0.629,0.604,0.62,0.62,0.62,0.62,0.602,0.568,0.611,0.62,0.615,0.62,0.62,0.62,0.62,0.564,0.62,0.618,0.62,0.62,0.62,0.62,0.629,0.599,0.559,0.564,0.62,0.62,0.62,0.613,0.615,0.62,0.564,0.62,0.663,0.62,0.58,0.623,0.62,0.667,0.663,0.623,0.62,0.62,0.564,0.564,0.564,0.62,0.62,0.62,0.62,0.62,0.62,0.611,0.552,0.604,0.62,0.62,0.586,0.604,0.62,0.62,0.586,0.62,0.604,0.62,0.62,0.663,0.634,0.62,0.546,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.615,0.586,0.62,0.62,0.62,0.62,0.604,0.55,0.528,0.699,0.62,0.62,0.62,0.611,0.604,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.615,0.615,0.615,0.534,0.528,0.62,0.564,0.629,0.598,0.62,0.62,0.62,0.666,0.564,0.62,0.62,0.62,0.62,0.62,0.62,0.615,0.615,0.62,0.604,0.528,0.62,0.604,0.62,0.618,0.586,0.62,0.62,0.62,0.62,0.708,0.62,0.62,0.62,0.62,0.62,0.604,0.59,0.604,0.595,0.62,0.604,0.604,0.62,0.62,0.62,0.629,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.595,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.604,0.62,0.62,0.604,0.625,0.604,0.62,0.62,0.62'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub10_txt = ''\n",
    "for prob in list(sub10['pred'].values):\n",
    "    sub10_txt = sub10_txt+','+str(prob)\n",
    "sub10_txt = sub10_txt[1:]\n",
    "\n",
    "sub10_txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
